{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Text Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_results_path = '/fs/cfar-projects/low-bit-vision/uniform_results/image_text_retrieval/blip2_flickr_results.csv'\n",
    "df_uniform = pd.read_csv(uniform_results_path)\n",
    "df_uniform = df_uniform.dropna(axis = 1, how = 'all')\n",
    "\n",
    "# with pd.option_context('display.max_rows', 10):\n",
    "#     display(df_uniform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vit_bits</th>\n",
       "      <th>qformer_bits</th>\n",
       "      <th>txt_r1</th>\n",
       "      <th>txt_r5</th>\n",
       "      <th>txt_r10</th>\n",
       "      <th>txt_r_mean</th>\n",
       "      <th>img_r1</th>\n",
       "      <th>img_r5</th>\n",
       "      <th>img_r10</th>\n",
       "      <th>img_r_mean</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>agg_metrics</th>\n",
       "      <th>model_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>65.6</td>\n",
       "      <td>85.1</td>\n",
       "      <td>91.9</td>\n",
       "      <td>80.866667</td>\n",
       "      <td>55.66</td>\n",
       "      <td>78.76</td>\n",
       "      <td>85.30</td>\n",
       "      <td>73.240000</td>\n",
       "      <td>77.053333</td>\n",
       "      <td>80.866667</td>\n",
       "      <td>387.970088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>78.4</td>\n",
       "      <td>93.3</td>\n",
       "      <td>96.6</td>\n",
       "      <td>89.433333</td>\n",
       "      <td>65.12</td>\n",
       "      <td>85.56</td>\n",
       "      <td>90.52</td>\n",
       "      <td>80.400000</td>\n",
       "      <td>84.916667</td>\n",
       "      <td>89.433333</td>\n",
       "      <td>408.189992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>78.2</td>\n",
       "      <td>93.8</td>\n",
       "      <td>96.4</td>\n",
       "      <td>89.466667</td>\n",
       "      <td>64.74</td>\n",
       "      <td>84.86</td>\n",
       "      <td>89.72</td>\n",
       "      <td>79.773333</td>\n",
       "      <td>84.620000</td>\n",
       "      <td>89.466667</td>\n",
       "      <td>428.409896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>79.1</td>\n",
       "      <td>93.1</td>\n",
       "      <td>95.9</td>\n",
       "      <td>89.366667</td>\n",
       "      <td>64.52</td>\n",
       "      <td>84.26</td>\n",
       "      <td>89.34</td>\n",
       "      <td>79.373333</td>\n",
       "      <td>84.370000</td>\n",
       "      <td>89.366667</td>\n",
       "      <td>448.629800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>78.5</td>\n",
       "      <td>93.6</td>\n",
       "      <td>95.7</td>\n",
       "      <td>89.266667</td>\n",
       "      <td>64.40</td>\n",
       "      <td>84.32</td>\n",
       "      <td>89.40</td>\n",
       "      <td>79.373333</td>\n",
       "      <td>84.320000</td>\n",
       "      <td>89.266667</td>\n",
       "      <td>468.849704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vit_bits  qformer_bits  txt_r1  txt_r5  txt_r10  txt_r_mean  img_r1  \\\n",
       "0         2             2    65.6    85.1     91.9   80.866667   55.66   \n",
       "1         2             3    78.4    93.3     96.6   89.433333   65.12   \n",
       "2         2             4    78.2    93.8     96.4   89.466667   64.74   \n",
       "3         2             5    79.1    93.1     95.9   89.366667   64.52   \n",
       "4         2             6    78.5    93.6     95.7   89.266667   64.40   \n",
       "\n",
       "   img_r5  img_r10  img_r_mean     r_mean  agg_metrics  model_size  \n",
       "0   78.76    85.30   73.240000  77.053333    80.866667  387.970088  \n",
       "1   85.56    90.52   80.400000  84.916667    89.433333  408.189992  \n",
       "2   84.86    89.72   79.773333  84.620000    89.466667  428.409896  \n",
       "3   84.26    89.34   79.373333  84.370000    89.366667  448.629800  \n",
       "4   84.32    89.40   79.373333  84.320000    89.266667  468.849704  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awq_results_path = '/fs/cfar-projects/low-bit-vision/awq_results/image_text_retrieval/awq_image_text_retrieval.csv'\n",
    "df_awq = pd.read_csv(awq_results_path)\n",
    "# bits --> megabytes\n",
    "df_awq['model_size'] = df_awq['model_size'] / 8e6\n",
    "df_awq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df_awq, x='img_r1', y=\"txt_r1\", z = 'model_size',\n",
    "                    color = 'vit_bits',\n",
    "                    symbol = 'qformer_bits',\n",
    "                    hover_data = df_awq.columns,\n",
    "                    title = 'AWQ Blip-2 Flickr30k Information Retrieval',)\n",
    "\n",
    "\n",
    "fig.update_traces(marker=dict(size=4.5))\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "                  xaxis_title='Text-->Img R@1',\n",
    "                  yaxis_title='Img -->Text R@1',\n",
    "                  zaxis_title='Model Size (MB)',\n",
    "                  \n",
    "                  xaxis = dict(autorange='reversed'),\n",
    "                  yaxis = dict(autorange='reversed')),)\n",
    "\n",
    "fig.write_html(\"awq_retrieval.html\")\n",
    "\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
