{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeebc607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs/nexus-scratch/vla/micromamba/envs/MMQ_LLAVA/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from typing import List, Dict, Any, Optional\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "from transformers.models.llava.image_processing_llava import LlavaImageProcessor\n",
    "\n",
    "from dataset import VQAv2Eval\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c285b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2362434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab5e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "# ====================================================\n",
    "# Quantization Classes and Functions\n",
    "# ====================================================\n",
    "\n",
    "def quantize(x, scale, zero, maxq):\n",
    "    if maxq < 0:\n",
    "        return (x > scale / 2).float() * scale + (x < zero / 2).float() * zero\n",
    "    q = torch.clamp(torch.round(x / scale) + zero, 0, maxq)\n",
    "    return scale * (q - zero)\n",
    "\n",
    "\n",
    "class Quantizer(nn.Module):\n",
    "    def __init__(self, shape=1):\n",
    "        super(Quantizer, self).__init__()\n",
    "        self.register_buffer(\"maxq\", torch.tensor(0))\n",
    "        self.register_buffer(\"scale\", torch.zeros(shape))\n",
    "        self.register_buffer(\"zero\", torch.zeros(shape))\n",
    "\n",
    "    def configure(\n",
    "        self,\n",
    "        bits,\n",
    "        perchannel=False,\n",
    "        sym=True,\n",
    "        mse=False,\n",
    "        norm=2.4,\n",
    "        grid=100,\n",
    "        maxshrink=0.8,\n",
    "        trits=False,\n",
    "    ):\n",
    "        device = self.maxq.device\n",
    "        self.maxq = torch.tensor(2**bits - 1, device=device)\n",
    "        self.perchannel = perchannel\n",
    "        self.sym = sym\n",
    "        self.mse = mse\n",
    "        self.norm = norm\n",
    "        self.grid = grid\n",
    "        self.maxshrink = maxshrink\n",
    "        if trits:\n",
    "            self.maxq = torch.tensor(-1, device=device)\n",
    "\n",
    "    def find_params(self, x, weight=False):\n",
    "        dev = x.device\n",
    "        self.maxq = self.maxq.to(dev)\n",
    "\n",
    "        shape = x.shape\n",
    "        if self.perchannel:\n",
    "            if weight:\n",
    "                x = x.flatten(1)\n",
    "            else:\n",
    "                if len(shape) == 4:\n",
    "                    x = x.permute([1, 0, 2, 3])\n",
    "                    x = x.flatten(1)\n",
    "                if len(shape) == 3:\n",
    "                    x = x.reshape((-1, shape[-1])).t()\n",
    "                if len(shape) == 2:\n",
    "                    x = x.t()\n",
    "        else:\n",
    "            x = x.flatten().unsqueeze(0)\n",
    "\n",
    "        tmp = torch.zeros(x.shape[0], device=dev)\n",
    "        xmin = torch.minimum(x.min(1)[0], tmp)\n",
    "        xmax = torch.maximum(x.max(1)[0], tmp)\n",
    "\n",
    "        if self.sym:\n",
    "            xmax = torch.maximum(torch.abs(xmin), xmax)\n",
    "            tmp = xmin < 0\n",
    "            if torch.any(tmp):\n",
    "                xmin[tmp] = -xmax[tmp]\n",
    "        tmp = (xmin == 0) & (xmax == 0)\n",
    "        xmin[tmp] = -1\n",
    "        xmax[tmp] = +1\n",
    "\n",
    "        if self.maxq < 0:\n",
    "            self.scale = xmax\n",
    "            self.zero = xmin\n",
    "        else:\n",
    "            self.scale = (xmax - xmin) / self.maxq\n",
    "            if self.sym:\n",
    "                self.zero = torch.full_like(self.scale, (self.maxq + 1) / 2)\n",
    "            else:\n",
    "                self.zero = torch.round(-xmin / self.scale)\n",
    "\n",
    "        if self.mse:\n",
    "            best = torch.full([x.shape[0]], float(\"inf\"), device=dev)\n",
    "            for i in range(int(self.maxshrink * self.grid)):\n",
    "                p = 1 - i / self.grid\n",
    "                xmin1 = p * xmin\n",
    "                xmax1 = p * xmax\n",
    "                scale1 = (xmax1 - xmin1) / self.maxq\n",
    "                zero1 = torch.round(-xmin1 / scale1) if not self.sym else self.zero\n",
    "                q = quantize(x, scale1.unsqueeze(1), zero1.unsqueeze(1), self.maxq)\n",
    "                q -= x\n",
    "                q.abs_()\n",
    "                q.pow_(self.norm)\n",
    "                err = torch.sum(q, 1)\n",
    "                tmp = err < best\n",
    "                if torch.any(tmp):\n",
    "                    best[tmp] = err[tmp]\n",
    "                    self.scale[tmp] = scale1[tmp]\n",
    "                    self.zero[tmp] = zero1[tmp]\n",
    "        if not self.perchannel:\n",
    "            if weight:\n",
    "                tmp = shape[0]\n",
    "            else:\n",
    "                tmp = shape[1] if len(shape) != 3 else shape[2]\n",
    "            self.scale = self.scale.repeat(tmp)\n",
    "            self.zero = self.zero.repeat(tmp)\n",
    "\n",
    "        if weight:\n",
    "            shape = [-1] + [1] * (len(shape) - 1)\n",
    "            self.scale = self.scale.reshape(shape)\n",
    "            self.zero = self.zero.reshape(shape)\n",
    "            return\n",
    "        if len(shape) == 4:\n",
    "            self.scale = self.scale.reshape((1, -1, 1, 1))\n",
    "            self.zero = self.zero.reshape((1, -1, 1, 1))\n",
    "        if len(shape) == 3:\n",
    "            self.scale = self.scale.reshape((1, 1, -1))\n",
    "            self.zero = self.zero.reshape((1, 1, -1))\n",
    "        if len(shape) == 2:\n",
    "            self.scale = self.scale.unsqueeze(0)\n",
    "            self.zero = self.zero.unsqueeze(0)\n",
    "\n",
    "        # Ensure buffers are on the same device as input x\n",
    "        self.scale = self.scale.to(dev)\n",
    "        self.zero = self.zero.to(dev)\n",
    "\n",
    "    def quantize(self, x):\n",
    "        if self.ready():\n",
    "            # Ensure buffers are on the same device as x\n",
    "            self.scale = self.scale.to(x.device)\n",
    "            self.zero = self.zero.to(x.device)\n",
    "            self.maxq = self.maxq.to(x.device)\n",
    "            return quantize(x, self.scale, self.zero, self.maxq)\n",
    "        return x\n",
    "\n",
    "    def enabled(self):\n",
    "        return self.maxq > 0\n",
    "\n",
    "    def ready(self):\n",
    "        return torch.all(self.scale != 0)\n",
    "\n",
    "\n",
    "class GPTQ:\n",
    "    def __init__(self, layer):\n",
    "        self.layer = layer\n",
    "        self.dev = self.layer.weight.device\n",
    "        W = layer.weight.data.clone()\n",
    "        if isinstance(self.layer, nn.Conv2d):\n",
    "            W = W.flatten(1)\n",
    "        if isinstance(self.layer, transformers.Conv1D):\n",
    "            W = W.t()\n",
    "        self.rows = W.shape[0]\n",
    "        self.columns = W.shape[1]\n",
    "        self.H = torch.zeros((self.columns, self.columns), device=self.dev)\n",
    "        self.nsamples = 0\n",
    "        self.quantizer = Quantizer()\n",
    "        self.quantizer.to(self.dev)\n",
    "\n",
    "    def add_batch(self, inp, out):\n",
    "        if DEBUG:\n",
    "            self.inp1 = inp\n",
    "            self.out1 = out\n",
    "        if len(inp.shape) == 2:\n",
    "            inp = inp.unsqueeze(0)\n",
    "        tmp = inp.shape[0]\n",
    "        if isinstance(self.layer, nn.Linear) or isinstance(\n",
    "            self.layer, transformers.Conv1D\n",
    "        ):\n",
    "            if len(inp.shape) == 3:\n",
    "                inp = inp.reshape((-1, inp.shape[-1]))\n",
    "            inp = inp.t()\n",
    "        if isinstance(self.layer, nn.Conv2d):\n",
    "            unfold = nn.Unfold(\n",
    "                self.layer.kernel_size,\n",
    "                dilation=self.layer.dilation,\n",
    "                padding=self.layer.padding,\n",
    "                stride=self.layer.stride,\n",
    "            )\n",
    "            inp = unfold(inp)\n",
    "            inp = inp.permute([1, 0, 2])\n",
    "            inp = inp.flatten(1)\n",
    "\n",
    "        self.H *= self.nsamples / (self.nsamples + tmp)\n",
    "        self.nsamples += tmp\n",
    "        inp = math.sqrt(2 / self.nsamples) * inp.float()\n",
    "        self.H += inp.matmul(inp.t())\n",
    "\n",
    "    def fasterquant(\n",
    "        self,\n",
    "        blocksize=128,\n",
    "        percdamp=0.01,\n",
    "        groupsize=-1,\n",
    "        actorder=False,\n",
    "        static_groups=False,\n",
    "    ):\n",
    "        W = self.layer.weight.data.clone()\n",
    "        if isinstance(self.layer, nn.Conv2d):\n",
    "            W = W.flatten(1)\n",
    "        if isinstance(self.layer, transformers.Conv1D):\n",
    "            W = W.t()\n",
    "        W = W.float()\n",
    "\n",
    "        tick = time.time()\n",
    "\n",
    "        if not self.quantizer.ready():\n",
    "            self.quantizer.find_params(W, weight=True)\n",
    "\n",
    "        H = self.H\n",
    "        del self.H\n",
    "        dead = torch.diag(H) == 0\n",
    "        H[dead, dead] = 1\n",
    "        W[:, dead] = 0\n",
    "\n",
    "        if static_groups:\n",
    "            import copy\n",
    "\n",
    "            groups = []\n",
    "            for i in range(0, self.columns, groupsize):\n",
    "                quantizer = copy.deepcopy(self.quantizer)\n",
    "                quantizer.find_params(W[:, i : (i + groupsize)], weight=True)\n",
    "                groups.append(quantizer)\n",
    "\n",
    "        if actorder:\n",
    "            perm = torch.argsort(torch.diag(H), descending=True)\n",
    "            W = W[:, perm]\n",
    "            H = H[perm][:, perm]\n",
    "            invperm = torch.argsort(perm)\n",
    "\n",
    "        Losses = torch.zeros_like(W)\n",
    "        Q = torch.zeros_like(W)\n",
    "\n",
    "        damp = percdamp * torch.mean(torch.diag(H))\n",
    "        diag = torch.arange(self.columns, device=self.dev)\n",
    "        H[diag, diag] += damp\n",
    "        H = torch.linalg.cholesky(H)\n",
    "        H = torch.cholesky_inverse(H)\n",
    "        H = torch.linalg.cholesky(H, upper=True)\n",
    "        Hinv = H\n",
    "\n",
    "        for i1 in range(0, self.columns, blocksize):\n",
    "            i2 = min(i1 + blocksize, self.columns)\n",
    "            count = i2 - i1\n",
    "\n",
    "            W1 = W[:, i1:i2].clone()\n",
    "            Q1 = torch.zeros_like(W1)\n",
    "            Err1 = torch.zeros_like(W1)\n",
    "            Losses1 = torch.zeros_like(W1)\n",
    "            Hinv1 = Hinv[i1:i2, i1:i2]\n",
    "\n",
    "            for i in range(count):\n",
    "                w = W1[:, i]\n",
    "                d = Hinv1[i, i]\n",
    "\n",
    "                if groupsize != -1:\n",
    "                    if not static_groups:\n",
    "                        if (i1 + i) % groupsize == 0:\n",
    "                            self.quantizer.find_params(\n",
    "                                W[:, (i1 + i) : (i1 + i + groupsize)], weight=True\n",
    "                            )\n",
    "                    else:\n",
    "                        idx = i1 + i\n",
    "                        if actorder:\n",
    "                            idx = perm[idx]\n",
    "                        self.quantizer = groups[idx // groupsize]\n",
    "\n",
    "                q = quantize(\n",
    "                    w.unsqueeze(1),\n",
    "                    self.quantizer.scale,\n",
    "                    self.quantizer.zero,\n",
    "                    self.quantizer.maxq,\n",
    "                ).flatten()\n",
    "                Q1[:, i] = q\n",
    "                Losses1[:, i] = (w - q) ** 2 / d**2\n",
    "\n",
    "                err1 = (w - q) / d\n",
    "                W1[:, i:] -= err1.unsqueeze(1).matmul(Hinv1[i, i:].unsqueeze(0))\n",
    "                Err1[:, i] = err1\n",
    "\n",
    "            Q[:, i1:i2] = Q1\n",
    "            Losses[:, i1:i2] = Losses1 / 2\n",
    "\n",
    "            W[:, i2:] -= Err1.matmul(Hinv[i1:i2, i2:])\n",
    "\n",
    "            if DEBUG:\n",
    "                self.layer.weight.data[:, :i2] = Q[:, :i2]\n",
    "                self.layer.weight.data[:, i2:] = W[:, i2:]\n",
    "                print(torch.sum((self.layer(self.inp1) - self.out1) ** 2))\n",
    "                print(torch.sum(Losses))\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        print(\"Time for quantization: %.2f seconds\" % (time.time() - tick))\n",
    "        print(\"Total quantization error:\", torch.sum(Losses).item())\n",
    "\n",
    "        if actorder:\n",
    "            Q = Q[:, invperm]\n",
    "\n",
    "        if isinstance(self.layer, transformers.Conv1D):\n",
    "            Q = Q.t()\n",
    "        self.layer.weight.data = Q.reshape(self.layer.weight.shape).to(\n",
    "            self.layer.weight.data.dtype\n",
    "        )\n",
    "        if DEBUG:\n",
    "            print(torch.sum((self.layer(self.inp1) - self.out1) ** 2))\n",
    "\n",
    "    def free(self):\n",
    "        if DEBUG:\n",
    "            self.inp1 = None\n",
    "            self.out1 = None\n",
    "        self.H = None\n",
    "        self.Losses = None\n",
    "        self.Trace = None\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def find_linear_layers_in_model(model):\n",
    "    layers = {}\n",
    "\n",
    "    def recurse(module, prefix=\"\"):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            layers[prefix.rstrip(\".\")] = module\n",
    "        for name, child in module.named_children():\n",
    "            recurse(child, prefix + name + \".\")\n",
    "\n",
    "    recurse(model)\n",
    "    return layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09fb58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlavaQuantizer:\n",
    "    def __init__(self, model, processor, device, chunk_size=32, task = 'vqav2'):\n",
    "        self.model = model\n",
    "        self.processor = processor\n",
    "        self.device = device\n",
    "        self.chunk_size = chunk_size\n",
    "        self.task = task\n",
    "\n",
    "        # Component-specific configuration parameters\n",
    "        self.config = {\n",
    "            \"vision\": {\n",
    "                \"bits\": 4,\n",
    "                \"percent_dampening\": 0.01,\n",
    "                \"group_size\": -1,\n",
    "                \"use_symmetric\": True,\n",
    "                \"use_act_order\": False,\n",
    "                \"use_static_groups\": False,\n",
    "            },\n",
    "            \"language\": {\n",
    "                \"bits\": 4,\n",
    "                \"percent_dampening\": 0.01,\n",
    "                \"group_size\": -1,\n",
    "                \"use_symmetric\": True,\n",
    "                \"use_act_order\": False,\n",
    "                \"use_static_groups\": False,\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "    def _prepare_quantizers(self, layers, component_type):\n",
    "        \"\"\"Initialize GPTQ quantizers for given layers with component-specific settings\"\"\"\n",
    "        config = self.config[component_type]\n",
    "        quantizers = {}\n",
    "        for name, layer in layers.items():\n",
    "            quantizers[name] = GPTQ(layer)\n",
    "            quantizers[name].quantizer.configure(\n",
    "                bits=config[\"bits\"],\n",
    "                perchannel=True,\n",
    "                sym=config[\"use_symmetric\"],\n",
    "                mse=False,\n",
    "            )\n",
    "        return quantizers\n",
    "    \n",
    "    def _process_chunk(\n",
    "        self, layers, start_idx, end_idx, forward_func, desc, component_type\n",
    "    ):\n",
    "        \"\"\"Process a chunk of layers with component-specific quantization settings\"\"\"\n",
    "        current_layers = dict(list(layers.items())[start_idx:end_idx])\n",
    "        print(\n",
    "            f\"\\nProcessing {desc} layers {start_idx} to {end_idx-1} with {self.config[component_type]['bits']}-bit precision\"\n",
    "        )\n",
    "\n",
    "        # Initialize quantizers for current chunk\n",
    "        quantizers = self._prepare_quantizers(current_layers, component_type)\n",
    "        hooks = []\n",
    "\n",
    "        def get_hook(name):\n",
    "            def hook(module, inp, out):\n",
    "                if name in quantizers:\n",
    "                    quantizers[name].add_batch(inp[0].detach(), out.detach())\n",
    "\n",
    "            return hook\n",
    "\n",
    "        for name, layer in current_layers.items():\n",
    "            hooks.append(layer.register_forward_hook(get_hook(name)))\n",
    "\n",
    "        forward_func()\n",
    "\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "\n",
    "        config = self.config[component_type]\n",
    "        for name, layer in current_layers.items():\n",
    "            print(f\"Quantizing layer {name}...\")\n",
    "            quantizer = quantizers[name]\n",
    "            quantizer.fasterquant(\n",
    "                blocksize=32,\n",
    "                percdamp=config[\"percent_dampening\"],\n",
    "                groupsize=config[\"group_size\"],\n",
    "                actorder=config[\"use_act_order\"],\n",
    "                static_groups=config[\"use_static_groups\"],\n",
    "            )\n",
    "\n",
    "            layer.weight.data = quantizer.quantizer.quantize(layer.weight.data).to(\n",
    "                layer.weight.data.dtype\n",
    "            )\n",
    "            quantizer.free()\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "    def quantize_vision_model(self, calibration_set):\n",
    "        \"\"\"Quantize vision model with 8-bit precision\"\"\"\n",
    "        print(\n",
    "            f\"Quantizing Vision Model with {self.config['vision']['bits']}-bit precision...\"\n",
    "        )\n",
    "\n",
    "        # some extra components need to be on device for vision model forward pass\n",
    "        # self.model.vision_tower.to(self.device)\n",
    "        self.model.to(self.device)\n",
    "        self.model.language_model.to('cpu')\n",
    "\n",
    "        layers = find_linear_layers_in_model(self.model.vision_tower.vision_model)\n",
    "        total_layers = len(layers)\n",
    "\n",
    "        print(f'total_layers: {total_layers}')\n",
    "        print(layers)\n",
    "\n",
    "        def forward_pass():\n",
    "            \n",
    "            vision_feature_layer = self.model.config.vision_feature_layer\n",
    "            vision_feature_select_strategy = self.model.config.vision_feature_select_strategy\n",
    "            image_sizes = None\n",
    "            \n",
    "            # TODO: adjust for GQA if needed\n",
    "            if self.task == 'vqav2':\n",
    "                \n",
    "                for img, prompt in tqdm(calibration_set, desc='Processing vision model batch'):\n",
    "\n",
    "                    inputs = self.processor(images = [img],\n",
    "                                            text= [prompt],\n",
    "                                            return_tensors='pt',\n",
    "                                            padding=True).to(self.device)\n",
    "                    \n",
    "                    # runs forward pass through vision_tower\n",
    "                    self.model.get_image_features(\n",
    "                        pixel_values = inputs['pixel_values'],\n",
    "                        vision_feature_layer=vision_feature_layer,\n",
    "                        vision_feature_select_strategy=vision_feature_select_strategy,\n",
    "                        image_sizes=image_sizes\n",
    "                    )\n",
    "\n",
    "\n",
    "        for start_idx in range(0, total_layers, self.chunk_size):\n",
    "            end_idx = min(start_idx + self.chunk_size, total_layers)\n",
    "            self._process_chunk(\n",
    "                layers, start_idx, end_idx, forward_pass, \"vision model\", \"vision\"\n",
    "            )\n",
    "\n",
    "        self.model.vision_tower.vision_model.cpu()\n",
    "        print(\"Vision Model quantization complete.\\n\")\n",
    "\n",
    "\n",
    "    def quantize_language_model(self, calibration_set):\n",
    "        \"\"\"Quantize language model with 4-bit precision\"\"\"\n",
    "        print(\n",
    "            f\"Quantizing Language Model with {self.config['language']['bits']}-bit precision...\"\n",
    "        )\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        layers = find_linear_layers_in_model(self.model.language_model.model)\n",
    "        # layers[\"language_projection\"] = self.model.language_projection\n",
    "        total_layers = len(layers)\n",
    "\n",
    "        def forward_pass():\n",
    "            # TODO: adjust for GQA if needed\n",
    "            if self.task == 'vqav2':\n",
    "                \n",
    "                for img, prompt in tqdm(calibration_set, desc='Processing language model batch'):\n",
    "\n",
    "                    inputs = self.processor(images = [img],\n",
    "                                            text= [prompt],\n",
    "                                            return_tensors='pt',\n",
    "                                            padding=True).to(self.device)\n",
    "                    \n",
    "                    self.model.generate(**inputs)\n",
    "   \n",
    "\n",
    "        for start_idx in range(0, total_layers, self.chunk_size):\n",
    "            end_idx = min(start_idx + self.chunk_size, total_layers)\n",
    "            self._process_chunk(\n",
    "                layers, start_idx, end_idx, forward_pass, \"language model\", \"language\"\n",
    "            )\n",
    "\n",
    "        self.model.cpu()\n",
    "        print(\"Language Model quantization complete.\\n\")\n",
    "\n",
    "    def quantize(self, calibration_set):\n",
    "        \"\"\"Quantize all LLAVA components\"\"\"\n",
    "        print(\"Starting LLAVA model quantization...\")\n",
    "        self.quantize_vision_model(calibration_set)\n",
    "        self.quantize_language_model(calibration_set)\n",
    "        print(\"LLAVA model quantization complete.\")\n",
    "\n",
    "\n",
    "    # TODO:\n",
    "    def prepare_for_inference(self):\n",
    "        self.model.to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50d8aef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 18.58it/s]\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "print(device)\n",
    "\n",
    "# Load the model\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\"llava-hf/llava-1.5-7b-hf\", torch_dtype=torch.float16)\n",
    "model.to('cpu')\n",
    "# processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\", pad_token = '<pad>')\n",
    "processor = AutoProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\", pad_token = '<pad>', use_fast = False)\n",
    "\n",
    "\n",
    "image_processor = LlavaImageProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\",\n",
    "                                                      do_pad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "125a09a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.image_processor = image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abec4170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlavaProcessor:\n",
       "- image_processor: LlavaImageProcessor {\n",
       "  \"crop_size\": {\n",
       "    \"height\": 336,\n",
       "    \"width\": 336\n",
       "  },\n",
       "  \"do_center_crop\": true,\n",
       "  \"do_convert_rgb\": true,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_pad\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.48145466,\n",
       "    0.4578275,\n",
       "    0.40821073\n",
       "  ],\n",
       "  \"image_processor_type\": \"LlavaImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.26862954,\n",
       "    0.26130258,\n",
       "    0.27577711\n",
       "  ],\n",
       "  \"processor_class\": \"LlavaProcessor\",\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"shortest_edge\": 336\n",
       "  }\n",
       "}\n",
       "\n",
       "- tokenizer: LlamaTokenizer(name_or_path='llava-hf/llava-1.5-7b-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'image_token': '<image>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32000: AddedToken(\"<image>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32001: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")\n",
       "\n",
       "{\n",
       "  \"image_token\": \"<image>\",\n",
       "  \"num_additional_image_tokens\": 1,\n",
       "  \"patch_size\": 14,\n",
       "  \"processor_class\": \"LlavaProcessor\",\n",
       "  \"vision_feature_select_strategy\": \"default\"\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16da1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # VQAv2 dataset paths\n",
    "# ann_root = '/fs/cfar-projects/low-bit-vision/datasets/vqav2/annotations'\n",
    "# q_root = '/fs/cfar-projects/low-bit-vision/datasets/vqav2/questions'\n",
    "# image_root = '/fs/cfar-projects/low-bit-vision/datasets/vqav2/val2014'\n",
    "\n",
    "# # short answer prompting according to: https://github.com/haotian-liu/LLaVA/blob/main/docs/Evaluation.md\n",
    "llava_prompt = 'USER: <image>\\n{}\\nAnswer the question using a single word or phrase. ASSISTANT:'\n",
    "\n",
    "# dataset = VQAv2Eval(image_root=image_root,\n",
    "#                     ann_root=ann_root,\n",
    "#                     q_root=q_root,\n",
    "#                     prompt=llava_prompt)\n",
    "\n",
    "\n",
    "from dataset import GQAEval\n",
    "\n",
    "image_root = '/fs/cfar-projects/low-bit-vision/datasets/gqa/images'\n",
    "q_root = '/fs/cfar-projects/low-bit-vision/datasets/gqa/questions'\n",
    "\n",
    "dataset = GQAEval(\n",
    "        image_root,\n",
    "        q_root,\n",
    "        prompt=llava_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c4d889f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': '20300425',\n",
       " 'image': <PIL.Image.Image image mode=RGB size=500x378>,\n",
       " 'text_input': 'USER: <image>\\nWhich kind of vehicle is waiting for the traffic light?\\nAnswer the question using a single word or phrase. ASSISTANT:',\n",
       " 'gt_answer': 'cars'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=16,\n",
    "                        num_workers=1,\n",
    "                        pin_memory=False,\n",
    "                        shuffle=False,\n",
    "                        collate_fn = dataset.collater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc0bf40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlavaForConditionalGeneration(\n",
       "  (vision_tower): CLIPVisionModel(\n",
       "    (vision_model): CLIPVisionTransformer(\n",
       "      (embeddings): CLIPVisionEmbeddings(\n",
       "        (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "        (position_embedding): Embedding(577, 1024)\n",
       "      )\n",
       "      (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder): CLIPEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x CLIPEncoderLayer(\n",
       "            (self_attn): CLIPSdpaAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): CLIPMLP(\n",
       "              (activation_fn): QuickGELUActivation()\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (multi_modal_projector): LlavaMultiModalProjector(\n",
       "    (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "    (act): GELUActivation()\n",
       "    (linear_2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  )\n",
       "  (language_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(32064, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from inference_pipeline import InferencePipeline\n",
    "inferencer = InferencePipeline(model, device, processor)\n",
    "processor_kwargs = dict(padding=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a04b464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = inferencer.run_inference(\n",
    "#     dataloader,\n",
    "#     task = 'vqav2',\n",
    "#     processor_kwargs = processor_kwargs,\n",
    "#     generate_kwargs = None\n",
    "# )\n",
    "\n",
    "# results = inferencer.run_inference(\n",
    "#     dataloader,\n",
    "#     task = 'gqa',\n",
    "#     processor_kwargs = processor_kwargs,\n",
    "#     generate_kwargs = None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6505e84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 214354)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_indices = range(len(dataset))\n",
    "total_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c273e0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CALIBRATION_SIZE = 128\n",
    "calibration_indices = random.sample(total_indices, CALIBRATION_SIZE)\n",
    "\n",
    "calibration_set = [(dataset[i]['image'], dataset[i]['text_input']) for i in calibration_indices]\n",
    "len(calibration_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc3cf219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LLAVA model quantization...\n",
      "Quantizing Vision Model with 2-bit precision...\n",
      "total_layers: 144\n",
      "{'encoder.layers.0.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.0.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.0.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.0.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.0.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.0.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.1.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.1.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.1.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.1.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.1.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.1.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.2.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.2.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.2.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.2.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.2.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.2.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.3.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.3.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.3.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.3.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.3.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.3.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.4.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.4.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.4.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.4.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.4.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.4.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.5.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.5.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.5.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.5.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.5.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.5.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.6.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.6.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.6.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.6.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.6.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.6.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.7.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.7.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.7.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.7.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.7.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.7.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.8.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.8.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.8.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.8.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.8.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.8.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.9.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.9.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.9.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.9.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.9.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.9.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.10.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.10.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.10.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.10.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.10.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.10.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.11.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.11.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.11.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.11.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.11.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.11.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.12.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.12.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.12.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.12.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.12.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.12.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.13.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.13.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.13.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.13.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.13.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.13.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.14.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.14.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.14.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.14.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.14.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.14.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.15.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.15.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.15.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.15.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.15.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.15.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.16.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.16.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.16.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.16.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.16.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.16.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.17.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.17.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.17.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.17.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.17.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.17.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.18.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.18.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.18.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.18.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.18.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.18.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.19.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.19.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.19.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.19.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.19.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.19.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.20.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.20.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.20.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.20.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.20.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.20.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.21.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.21.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.21.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.21.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.21.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.21.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.22.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.22.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.22.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.22.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.22.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.22.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True), 'encoder.layers.23.self_attn.k_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.23.self_attn.v_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.23.self_attn.q_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.23.self_attn.out_proj': Linear(in_features=1024, out_features=1024, bias=True), 'encoder.layers.23.mlp.fc1': Linear(in_features=1024, out_features=4096, bias=True), 'encoder.layers.23.mlp.fc2': Linear(in_features=4096, out_features=1024, bias=True)}\n",
      "\n",
      "Processing vision model layers 0 to 31 with 2-bit precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing vision model batch: 100%|██████████| 128/128 [00:08<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer encoder.layers.0.self_attn.k_proj...\n",
      "Time for quantization: 1.72 seconds\n",
      "Total quantization error: 7536.826171875\n",
      "Quantizing layer encoder.layers.0.self_attn.v_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 5068.3720703125\n",
      "Quantizing layer encoder.layers.0.self_attn.q_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 8809.1796875\n",
      "Quantizing layer encoder.layers.0.self_attn.out_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 36.56419372558594\n",
      "Quantizing layer encoder.layers.0.mlp.fc1...\n",
      "Time for quantization: 0.30 seconds\n",
      "Total quantization error: 138271.296875\n",
      "Quantizing layer encoder.layers.0.mlp.fc2...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 801.8564453125\n",
      "Quantizing layer encoder.layers.1.self_attn.k_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 7883.9990234375\n",
      "Quantizing layer encoder.layers.1.self_attn.v_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 5601.65673828125\n",
      "Quantizing layer encoder.layers.1.self_attn.q_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 7485.513671875\n",
      "Quantizing layer encoder.layers.1.self_attn.out_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 25.986534118652344\n",
      "Quantizing layer encoder.layers.1.mlp.fc1...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 62316.61328125\n",
      "Quantizing layer encoder.layers.1.mlp.fc2...\n",
      "Time for quantization: 1.11 seconds\n",
      "Total quantization error: 755.3704223632812\n",
      "Quantizing layer encoder.layers.2.self_attn.k_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 15435.603515625\n",
      "Quantizing layer encoder.layers.2.self_attn.v_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 7931.7978515625\n",
      "Quantizing layer encoder.layers.2.self_attn.q_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 14603.431640625\n",
      "Quantizing layer encoder.layers.2.self_attn.out_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 45.67170333862305\n",
      "Quantizing layer encoder.layers.2.mlp.fc1...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 88615.875\n",
      "Quantizing layer encoder.layers.2.mlp.fc2...\n",
      "Time for quantization: 1.10 seconds\n",
      "Total quantization error: 1087.5069580078125\n",
      "Quantizing layer encoder.layers.3.self_attn.k_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 44980.125\n",
      "Quantizing layer encoder.layers.3.self_attn.v_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 10103.92578125\n",
      "Quantizing layer encoder.layers.3.self_attn.q_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 39181.890625\n",
      "Quantizing layer encoder.layers.3.self_attn.out_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 593.7203369140625\n",
      "Quantizing layer encoder.layers.3.mlp.fc1...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 84676.21875\n",
      "Quantizing layer encoder.layers.3.mlp.fc2...\n",
      "Time for quantization: 1.10 seconds\n",
      "Total quantization error: 1164.66064453125\n",
      "Quantizing layer encoder.layers.4.self_attn.k_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 29548.58203125\n",
      "Quantizing layer encoder.layers.4.self_attn.v_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 9609.4208984375\n",
      "Quantizing layer encoder.layers.4.self_attn.q_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 24242.59765625\n",
      "Quantizing layer encoder.layers.4.self_attn.out_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 182.055419921875\n",
      "Quantizing layer encoder.layers.4.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 94816.0234375\n",
      "Quantizing layer encoder.layers.4.mlp.fc2...\n",
      "Time for quantization: 1.10 seconds\n",
      "Total quantization error: 1488.71044921875\n",
      "Quantizing layer encoder.layers.5.self_attn.k_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 34231.47265625\n",
      "Quantizing layer encoder.layers.5.self_attn.v_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 12763.234375\n",
      "\n",
      "Processing vision model layers 32 to 63 with 2-bit precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing vision model batch: 100%|██████████| 128/128 [00:03<00:00, 42.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer encoder.layers.5.self_attn.q_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 30146.412109375\n",
      "Quantizing layer encoder.layers.5.self_attn.out_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 209.6897430419922\n",
      "Quantizing layer encoder.layers.5.mlp.fc1...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 137523.125\n",
      "Quantizing layer encoder.layers.5.mlp.fc2...\n",
      "Time for quantization: 1.10 seconds\n",
      "Total quantization error: 1430.869873046875\n",
      "Quantizing layer encoder.layers.6.self_attn.k_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 79953.078125\n",
      "Quantizing layer encoder.layers.6.self_attn.v_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 22287.55859375\n",
      "Quantizing layer encoder.layers.6.self_attn.q_proj...\n",
      "Time for quantization: 0.31 seconds\n",
      "Total quantization error: 58968.96875\n",
      "Quantizing layer encoder.layers.6.self_attn.out_proj...\n",
      "Time for quantization: 0.30 seconds\n",
      "Total quantization error: 850.9054565429688\n",
      "Quantizing layer encoder.layers.6.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 130215.1953125\n",
      "Quantizing layer encoder.layers.6.mlp.fc2...\n",
      "Time for quantization: 1.10 seconds\n",
      "Total quantization error: 1656.4346923828125\n",
      "Quantizing layer encoder.layers.7.self_attn.k_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 59021.7421875\n",
      "Quantizing layer encoder.layers.7.self_attn.v_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 28601.73046875\n",
      "Quantizing layer encoder.layers.7.self_attn.q_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 48874.6484375\n",
      "Quantizing layer encoder.layers.7.self_attn.out_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 515.337158203125\n",
      "Quantizing layer encoder.layers.7.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 148671.59375\n",
      "Quantizing layer encoder.layers.7.mlp.fc2...\n",
      "Time for quantization: 1.10 seconds\n",
      "Total quantization error: 2141.197265625\n",
      "Quantizing layer encoder.layers.8.self_attn.k_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 62288.75\n",
      "Quantizing layer encoder.layers.8.self_attn.v_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 30358.32421875\n",
      "Quantizing layer encoder.layers.8.self_attn.q_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 53317.671875\n",
      "Quantizing layer encoder.layers.8.self_attn.out_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 765.0619506835938\n",
      "Quantizing layer encoder.layers.8.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 164230.6875\n",
      "Quantizing layer encoder.layers.8.mlp.fc2...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 2816.334228515625\n",
      "Quantizing layer encoder.layers.9.self_attn.k_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 60985.80859375\n",
      "Quantizing layer encoder.layers.9.self_attn.v_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 29847.2421875\n",
      "Quantizing layer encoder.layers.9.self_attn.q_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 51286.03125\n",
      "Quantizing layer encoder.layers.9.self_attn.out_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 846.2679443359375\n",
      "Quantizing layer encoder.layers.9.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 170620.34375\n",
      "Quantizing layer encoder.layers.9.mlp.fc2...\n",
      "Time for quantization: 1.11 seconds\n",
      "Total quantization error: 2736.060791015625\n",
      "Quantizing layer encoder.layers.10.self_attn.k_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 62666.9375\n",
      "Quantizing layer encoder.layers.10.self_attn.v_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 31524.046875\n",
      "Quantizing layer encoder.layers.10.self_attn.q_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 55102.5390625\n",
      "Quantizing layer encoder.layers.10.self_attn.out_proj...\n",
      "Time for quantization: 0.30 seconds\n",
      "Total quantization error: 901.84130859375\n",
      "\n",
      "Processing vision model layers 64 to 95 with 2-bit precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing vision model batch: 100%|██████████| 128/128 [00:03<00:00, 40.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer encoder.layers.10.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 215141.921875\n",
      "Quantizing layer encoder.layers.10.mlp.fc2...\n",
      "Time for quantization: 1.15 seconds\n",
      "Total quantization error: 2340.267578125\n",
      "Quantizing layer encoder.layers.11.self_attn.k_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 72329.453125\n",
      "Quantizing layer encoder.layers.11.self_attn.v_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 35899.09765625\n",
      "Quantizing layer encoder.layers.11.self_attn.q_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 65553.28125\n",
      "Quantizing layer encoder.layers.11.self_attn.out_proj...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 406.91229248046875\n",
      "Quantizing layer encoder.layers.11.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 225343.96875\n",
      "Quantizing layer encoder.layers.11.mlp.fc2...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 2778.89697265625\n",
      "Quantizing layer encoder.layers.12.self_attn.k_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 68561.578125\n",
      "Quantizing layer encoder.layers.12.self_attn.v_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 33404.51171875\n",
      "Quantizing layer encoder.layers.12.self_attn.q_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 63146.9375\n",
      "Quantizing layer encoder.layers.12.self_attn.out_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 278.0452880859375\n",
      "Quantizing layer encoder.layers.12.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 222461.15625\n",
      "Quantizing layer encoder.layers.12.mlp.fc2...\n",
      "Time for quantization: 1.12 seconds\n",
      "Total quantization error: 10091.5458984375\n",
      "Quantizing layer encoder.layers.13.self_attn.k_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 71382.625\n",
      "Quantizing layer encoder.layers.13.self_attn.v_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 36280.6796875\n",
      "Quantizing layer encoder.layers.13.self_attn.q_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 67001.9375\n",
      "Quantizing layer encoder.layers.13.self_attn.out_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 310.2740478515625\n",
      "Quantizing layer encoder.layers.13.mlp.fc1...\n",
      "Time for quantization: 0.32 seconds\n",
      "Total quantization error: 205684.90625\n",
      "Quantizing layer encoder.layers.13.mlp.fc2...\n",
      "Time for quantization: 1.26 seconds\n",
      "Total quantization error: 1846.7236328125\n",
      "Quantizing layer encoder.layers.14.self_attn.k_proj...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 60569.984375\n",
      "Quantizing layer encoder.layers.14.self_attn.v_proj...\n",
      "Time for quantization: 0.31 seconds\n",
      "Total quantization error: 31290.86328125\n",
      "Quantizing layer encoder.layers.14.self_attn.q_proj...\n",
      "Time for quantization: 0.30 seconds\n",
      "Total quantization error: 57308.58984375\n",
      "Quantizing layer encoder.layers.14.self_attn.out_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 230.7410888671875\n",
      "Quantizing layer encoder.layers.14.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 222883.46875\n",
      "Quantizing layer encoder.layers.14.mlp.fc2...\n",
      "Time for quantization: 1.12 seconds\n",
      "Total quantization error: 1922.51123046875\n",
      "Quantizing layer encoder.layers.15.self_attn.k_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 53570.953125\n",
      "Quantizing layer encoder.layers.15.self_attn.v_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 31346.1015625\n",
      "Quantizing layer encoder.layers.15.self_attn.q_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 51951.453125\n",
      "Quantizing layer encoder.layers.15.self_attn.out_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 181.08407592773438\n",
      "Quantizing layer encoder.layers.15.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 259875.578125\n",
      "Quantizing layer encoder.layers.15.mlp.fc2...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 2083.7099609375\n",
      "\n",
      "Processing vision model layers 96 to 127 with 2-bit precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing vision model batch: 100%|██████████| 128/128 [00:03<00:00, 42.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer encoder.layers.16.self_attn.k_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 96940.3515625\n",
      "Quantizing layer encoder.layers.16.self_attn.v_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 61425.203125\n",
      "Quantizing layer encoder.layers.16.self_attn.q_proj...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 93793.9375\n",
      "Quantizing layer encoder.layers.16.self_attn.out_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 114.7514877319336\n",
      "Quantizing layer encoder.layers.16.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 562054.25\n",
      "Quantizing layer encoder.layers.16.mlp.fc2...\n",
      "Time for quantization: 1.11 seconds\n",
      "Total quantization error: 2076.9423828125\n",
      "Quantizing layer encoder.layers.17.self_attn.k_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 98655.75\n",
      "Quantizing layer encoder.layers.17.self_attn.v_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 63209.3671875\n",
      "Quantizing layer encoder.layers.17.self_attn.q_proj...\n",
      "Time for quantization: 0.31 seconds\n",
      "Total quantization error: 96483.15625\n",
      "Quantizing layer encoder.layers.17.self_attn.out_proj...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 77.26315307617188\n",
      "Quantizing layer encoder.layers.17.mlp.fc1...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 781201.5\n",
      "Quantizing layer encoder.layers.17.mlp.fc2...\n",
      "Time for quantization: 1.21 seconds\n",
      "Total quantization error: 3663.663330078125\n",
      "Quantizing layer encoder.layers.18.self_attn.k_proj...\n",
      "Time for quantization: 0.31 seconds\n",
      "Total quantization error: 110853.6953125\n",
      "Quantizing layer encoder.layers.18.self_attn.v_proj...\n",
      "Time for quantization: 0.32 seconds\n",
      "Total quantization error: 76915.140625\n",
      "Quantizing layer encoder.layers.18.self_attn.q_proj...\n",
      "Time for quantization: 0.32 seconds\n",
      "Total quantization error: 112623.234375\n",
      "Quantizing layer encoder.layers.18.self_attn.out_proj...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 97.75102996826172\n",
      "Quantizing layer encoder.layers.18.mlp.fc1...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 964601.375\n",
      "Quantizing layer encoder.layers.18.mlp.fc2...\n",
      "Time for quantization: 1.16 seconds\n",
      "Total quantization error: 4506.630859375\n",
      "Quantizing layer encoder.layers.19.self_attn.k_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 115003.609375\n",
      "Quantizing layer encoder.layers.19.self_attn.v_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 81111.65625\n",
      "Quantizing layer encoder.layers.19.self_attn.q_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 113607.96875\n",
      "Quantizing layer encoder.layers.19.self_attn.out_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 86.44048309326172\n",
      "Quantizing layer encoder.layers.19.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 1041932.25\n",
      "Quantizing layer encoder.layers.19.mlp.fc2...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 5255.044921875\n",
      "Quantizing layer encoder.layers.20.self_attn.k_proj...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 110170.0546875\n",
      "Quantizing layer encoder.layers.20.self_attn.v_proj...\n",
      "Time for quantization: 0.30 seconds\n",
      "Total quantization error: 87566.390625\n",
      "Quantizing layer encoder.layers.20.self_attn.q_proj...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 111702.796875\n",
      "Quantizing layer encoder.layers.20.self_attn.out_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 121.17045593261719\n",
      "Quantizing layer encoder.layers.20.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 1364214.75\n",
      "Quantizing layer encoder.layers.20.mlp.fc2...\n",
      "Time for quantization: 1.16 seconds\n",
      "Total quantization error: 5751.2216796875\n",
      "Quantizing layer encoder.layers.21.self_attn.k_proj...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 96696.6875\n",
      "Quantizing layer encoder.layers.21.self_attn.v_proj...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 87815.703125\n",
      "\n",
      "Processing vision model layers 128 to 143 with 2-bit precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing vision model batch: 100%|██████████| 128/128 [00:03<00:00, 39.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer encoder.layers.21.self_attn.q_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 142811.8125\n",
      "Quantizing layer encoder.layers.21.self_attn.out_proj...\n",
      "Time for quantization: 0.27 seconds\n",
      "Total quantization error: 400.9639892578125\n",
      "Quantizing layer encoder.layers.21.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 1575822.375\n",
      "Quantizing layer encoder.layers.21.mlp.fc2...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 9809.55859375\n",
      "Quantizing layer encoder.layers.22.self_attn.k_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 110969.3125\n",
      "Quantizing layer encoder.layers.22.self_attn.v_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 115392.4375\n",
      "Quantizing layer encoder.layers.22.self_attn.q_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 987890.5\n",
      "Quantizing layer encoder.layers.22.self_attn.out_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 301.11627197265625\n",
      "Quantizing layer encoder.layers.22.mlp.fc1...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 1003122.0625\n",
      "Quantizing layer encoder.layers.22.mlp.fc2...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 7096.63720703125\n",
      "Quantizing layer encoder.layers.23.self_attn.k_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 87967.21875\n",
      "Quantizing layer encoder.layers.23.self_attn.v_proj...\n",
      "Time for quantization: 0.28 seconds\n",
      "Total quantization error: 133565.421875\n",
      "Quantizing layer encoder.layers.23.self_attn.q_proj...\n",
      "Time for quantization: 0.30 seconds\n",
      "Total quantization error: 84975.1640625\n",
      "Quantizing layer encoder.layers.23.self_attn.out_proj...\n",
      "Time for quantization: 0.30 seconds\n",
      "Total quantization error: 249.34539794921875\n",
      "Quantizing layer encoder.layers.23.mlp.fc1...\n",
      "Time for quantization: 0.29 seconds\n",
      "Total quantization error: 422525.9375\n",
      "Quantizing layer encoder.layers.23.mlp.fc2...\n",
      "Time for quantization: 1.15 seconds\n",
      "Total quantization error: 4236.0546875\n",
      "Vision Model quantization complete.\n",
      "\n",
      "Quantizing Language Model with 6-bit precision...\n",
      "\n",
      "Processing language model layers 0 to 31 with 6-bit precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language model batch: 100%|██████████| 128/128 [00:43<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer layers.0.self_attn.q_proj...\n",
      "Time for quantization: 1.32 seconds\n",
      "Total quantization error: 2.989701747894287\n",
      "Quantizing layer layers.0.self_attn.k_proj...\n",
      "Time for quantization: 1.99 seconds\n",
      "Total quantization error: 2.831799030303955\n",
      "Quantizing layer layers.0.self_attn.v_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 0.2066064178943634\n",
      "Quantizing layer layers.0.self_attn.o_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 0.004312355071306229\n",
      "Quantizing layer layers.0.mlp.gate_proj...\n",
      "Time for quantization: 1.22 seconds\n",
      "Total quantization error: 1.2334898710250854\n",
      "Quantizing layer layers.0.mlp.up_proj...\n",
      "Time for quantization: 1.87 seconds\n",
      "Total quantization error: 1.1072502136230469\n",
      "Quantizing layer layers.0.mlp.down_proj...\n",
      "Time for quantization: 4.05 seconds\n",
      "Total quantization error: 0.009842751547694206\n",
      "Quantizing layer layers.1.self_attn.q_proj...\n",
      "Time for quantization: 2.10 seconds\n",
      "Total quantization error: 7.370405197143555\n",
      "Quantizing layer layers.1.self_attn.k_proj...\n",
      "Time for quantization: 1.74 seconds\n",
      "Total quantization error: 7.984486103057861\n",
      "Quantizing layer layers.1.self_attn.v_proj...\n",
      "Time for quantization: 1.23 seconds\n",
      "Total quantization error: 0.5757219791412354\n",
      "Quantizing layer layers.1.self_attn.o_proj...\n",
      "Time for quantization: 1.59 seconds\n",
      "Total quantization error: 0.013945920392870903\n",
      "Quantizing layer layers.1.mlp.gate_proj...\n",
      "Time for quantization: 1.22 seconds\n",
      "Total quantization error: 4.589108467102051\n",
      "Quantizing layer layers.1.mlp.up_proj...\n",
      "Time for quantization: 1.23 seconds\n",
      "Total quantization error: 3.8899872303009033\n",
      "Quantizing layer layers.1.mlp.down_proj...\n",
      "Time for quantization: 4.11 seconds\n",
      "Total quantization error: 42.539634704589844\n",
      "Quantizing layer layers.2.self_attn.q_proj...\n",
      "Time for quantization: 1.23 seconds\n",
      "Total quantization error: 26.90134048461914\n",
      "Quantizing layer layers.2.self_attn.k_proj...\n",
      "Time for quantization: 1.26 seconds\n",
      "Total quantization error: 19.149137496948242\n",
      "Quantizing layer layers.2.self_attn.v_proj...\n",
      "Time for quantization: 1.21 seconds\n",
      "Total quantization error: 3.2028112411499023\n",
      "Quantizing layer layers.2.self_attn.o_proj...\n",
      "Time for quantization: 1.23 seconds\n",
      "Total quantization error: 0.09774317592382431\n",
      "Quantizing layer layers.2.mlp.gate_proj...\n",
      "Time for quantization: 1.29 seconds\n",
      "Total quantization error: 8.7083740234375\n",
      "Quantizing layer layers.2.mlp.up_proj...\n",
      "Time for quantization: 1.19 seconds\n",
      "Total quantization error: 7.3677239418029785\n",
      "Quantizing layer layers.2.mlp.down_proj...\n",
      "Time for quantization: 3.44 seconds\n",
      "Total quantization error: 0.32798123359680176\n",
      "Quantizing layer layers.3.self_attn.q_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 74.21306610107422\n",
      "Quantizing layer layers.3.self_attn.k_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 39.04096603393555\n",
      "Quantizing layer layers.3.self_attn.v_proj...\n",
      "Time for quantization: 1.21 seconds\n",
      "Total quantization error: 8.094205856323242\n",
      "Quantizing layer layers.3.self_attn.o_proj...\n",
      "Time for quantization: 1.39 seconds\n",
      "Total quantization error: 0.048147402703762054\n",
      "Quantizing layer layers.3.mlp.gate_proj...\n",
      "Time for quantization: 1.23 seconds\n",
      "Total quantization error: 15.363450050354004\n",
      "Quantizing layer layers.3.mlp.up_proj...\n",
      "Time for quantization: 1.19 seconds\n",
      "Total quantization error: 12.84113597869873\n",
      "Quantizing layer layers.3.mlp.down_proj...\n",
      "Time for quantization: 3.77 seconds\n",
      "Total quantization error: 0.8056259155273438\n",
      "Quantizing layer layers.4.self_attn.q_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 69.60504913330078\n",
      "Quantizing layer layers.4.self_attn.k_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 39.72223663330078\n",
      "Quantizing layer layers.4.self_attn.v_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 8.469852447509766\n",
      "Quantizing layer layers.4.self_attn.o_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 0.08602683991193771\n",
      "\n",
      "Processing language model layers 32 to 63 with 6-bit precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language model batch: 100%|██████████| 128/128 [00:48<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer layers.4.mlp.gate_proj...\n",
      "Time for quantization: 2.92 seconds\n",
      "Total quantization error: 21.84815216064453\n",
      "Quantizing layer layers.4.mlp.up_proj...\n",
      "Time for quantization: 3.22 seconds\n",
      "Total quantization error: 17.30970001220703\n",
      "Quantizing layer layers.4.mlp.down_proj...\n",
      "Time for quantization: 8.32 seconds\n",
      "Total quantization error: 1.3419699668884277\n",
      "Quantizing layer layers.5.self_attn.q_proj...\n",
      "Time for quantization: 3.32 seconds\n",
      "Total quantization error: 58.1400260925293\n",
      "Quantizing layer layers.5.self_attn.k_proj...\n",
      "Time for quantization: 2.93 seconds\n",
      "Total quantization error: 47.555625915527344\n",
      "Quantizing layer layers.5.self_attn.v_proj...\n",
      "Time for quantization: 3.22 seconds\n",
      "Total quantization error: 10.853681564331055\n",
      "Quantizing layer layers.5.self_attn.o_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 0.20798379182815552\n",
      "Quantizing layer layers.5.mlp.gate_proj...\n",
      "Time for quantization: 1.22 seconds\n",
      "Total quantization error: 27.885303497314453\n",
      "Quantizing layer layers.5.mlp.up_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 22.130115509033203\n",
      "Quantizing layer layers.5.mlp.down_proj...\n",
      "Time for quantization: 3.67 seconds\n",
      "Total quantization error: 1.5060265064239502\n",
      "Quantizing layer layers.6.self_attn.q_proj...\n",
      "Time for quantization: 1.53 seconds\n",
      "Total quantization error: 90.01118469238281\n",
      "Quantizing layer layers.6.self_attn.k_proj...\n",
      "Time for quantization: 1.29 seconds\n",
      "Total quantization error: 64.48128509521484\n",
      "Quantizing layer layers.6.self_attn.v_proj...\n",
      "Time for quantization: 1.20 seconds\n",
      "Total quantization error: 16.861934661865234\n",
      "Quantizing layer layers.6.self_attn.o_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 0.268207311630249\n",
      "Quantizing layer layers.6.mlp.gate_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 36.16478729248047\n",
      "Quantizing layer layers.6.mlp.up_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 27.540023803710938\n",
      "Quantizing layer layers.6.mlp.down_proj...\n",
      "Time for quantization: 3.41 seconds\n",
      "Total quantization error: 1.9666942358016968\n",
      "Quantizing layer layers.7.self_attn.q_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 89.46115112304688\n",
      "Quantizing layer layers.7.self_attn.k_proj...\n",
      "Time for quantization: 1.12 seconds\n",
      "Total quantization error: 70.85684204101562\n",
      "Quantizing layer layers.7.self_attn.v_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 20.639238357543945\n",
      "Quantizing layer layers.7.self_attn.o_proj...\n",
      "Time for quantization: 1.15 seconds\n",
      "Total quantization error: 0.4250693917274475\n",
      "Quantizing layer layers.7.mlp.gate_proj...\n",
      "Time for quantization: 1.20 seconds\n",
      "Total quantization error: 44.569618225097656\n",
      "Quantizing layer layers.7.mlp.up_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 34.13462829589844\n",
      "Quantizing layer layers.7.mlp.down_proj...\n",
      "Time for quantization: 3.40 seconds\n",
      "Total quantization error: 2.4605703353881836\n",
      "Quantizing layer layers.8.self_attn.q_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 86.86235809326172\n",
      "Quantizing layer layers.8.self_attn.k_proj...\n",
      "Time for quantization: 1.12 seconds\n",
      "Total quantization error: 76.52308654785156\n",
      "Quantizing layer layers.8.self_attn.v_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 21.796897888183594\n",
      "Quantizing layer layers.8.self_attn.o_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 0.7182276248931885\n",
      "Quantizing layer layers.8.mlp.gate_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 47.52708435058594\n",
      "Quantizing layer layers.8.mlp.up_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 39.065330505371094\n",
      "Quantizing layer layers.8.mlp.down_proj...\n",
      "Time for quantization: 3.39 seconds\n",
      "Total quantization error: 2.9835262298583984\n",
      "Quantizing layer layers.9.self_attn.q_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 90.47483825683594\n",
      "\n",
      "Processing language model layers 64 to 95 with 6-bit precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language model batch: 100%|██████████| 128/128 [00:45<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer layers.9.self_attn.k_proj...\n",
      "Time for quantization: 1.33 seconds\n",
      "Total quantization error: 85.71088409423828\n",
      "Quantizing layer layers.9.self_attn.v_proj...\n",
      "Time for quantization: 1.21 seconds\n",
      "Total quantization error: 24.97563934326172\n",
      "Quantizing layer layers.9.self_attn.o_proj...\n",
      "Time for quantization: 1.20 seconds\n",
      "Total quantization error: 1.2394875288009644\n",
      "Quantizing layer layers.9.mlp.gate_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 51.35231018066406\n",
      "Quantizing layer layers.9.mlp.up_proj...\n",
      "Time for quantization: 1.20 seconds\n",
      "Total quantization error: 43.4822998046875\n",
      "Quantizing layer layers.9.mlp.down_proj...\n",
      "Time for quantization: 3.40 seconds\n",
      "Total quantization error: 3.4020423889160156\n",
      "Quantizing layer layers.10.self_attn.q_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 88.2155532836914\n",
      "Quantizing layer layers.10.self_attn.k_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 91.2552490234375\n",
      "Quantizing layer layers.10.self_attn.v_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 27.669450759887695\n",
      "Quantizing layer layers.10.self_attn.o_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 1.6878772974014282\n",
      "Quantizing layer layers.10.mlp.gate_proj...\n",
      "Time for quantization: 1.34 seconds\n",
      "Total quantization error: 51.82904815673828\n",
      "Quantizing layer layers.10.mlp.up_proj...\n",
      "Time for quantization: 2.86 seconds\n",
      "Total quantization error: 44.39678955078125\n",
      "Quantizing layer layers.10.mlp.down_proj...\n",
      "Time for quantization: 4.08 seconds\n",
      "Total quantization error: 3.891646385192871\n",
      "Quantizing layer layers.11.self_attn.q_proj...\n",
      "Time for quantization: 1.45 seconds\n",
      "Total quantization error: 99.66990661621094\n",
      "Quantizing layer layers.11.self_attn.k_proj...\n",
      "Time for quantization: 1.49 seconds\n",
      "Total quantization error: 91.78538513183594\n",
      "Quantizing layer layers.11.self_attn.v_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 36.9306755065918\n",
      "Quantizing layer layers.11.self_attn.o_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 1.4064407348632812\n",
      "Quantizing layer layers.11.mlp.gate_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 56.678279876708984\n",
      "Quantizing layer layers.11.mlp.up_proj...\n",
      "Time for quantization: 1.28 seconds\n",
      "Total quantization error: 50.15105438232422\n",
      "Quantizing layer layers.11.mlp.down_proj...\n",
      "Time for quantization: 3.45 seconds\n",
      "Total quantization error: 3.8708343505859375\n",
      "Quantizing layer layers.12.self_attn.q_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 106.29507446289062\n",
      "Quantizing layer layers.12.self_attn.k_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 106.59021759033203\n",
      "Quantizing layer layers.12.self_attn.v_proj...\n",
      "Time for quantization: 1.12 seconds\n",
      "Total quantization error: 37.61466979980469\n",
      "Quantizing layer layers.12.self_attn.o_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 0.9477210640907288\n",
      "Quantizing layer layers.12.mlp.gate_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 58.96004104614258\n",
      "Quantizing layer layers.12.mlp.up_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 53.08171463012695\n",
      "Quantizing layer layers.12.mlp.down_proj...\n",
      "Time for quantization: 3.45 seconds\n",
      "Total quantization error: 4.247705936431885\n",
      "Quantizing layer layers.13.self_attn.q_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 116.15562438964844\n",
      "Quantizing layer layers.13.self_attn.k_proj...\n",
      "Time for quantization: 1.16 seconds\n",
      "Total quantization error: 104.52471923828125\n",
      "Quantizing layer layers.13.self_attn.v_proj...\n",
      "Time for quantization: 1.61 seconds\n",
      "Total quantization error: 38.8678092956543\n",
      "Quantizing layer layers.13.self_attn.o_proj...\n",
      "Time for quantization: 1.62 seconds\n",
      "Total quantization error: 1.1996291875839233\n",
      "Quantizing layer layers.13.mlp.gate_proj...\n",
      "Time for quantization: 1.50 seconds\n",
      "Total quantization error: 60.3423957824707\n",
      "\n",
      "Processing language model layers 96 to 127 with 6-bit precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language model batch: 100%|██████████| 128/128 [00:46<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer layers.13.mlp.up_proj...\n",
      "Time for quantization: 1.73 seconds\n",
      "Total quantization error: 55.68977737426758\n",
      "Quantizing layer layers.13.mlp.down_proj...\n",
      "Time for quantization: 3.51 seconds\n",
      "Total quantization error: 5.318157196044922\n",
      "Quantizing layer layers.14.self_attn.q_proj...\n",
      "Time for quantization: 1.27 seconds\n",
      "Total quantization error: 106.26704406738281\n",
      "Quantizing layer layers.14.self_attn.k_proj...\n",
      "Time for quantization: 1.15 seconds\n",
      "Total quantization error: 109.53216552734375\n",
      "Quantizing layer layers.14.self_attn.v_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 38.33792495727539\n",
      "Quantizing layer layers.14.self_attn.o_proj...\n",
      "Time for quantization: 1.15 seconds\n",
      "Total quantization error: 1.5643620491027832\n",
      "Quantizing layer layers.14.mlp.gate_proj...\n",
      "Time for quantization: 1.62 seconds\n",
      "Total quantization error: 68.84748840332031\n",
      "Quantizing layer layers.14.mlp.up_proj...\n",
      "Time for quantization: 2.19 seconds\n",
      "Total quantization error: 64.00037384033203\n",
      "Quantizing layer layers.14.mlp.down_proj...\n",
      "Time for quantization: 6.13 seconds\n",
      "Total quantization error: 5.932445049285889\n",
      "Quantizing layer layers.15.self_attn.q_proj...\n",
      "Time for quantization: 3.07 seconds\n",
      "Total quantization error: 124.31282806396484\n",
      "Quantizing layer layers.15.self_attn.k_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 113.63148498535156\n",
      "Quantizing layer layers.15.self_attn.v_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 42.92724609375\n",
      "Quantizing layer layers.15.self_attn.o_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 1.751847505569458\n",
      "Quantizing layer layers.15.mlp.gate_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 77.96691131591797\n",
      "Quantizing layer layers.15.mlp.up_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 73.45317077636719\n",
      "Quantizing layer layers.15.mlp.down_proj...\n",
      "Time for quantization: 3.43 seconds\n",
      "Total quantization error: 8.775169372558594\n",
      "Quantizing layer layers.16.self_attn.q_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 144.11874389648438\n",
      "Quantizing layer layers.16.self_attn.k_proj...\n",
      "Time for quantization: 1.22 seconds\n",
      "Total quantization error: 126.98933410644531\n",
      "Quantizing layer layers.16.self_attn.v_proj...\n",
      "Time for quantization: 1.15 seconds\n",
      "Total quantization error: 50.07670593261719\n",
      "Quantizing layer layers.16.self_attn.o_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 0.8928433656692505\n",
      "Quantizing layer layers.16.mlp.gate_proj...\n",
      "Time for quantization: 1.41 seconds\n",
      "Total quantization error: 91.5534896850586\n",
      "Quantizing layer layers.16.mlp.up_proj...\n",
      "Time for quantization: 1.69 seconds\n",
      "Total quantization error: 84.37324523925781\n",
      "Quantizing layer layers.16.mlp.down_proj...\n",
      "Time for quantization: 4.18 seconds\n",
      "Total quantization error: 11.662395477294922\n",
      "Quantizing layer layers.17.self_attn.q_proj...\n",
      "Time for quantization: 1.15 seconds\n",
      "Total quantization error: 149.36753845214844\n",
      "Quantizing layer layers.17.self_attn.k_proj...\n",
      "Time for quantization: 1.24 seconds\n",
      "Total quantization error: 130.962158203125\n",
      "Quantizing layer layers.17.self_attn.v_proj...\n",
      "Time for quantization: 1.19 seconds\n",
      "Total quantization error: 54.16375732421875\n",
      "Quantizing layer layers.17.self_attn.o_proj...\n",
      "Time for quantization: 1.19 seconds\n",
      "Total quantization error: 1.1655478477478027\n",
      "Quantizing layer layers.17.mlp.gate_proj...\n",
      "Time for quantization: 1.71 seconds\n",
      "Total quantization error: 108.42695617675781\n",
      "Quantizing layer layers.17.mlp.up_proj...\n",
      "Time for quantization: 1.67 seconds\n",
      "Total quantization error: 97.18403625488281\n",
      "Quantizing layer layers.17.mlp.down_proj...\n",
      "Time for quantization: 5.13 seconds\n",
      "Total quantization error: 13.064023971557617\n",
      "Quantizing layer layers.18.self_attn.q_proj...\n",
      "Time for quantization: 1.70 seconds\n",
      "Total quantization error: 179.85853576660156\n",
      "Quantizing layer layers.18.self_attn.k_proj...\n",
      "Time for quantization: 1.72 seconds\n",
      "Total quantization error: 145.8607940673828\n",
      "\n",
      "Processing language model layers 128 to 159 with 6-bit precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language model batch: 100%|██████████| 128/128 [00:46<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer layers.18.self_attn.v_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 67.752197265625\n",
      "Quantizing layer layers.18.self_attn.o_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 1.2422922849655151\n",
      "Quantizing layer layers.18.mlp.gate_proj...\n",
      "Time for quantization: 1.23 seconds\n",
      "Total quantization error: 127.36318969726562\n",
      "Quantizing layer layers.18.mlp.up_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 111.65200805664062\n",
      "Quantizing layer layers.18.mlp.down_proj...\n",
      "Time for quantization: 3.40 seconds\n",
      "Total quantization error: 16.19788360595703\n",
      "Quantizing layer layers.19.self_attn.q_proj...\n",
      "Time for quantization: 1.79 seconds\n",
      "Total quantization error: 192.74815368652344\n",
      "Quantizing layer layers.19.self_attn.k_proj...\n",
      "Time for quantization: 1.12 seconds\n",
      "Total quantization error: 153.8065185546875\n",
      "Quantizing layer layers.19.self_attn.v_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 68.77992248535156\n",
      "Quantizing layer layers.19.self_attn.o_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 1.6653181314468384\n",
      "Quantizing layer layers.19.mlp.gate_proj...\n",
      "Time for quantization: 1.27 seconds\n",
      "Total quantization error: 138.4702911376953\n",
      "Quantizing layer layers.19.mlp.up_proj...\n",
      "Time for quantization: 1.24 seconds\n",
      "Total quantization error: 121.71914672851562\n",
      "Quantizing layer layers.19.mlp.down_proj...\n",
      "Time for quantization: 3.63 seconds\n",
      "Total quantization error: 17.684993743896484\n",
      "Quantizing layer layers.20.self_attn.q_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 192.4244384765625\n",
      "Quantizing layer layers.20.self_attn.k_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 158.15936279296875\n",
      "Quantizing layer layers.20.self_attn.v_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 70.11392211914062\n",
      "Quantizing layer layers.20.self_attn.o_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 1.5406880378723145\n",
      "Quantizing layer layers.20.mlp.gate_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 149.1056671142578\n",
      "Quantizing layer layers.20.mlp.up_proj...\n",
      "Time for quantization: 1.90 seconds\n",
      "Total quantization error: 129.33721923828125\n",
      "Quantizing layer layers.20.mlp.down_proj...\n",
      "Time for quantization: 3.47 seconds\n",
      "Total quantization error: 18.94611930847168\n",
      "Quantizing layer layers.21.self_attn.q_proj...\n",
      "Time for quantization: 1.37 seconds\n",
      "Total quantization error: 238.35638427734375\n",
      "Quantizing layer layers.21.self_attn.k_proj...\n",
      "Time for quantization: 1.26 seconds\n",
      "Total quantization error: 176.2716064453125\n",
      "Quantizing layer layers.21.self_attn.v_proj...\n",
      "Time for quantization: 1.15 seconds\n",
      "Total quantization error: 84.16791534423828\n",
      "Quantizing layer layers.21.self_attn.o_proj...\n",
      "Time for quantization: 1.25 seconds\n",
      "Total quantization error: 0.8847126960754395\n",
      "Quantizing layer layers.21.mlp.gate_proj...\n",
      "Time for quantization: 1.25 seconds\n",
      "Total quantization error: 163.19677734375\n",
      "Quantizing layer layers.21.mlp.up_proj...\n",
      "Time for quantization: 1.22 seconds\n",
      "Total quantization error: 139.49661254882812\n",
      "Quantizing layer layers.21.mlp.down_proj...\n",
      "Time for quantization: 3.44 seconds\n",
      "Total quantization error: 18.52564239501953\n",
      "Quantizing layer layers.22.self_attn.q_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 240.757080078125\n",
      "Quantizing layer layers.22.self_attn.k_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 193.0281219482422\n",
      "Quantizing layer layers.22.self_attn.v_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 90.3445816040039\n",
      "Quantizing layer layers.22.self_attn.o_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 1.543156623840332\n",
      "Quantizing layer layers.22.mlp.gate_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 168.78958129882812\n",
      "Quantizing layer layers.22.mlp.up_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 142.2694854736328\n",
      "\n",
      "Processing language model layers 160 to 191 with 6-bit precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language model batch: 100%|██████████| 128/128 [00:44<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer layers.22.mlp.down_proj...\n",
      "Time for quantization: 3.46 seconds\n",
      "Total quantization error: 17.65645980834961\n",
      "Quantizing layer layers.23.self_attn.q_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 260.3820495605469\n",
      "Quantizing layer layers.23.self_attn.k_proj...\n",
      "Time for quantization: 1.12 seconds\n",
      "Total quantization error: 196.86280822753906\n",
      "Quantizing layer layers.23.self_attn.v_proj...\n",
      "Time for quantization: 1.12 seconds\n",
      "Total quantization error: 104.8172836303711\n",
      "Quantizing layer layers.23.self_attn.o_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 1.3783042430877686\n",
      "Quantizing layer layers.23.mlp.gate_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 180.47747802734375\n",
      "Quantizing layer layers.23.mlp.up_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 154.5054473876953\n",
      "Quantizing layer layers.23.mlp.down_proj...\n",
      "Time for quantization: 3.38 seconds\n",
      "Total quantization error: 20.91553497314453\n",
      "Quantizing layer layers.24.self_attn.q_proj...\n",
      "Time for quantization: 1.12 seconds\n",
      "Total quantization error: 230.61013793945312\n",
      "Quantizing layer layers.24.self_attn.k_proj...\n",
      "Time for quantization: 1.12 seconds\n",
      "Total quantization error: 191.51058959960938\n",
      "Quantizing layer layers.24.self_attn.v_proj...\n",
      "Time for quantization: 1.12 seconds\n",
      "Total quantization error: 100.37843322753906\n",
      "Quantizing layer layers.24.self_attn.o_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 1.539262294769287\n",
      "Quantizing layer layers.24.mlp.gate_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 176.47439575195312\n",
      "Quantizing layer layers.24.mlp.up_proj...\n",
      "Time for quantization: 1.19 seconds\n",
      "Total quantization error: 150.14842224121094\n",
      "Quantizing layer layers.24.mlp.down_proj...\n",
      "Time for quantization: 3.71 seconds\n",
      "Total quantization error: 18.425758361816406\n",
      "Quantizing layer layers.25.self_attn.q_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 249.8153533935547\n",
      "Quantizing layer layers.25.self_attn.k_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 195.68783569335938\n",
      "Quantizing layer layers.25.self_attn.v_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 114.73066711425781\n",
      "Quantizing layer layers.25.self_attn.o_proj...\n",
      "Time for quantization: 1.15 seconds\n",
      "Total quantization error: 0.985366702079773\n",
      "Quantizing layer layers.25.mlp.gate_proj...\n",
      "Time for quantization: 1.20 seconds\n",
      "Total quantization error: 188.82435607910156\n",
      "Quantizing layer layers.25.mlp.up_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 160.66192626953125\n",
      "Quantizing layer layers.25.mlp.down_proj...\n",
      "Time for quantization: 3.69 seconds\n",
      "Total quantization error: 19.751079559326172\n",
      "Quantizing layer layers.26.self_attn.q_proj...\n",
      "Time for quantization: 1.19 seconds\n",
      "Total quantization error: 277.21923828125\n",
      "Quantizing layer layers.26.self_attn.k_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 199.06280517578125\n",
      "Quantizing layer layers.26.self_attn.v_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 115.04022216796875\n",
      "Quantizing layer layers.26.self_attn.o_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 3.0137643814086914\n",
      "Quantizing layer layers.26.mlp.gate_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 181.84329223632812\n",
      "Quantizing layer layers.26.mlp.up_proj...\n",
      "Time for quantization: 1.18 seconds\n",
      "Total quantization error: 156.48687744140625\n",
      "Quantizing layer layers.26.mlp.down_proj...\n",
      "Time for quantization: 3.39 seconds\n",
      "Total quantization error: 17.526222229003906\n",
      "Quantizing layer layers.27.self_attn.q_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 292.4416809082031\n",
      "Quantizing layer layers.27.self_attn.k_proj...\n",
      "Time for quantization: 1.20 seconds\n",
      "Total quantization error: 183.27902221679688\n",
      "Quantizing layer layers.27.self_attn.v_proj...\n",
      "Time for quantization: 1.24 seconds\n",
      "Total quantization error: 108.62908935546875\n",
      "\n",
      "Processing language model layers 192 to 223 with 6-bit precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language model batch: 100%|██████████| 128/128 [00:44<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing layer layers.27.self_attn.o_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 1.2542890310287476\n",
      "Quantizing layer layers.27.mlp.gate_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 191.4755096435547\n",
      "Quantizing layer layers.27.mlp.up_proj...\n",
      "Time for quantization: 1.23 seconds\n",
      "Total quantization error: 166.24130249023438\n",
      "Quantizing layer layers.27.mlp.down_proj...\n",
      "Time for quantization: 3.39 seconds\n",
      "Total quantization error: 19.493118286132812\n",
      "Quantizing layer layers.28.self_attn.q_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 332.40203857421875\n",
      "Quantizing layer layers.28.self_attn.k_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 185.15736389160156\n",
      "Quantizing layer layers.28.self_attn.v_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 117.61782836914062\n",
      "Quantizing layer layers.28.self_attn.o_proj...\n",
      "Time for quantization: 1.12 seconds\n",
      "Total quantization error: 1.7196297645568848\n",
      "Quantizing layer layers.28.mlp.gate_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 190.54931640625\n",
      "Quantizing layer layers.28.mlp.up_proj...\n",
      "Time for quantization: 1.19 seconds\n",
      "Total quantization error: 170.57394409179688\n",
      "Quantizing layer layers.28.mlp.down_proj...\n",
      "Time for quantization: 3.39 seconds\n",
      "Total quantization error: 21.602191925048828\n",
      "Quantizing layer layers.29.self_attn.q_proj...\n",
      "Time for quantization: 1.12 seconds\n",
      "Total quantization error: 310.69635009765625\n",
      "Quantizing layer layers.29.self_attn.k_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 171.73776245117188\n",
      "Quantizing layer layers.29.self_attn.v_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 105.93821716308594\n",
      "Quantizing layer layers.29.self_attn.o_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 2.1055049896240234\n",
      "Quantizing layer layers.29.mlp.gate_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 191.65054321289062\n",
      "Quantizing layer layers.29.mlp.up_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 173.7242431640625\n",
      "Quantizing layer layers.29.mlp.down_proj...\n",
      "Time for quantization: 3.45 seconds\n",
      "Total quantization error: 27.428131103515625\n",
      "Quantizing layer layers.30.self_attn.q_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 405.4654235839844\n",
      "Quantizing layer layers.30.self_attn.k_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 173.12855529785156\n",
      "Quantizing layer layers.30.self_attn.v_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 119.32344055175781\n",
      "Quantizing layer layers.30.self_attn.o_proj...\n",
      "Time for quantization: 1.13 seconds\n",
      "Total quantization error: 2.7953596115112305\n",
      "Quantizing layer layers.30.mlp.gate_proj...\n",
      "Time for quantization: 1.23 seconds\n",
      "Total quantization error: 201.66592407226562\n",
      "Quantizing layer layers.30.mlp.up_proj...\n",
      "Time for quantization: 1.17 seconds\n",
      "Total quantization error: 176.90870666503906\n",
      "Quantizing layer layers.30.mlp.down_proj...\n",
      "Time for quantization: 3.66 seconds\n",
      "Total quantization error: 53.23955535888672\n",
      "Quantizing layer layers.31.self_attn.q_proj...\n",
      "Time for quantization: 1.15 seconds\n",
      "Total quantization error: 168.50360107421875\n",
      "Quantizing layer layers.31.self_attn.k_proj...\n",
      "Time for quantization: 1.19 seconds\n",
      "Total quantization error: 144.22125244140625\n",
      "Quantizing layer layers.31.self_attn.v_proj...\n",
      "Time for quantization: 1.14 seconds\n",
      "Total quantization error: 71.99061584472656\n",
      "Quantizing layer layers.31.self_attn.o_proj...\n",
      "Time for quantization: 1.21 seconds\n",
      "Total quantization error: 7.958558082580566\n",
      "Quantizing layer layers.31.mlp.gate_proj...\n",
      "Time for quantization: 1.25 seconds\n",
      "Total quantization error: 181.67929077148438\n",
      "Quantizing layer layers.31.mlp.up_proj...\n",
      "Time for quantization: 1.52 seconds\n",
      "Total quantization error: 163.659912109375\n",
      "Quantizing layer layers.31.mlp.down_proj...\n",
      "Time for quantization: 3.43 seconds\n",
      "Total quantization error: 156.51048278808594\n",
      "Language Model quantization complete.\n",
      "\n",
      "LLAVA model quantization complete.\n",
      "Elapsed time: 827.1064443588257\n"
     ]
    }
   ],
   "source": [
    "quantizer = LlavaQuantizer(model, processor, device)\n",
    "\n",
    "quantizer.config = {\n",
    "    \"vision\": {\n",
    "        \"bits\": 2,\n",
    "        \"percent_dampening\": 0.01,\n",
    "        \"group_size\": -1,\n",
    "        \"use_symmetric\": True,\n",
    "        \"use_act_order\": False,\n",
    "        \"use_static_groups\": False,\n",
    "    },\n",
    "    \"language\": {\n",
    "        \"bits\": 6,\n",
    "        \"percent_dampening\": 0.01,\n",
    "        \"group_size\": -1,\n",
    "        \"use_symmetric\": True,\n",
    "        \"use_act_order\": False,\n",
    "        \"use_static_groups\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "# quantizer.quantize_vision_model(calibration_set)\n",
    "# quantizer.quantize_language_model(calibration_set)\n",
    "\n",
    "start_time = time.time()\n",
    "quantizer.quantize(calibration_set)\n",
    "\n",
    "print(f'Elapsed time: {time.time() - start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77f17f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: <image>\n",
      "How is the clothing item that is pink called?\n",
      "Answer the question using a single word or phrase. ASSISTANT:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['USER: \\nHow is the clothing item that is pink called?\\nAnswer the question using a single word or phrase. ASSISTANT: Tank top']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = dataset[42]['image']\n",
    "# prompt = 'USER: <image>\\n' + dataset.qa_pairs[42]['question'] + '\\nAnswer the question using a single word or phrase. ASSISTANT:'\n",
    "\n",
    "prompt = dataset[42]['text_input']\n",
    "print(prompt)\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "# set this according to huggingface usage tips: https://huggingface.co/docs/transformers/en/model_doc/llava\n",
    "processor.tokenizer.padding_side = \"left\"\n",
    "samples = processor(images = [img],\n",
    "                     text=[prompt],\n",
    "                     return_tensors='pt',\n",
    "                     padding=True).to(model.device)\n",
    "\n",
    "# Generate\n",
    "# generate_ids = model.generate(**inputs, max_new_tokens=30)\n",
    "generate_ids = model.generate(**samples, max_new_tokens=30)\n",
    "output = processor.batch_decode(generate_ids, skip_special_tokens=True)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de6c18ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tank top'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].split('ASSISTANT: ')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68090ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': '201974971',\n",
       " 'image': <PIL.Image.Image image mode=RGB size=640x427>,\n",
       " 'text_input': 'USER: <image>\\nHow is the clothing item that is pink called?\\nAnswer the question using a single word or phrase. ASSISTANT:',\n",
       " 'gt_answer': 'tank top'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[42]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
