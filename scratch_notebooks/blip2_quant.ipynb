{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2252dab7-667f-454b-bba1-6a75f57aec63",
   "metadata": {},
   "source": [
    "# Blip2 COCO Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f543991-f107-4ae1-9988-ec55ff36af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "from datasets import COCODataset\n",
    "from datasets import COCODataset\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load BLIP-2 model and processor\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "\n",
    "# Ensure the model is on the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "# Load COCO dataset\n",
    "coco_dataset = COCODataset(\n",
    "    ann_file=\"./data/coco/annotations/captions_val2017.json\",\n",
    "    img_dir=\"./data/coco/val2017\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36001a9a-7ab2-4978-bd25-5bfacb1b7db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coco_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415eff56-a416-4709-8edc-241d21cc59db",
   "metadata": {},
   "source": [
    "## nbitlineardynamic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad2dd8-dd6d-4a40-99a8-e206180b3dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nbitlinear.py\n",
    "\"\"\"\n",
    "\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def quant(x: Tensor, num_bits):\n",
    "    min_val = x.min(dim=-1).values.unsqueeze(-1)\n",
    "    max_val = x.max(dim=-1).values.unsqueeze(-1)\n",
    "\n",
    "    alpha = max_val - min_val\n",
    "    x = (x - min_val) / alpha\n",
    "\n",
    "    scale = 2**num_bits - 1\n",
    "    result = (scale * x).round()\n",
    "    result /= scale\n",
    "\n",
    "    result = alpha * result + min_val\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class NBitLinearDynamic(nn.Linear):\n",
    "    def __init__(self, *kargs, weight_bits=8, activation_bits=8, **kwargs):\n",
    "        super().__init__(*kargs, **kwargs)\n",
    "        self.weight_bits = weight_bits\n",
    "        self.activation_bits = activation_bits\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        w = self.weight\n",
    "        b = self.bias\n",
    "\n",
    "        x_quant = x + (quant(x, self.activation_bits) - x).detach()\n",
    "        w_quant = w + (quant(w, self.weight_bits) - w).detach()\n",
    "\n",
    "        if b != None:\n",
    "            b = b + (quant(b, self.weight_bits) - b).detach()\n",
    "\n",
    "        y = F.linear(x_quant, w_quant, bias=b)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return super().extra_repr() + f\" | w={self.weight_bits}, a={self.activation_bits}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a44237-7b38-4309-8744-f7594e071e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def quant(x: Tensor, num_bits):\n",
    "    min_val = x.min(dim=-1).values.unsqueeze(-1)\n",
    "    max_val = x.max(dim=-1).values.unsqueeze(-1)\n",
    "\n",
    "    alpha = max_val - min_val\n",
    "    x = (x - min_val) / alpha\n",
    "\n",
    "    scale = 2**num_bits - 1\n",
    "    result = (scale * x).round()\n",
    "    result /= scale\n",
    "\n",
    "    result = alpha * result + min_val\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def test_quantization():\n",
    "    # Create a sample tensor\n",
    "    torch.manual_seed(0)  # for reproducibility\n",
    "    x = torch.randn(1, 100)  # 1x100 tensor of random values\n",
    "\n",
    "    # Test different bit sizes\n",
    "    bit_sizes = [1, 2, 4, 8]\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(len(bit_sizes) + 1, 1, 1)\n",
    "    plt.plot(x.squeeze().numpy())\n",
    "    plt.title(\"Original Data\")\n",
    "\n",
    "    for i, bits in enumerate(bit_sizes):\n",
    "        quantized = quant(x, bits)\n",
    "\n",
    "        plt.subplot(len(bit_sizes) + 1, 1, i + 2)\n",
    "        plt.plot(quantized.squeeze().numpy())\n",
    "        plt.title(f\"{bits}-bit Quantization\")\n",
    "\n",
    "        print(f\"\\n{bits}-bit Quantization:\")\n",
    "        print(\"Min value:\", quantized.min().item())\n",
    "        print(\"Max value:\", quantized.max().item())\n",
    "        print(\"Unique values:\", torch.unique(quantized).numel())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "test_quantization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6aee40-9522-4a06-b259-860af4dfdc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nbitlinear.py\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def quant(x: Tensor, num_bits):\n",
    "    min_val = x.min()\n",
    "    max_val = x.max()\n",
    "\n",
    "    alpha = max_val - min_val\n",
    "    x = (x - min_val) / alpha\n",
    "\n",
    "    scale = 2**num_bits - 1\n",
    "    result = (scale * x).round()\n",
    "    result /= scale\n",
    "\n",
    "    result = alpha * result + min_val\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class NBitLinearDynamic(nn.Linear):\n",
    "    def __init__(self, *args, weight_bits=8, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.weight_bits = weight_bits\n",
    "\n",
    "        # Pre-compute quantized weights and biases\n",
    "        self.register_buffer(\"weight_quant\", quant(self.weight, self.weight_bits))\n",
    "        if self.bias is not None:\n",
    "            self.register_buffer(\"bias_quant\", quant(self.bias, self.weight_bits))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        y = F.linear(\n",
    "            x,\n",
    "            self.weight_quant,\n",
    "            bias=self.bias_quant if self.bias is not None else None,\n",
    "        )\n",
    "        return y\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return super().extra_repr() + f\" | w={self.weight_bits}\"\n",
    "\n",
    "\n",
    "def replace_linear_with_quantized(model: nn.Module, weight_bits: int = 2) -> nn.Module:\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            quantized_linear = NBitLinearDynamic(\n",
    "                in_features=module.in_features,\n",
    "                out_features=module.out_features,\n",
    "                bias=module.bias is not None,\n",
    "                weight_bits=weight_bits,\n",
    "            )\n",
    "\n",
    "            # Copy the weights and bias\n",
    "            quantized_linear.weight.data = module.weight.data\n",
    "            if module.bias is not None:\n",
    "                quantized_linear.bias.data = module.bias.data\n",
    "\n",
    "            # Replace the original linear layer with the quantized version\n",
    "            setattr(model, name, quantized_linear)\n",
    "        elif isinstance(module, nn.Module):\n",
    "            # Recursively apply to child modules\n",
    "            setattr(model, name, replace_linear_with_quantized(module, weight_bits))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_quantization():\n",
    "    # Create a sample tensor\n",
    "    torch.manual_seed(1)  # for reproducibility\n",
    "    x = torch.randn(1, 100000)  # 1x100 tensor of random values\n",
    "\n",
    "    # Test different bit sizes\n",
    "    bit_sizes = [1, 2, 4, 8]\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(len(bit_sizes) + 1, 1, 1)\n",
    "    plt.plot(x.squeeze().numpy())\n",
    "    plt.title(\"Original Data\")\n",
    "\n",
    "    for i, bits in enumerate(bit_sizes):\n",
    "        quantized = quant(x, bits)\n",
    "\n",
    "        plt.subplot(len(bit_sizes) + 1, 1, i + 2)\n",
    "        plt.plot(quantized.squeeze().numpy())\n",
    "        plt.title(f\"{bits}-bit Quantization\")\n",
    "\n",
    "        print(f\"\\n{bits}-bit Quantization:\")\n",
    "        print(\"Min value:\", quantized.min().item())\n",
    "        print(\"Max value:\", quantized.max().item())\n",
    "        print(\"Unique values:\", torch.unique(quantized).numel())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "test_quantization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db23de-6673-4a6d-9358-f42b303286b3",
   "metadata": {},
   "source": [
    "## quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8123021-311a-4828-9232-2c4c1fc86efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Union, Tuple\n",
    "\n",
    "\n",
    "def replace_linear_with_quantized(model: nn.Module, weight_bits: int = 8, activation_bits: int = 8) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Replaces nn.Linear layers in a PyTorch model with NBitLinearDynamic layers.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to modify.\n",
    "        weight_bits (int): Number of bits for weight quantization. Default is 8.\n",
    "        activation_bits (int): Number of bits for activation quantization. Default is 8.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: The modified model with quantized linear layers.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            quantized_linear = NBitLinearDynamic(\n",
    "                in_features=module.in_features,\n",
    "                out_features=module.out_features,\n",
    "                bias=module.bias is not None,\n",
    "                weight_bits=weight_bits,\n",
    "                activation_bits=activation_bits,\n",
    "            )\n",
    "\n",
    "            # Copy the weights and bias\n",
    "            quantized_linear.weight.data = module.weight.data\n",
    "            if module.bias is not None:\n",
    "                quantized_linear.bias.data = module.bias.data\n",
    "\n",
    "            # Replace the original linear layer with the quantized version\n",
    "            setattr(model, name, quantized_linear)\n",
    "        elif isinstance(module, nn.Module):\n",
    "            # Recursively apply to child modules\n",
    "            setattr(\n",
    "                model,\n",
    "                name,\n",
    "                replace_linear_with_quantized(module, weight_bits, activation_bits),\n",
    "            )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd09ab-236b-4ebc-9a5b-d8158c64a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = replace_linear_with_quantized(model, weight_bits=8, activation_bits=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c57227e-4ed7-4776-821e-b3222b46dd68",
   "metadata": {},
   "source": [
    "## Collect Inference Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe866692-f447-431f-8e3d-2a37df47f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def eval_model(qmodel, results_file=\"./results/inference.json\"):\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(0, min(50, len(coco_dataset)))):\n",
    "        image, _ = coco_dataset[i]\n",
    "        \n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "            out = qmodel.generate(**inputs)\n",
    "\n",
    "        caption = processor.decode(out[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        image_id = coco_dataset.ids[i]\n",
    "        results.append({\"image_id\": image_id, \"caption\": caption})\n",
    "\n",
    "    with open(results_file, \"w\") as f:\n",
    "        json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135160e1-d3ce-4ff1-b430-a02a736ad0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e74f15b-7a2f-428e-aec8-32924e4d6a50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_model(model, results_file=\"./results/inference_regular.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb567de4-631e-47c3-943a-3dc29ba77dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "\n",
    "\n",
    "class SimpleCIDErEval:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = PTBTokenizer()\n",
    "        self.cider_scorer = Cider()\n",
    "\n",
    "    def evaluate(self, predictions, references):\n",
    "        # Format the input for the tokenizer\n",
    "        gts = {i: [{\"caption\": c} for c in refs] for i, refs in enumerate(references)}\n",
    "        res = {i: [{\"caption\": p}] for i, p in enumerate(predictions)}\n",
    "\n",
    "        # Tokenize\n",
    "        gts_tokenized = self.tokenizer.tokenize(gts)\n",
    "        res_tokenized = self.tokenizer.tokenize(res)\n",
    "\n",
    "        # Compute CIDEr score\n",
    "        score, scores = self.cider_scorer.compute_score(gts_tokenized, res_tokenized)\n",
    "\n",
    "        return score, scores\n",
    "\n",
    "\n",
    "def score_results(results_file=\"./results/inference.json\"):\n",
    "    f = open(results_file)\n",
    "    results = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    candidates = [result[\"caption\"] for result in results]\n",
    "    references = [coco_dataset.get_captions(result[\"image_id\"]) for result in results]\n",
    "\n",
    "    # Create evaluator\n",
    "    evaluator = SimpleCIDErEval()\n",
    "\n",
    "    overall_score, individual_scores = evaluator.evaluate(candidates, references)\n",
    "\n",
    "    print(f\"Overall CIDEr score: {overall_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a316e4d3-5111-440b-81c2-6150b24d038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_results(\"./results/inference.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a0e1e8-b182-4e4c-a0ab-b4f9b3d462f3",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8fdbf6-c726-45d5-8bbe-61516f4ecc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9365a6f-22fb-4373-927c-cb13859dabd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./results/coco_results.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff17880-b275-413c-af04-e4cac6f4ef9c",
   "metadata": {},
   "source": [
    "## Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a309c82-1bdc-4529-ab93-d5b50fc51bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pycocoevalfolder\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the current directory to the Python path\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "\n",
    "# Verify the path\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d523f9-0926-42e0-b15a-3d95a43b9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocoevalcap.tokenizer.ptbtokenizer import PTBTokenizer\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "\n",
    "\n",
    "class SimpleCIDErEval:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = PTBTokenizer()\n",
    "        self.cider_scorer = Cider()\n",
    "\n",
    "    def evaluate(self, predictions, references):\n",
    "        # Format the input for the tokenizer\n",
    "        gts = {i: [{\"caption\": c} for c in refs] for i, refs in enumerate(references)}\n",
    "        res = {i: [{\"caption\": p}] for i, p in enumerate(predictions)}\n",
    "\n",
    "        # Tokenize\n",
    "        gts_tokenized = self.tokenizer.tokenize(gts)\n",
    "        res_tokenized = self.tokenizer.tokenize(res)\n",
    "\n",
    "        # Compute CIDEr score\n",
    "        score, scores = self.cider_scorer.compute_score(gts_tokenized, res_tokenized)\n",
    "\n",
    "        return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a93018-94ff-4b9b-9eba-b3dc01d9635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dataset = COCODataset(\n",
    "    ann_file=\"./data/coco/annotations/captions_val2017.json\",\n",
    "    img_dir=\"./data/coco/val2017\",\n",
    ")\n",
    "\n",
    "f = open(\"./results/coco_results.json\")\n",
    "results = json.load(f)\n",
    "f.close()\n",
    "\n",
    "candidates = [result[\"caption\"] for result in results]\n",
    "references = [coco_dataset.get_captions(result[\"image_id\"]) for result in results]\n",
    "\n",
    "# Create evaluator\n",
    "evaluator = SimpleCIDErEval()\n",
    "\n",
    "overall_score, individual_scores = evaluator.evaluate(candidates, references)\n",
    "\n",
    "print(f\"Overall CIDEr score: {overall_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4533abd-f500-41be-b054-ca93072fc93b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cidereval import cider\n",
    "\n",
    "cider_scores = cider(candidates, references)\n",
    "\n",
    "print(f\"Average CIDEr score: {cider_scores['avg_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f74bbf-5aac-4172-9b22-47ec603f94c3",
   "metadata": {},
   "source": [
    "## Replace and test replacement for BLIP-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e304ed3-e8d7-4784-94bd-19a1da82c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Union, Tuple\n",
    "\n",
    "\n",
    "def replace_linear_with_quantized(model: nn.Module, weight_bits: int = 8, activation_bits: int = 8) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Replaces nn.Linear layers in a PyTorch model with NBitLinearDynamic layers.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to modify.\n",
    "        weight_bits (int): Number of bits for weight quantization. Default is 8.\n",
    "        activation_bits (int): Number of bits for activation quantization. Default is 8.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: The modified model with quantized linear layers.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            quantized_linear = NBitLinearDynamic(\n",
    "                in_features=module.in_features,\n",
    "                out_features=module.out_features,\n",
    "                bias=module.bias is not None,\n",
    "                weight_bits=weight_bits,\n",
    "                activation_bits=activation_bits,\n",
    "            )\n",
    "\n",
    "            # Copy the weights and bias\n",
    "            quantized_linear.weight.data = module.weight.data\n",
    "            if module.bias is not None:\n",
    "                quantized_linear.bias.data = module.bias.data\n",
    "\n",
    "            # Replace the original linear layer with the quantized version\n",
    "            setattr(model, name, quantized_linear)\n",
    "        elif isinstance(module, nn.Module):\n",
    "            # Recursively apply to child modules\n",
    "            setattr(\n",
    "                model,\n",
    "                name,\n",
    "                replace_linear_with_quantized(module, weight_bits, activation_bits),\n",
    "            )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7817eb0-e1d7-4b7c-8b73-c681fb9f3101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a PyTorch model called 'my_model'\n",
    "quantized_model = replace_linear_with_quantized(model, weight_bits=16, activation_bits=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1629218a-ea53-4687-93b0-b3a846273c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb85c89-2e09-4231-95a0-d1990e0b2168",
   "metadata": {},
   "source": [
    "### Taken from nbitlineardynamic.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22289e5e-05d3-4b5c-8002-bce31ec61758",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nbitlinear.py\n",
    "'''\n",
    "\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def quant(x: Tensor, num_bits):\n",
    "    min_val = x.min(dim=-1).values.unsqueeze(-1)\n",
    "    max_val = x.max(dim=-1).values.unsqueeze(-1)\n",
    "\n",
    "    alpha = max_val - min_val\n",
    "    x = (x - min_val) / alpha\n",
    "\n",
    "    scale = 2**num_bits - 1\n",
    "    result = (scale * x).round()\n",
    "    result /= scale\n",
    "\n",
    "    result = alpha * result + min_val\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class NBitLinearDynamic(nn.Linear):\n",
    "    def __init__(self, *kargs, weight_bits=8, activation_bits=8, **kwargs):\n",
    "        super().__init__(*kargs, **kwargs)\n",
    "        self.weight_bits = weight_bits\n",
    "        self.activation_bits = activation_bits\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        w = self.weight\n",
    "        b = self.bias\n",
    "\n",
    "        x_quant = x + (quant(x, self.activation_bits) - x).detach()\n",
    "        w_quant = w + (quant(w, self.weight_bits) - w).detach()\n",
    "\n",
    "        if b != None:\n",
    "            b = b + (quant(b, self.weight_bits) - b).detach()\n",
    "\n",
    "        y = F.linear(x_quant, w_quant, bias=b)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return super().extra_repr() + f\" | w={self.weight_bits}, a={self.activation_bits}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81df77-8aad-43ac-bd98-78ab9a38ba01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
