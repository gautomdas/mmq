{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration, AutoProcessor, Blip2ForImageTextRetrieval\n",
    "from dataset import COCODataset\n",
    "from awq.quantizer import Blip2ForConditionalGenerationAWQQuantizer\n",
    "from inference_pipeline import InferencePipeline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWQ Blip-2 Caption Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd590ab2806b48a4bced4f5f2479a7e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSalesforce/blip2-opt-2.7b\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m Blip2ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m processor \u001b[38;5;241m=\u001b[39m Blip2Processor\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# NOTE: set paths as appropriate\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Will sample n_samples from dataset to create calibration set\u001b[39;00m\n",
      "File \u001b[0;32m/fs/nexus-scratch/vla/micromamba/envs/MMQ/lib/python3.10/site-packages/transformers/modeling_utils.py:2920\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2915\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2916\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2917\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2918\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2919\u001b[0m         )\n\u001b[0;32m-> 2920\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/fs/nexus-scratch/vla/micromamba/envs/MMQ/lib/python3.10/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/fs/nexus-scratch/vla/micromamba/envs/MMQ/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/fs/nexus-scratch/vla/micromamba/envs/MMQ/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 780 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m/fs/nexus-scratch/vla/micromamba/envs/MMQ/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/fs/nexus-scratch/vla/micromamba/envs/MMQ/lib/python3.10/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/fs/nexus-scratch/vla/micromamba/envs/MMQ/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SETUP\n",
    "model_name = \"Salesforce/blip2-opt-2.7b\"\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "\n",
    "processor = Blip2Processor.from_pretrained(model_name)\n",
    "\n",
    "# NOTE: set paths as appropriate\n",
    "# Will sample n_samples from dataset to create calibration set\n",
    "coco_dataset = COCODataset(ann_file='/nfshomes/vla/project_dirs/low-bit-vision/datasets/cocow/annotations/captions_val2017.json',\n",
    "                           img_dir='/nfshomes/vla/project_dirs/low-bit-vision/datasets/cocow/images/val2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]Expanding inputs for image tokens in BLIP-2 should be done in processing. Please follow instruction here (https://gist.github.com/zucchini-nlp/e9f20b054fa322f84ac9311d9ab67042) to update your BLIP-2 model. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'image_id': 397133,\n",
       "   'caption': 'a woman in a kitchen with a man in a kitchen'}],\n",
       " 'references': [['A man is in a kitchen making pizzas.',\n",
       "   'Man in apron standing on front of oven with pans and bakeware',\n",
       "   'A baker is working in the kitchen rolling dough.',\n",
       "   'A person standing by a stove in a kitchen.',\n",
       "   'A table with pies being made and a person standing near a wall with pots and pans hanging on the wall.']]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = InferencePipeline(model, device, processor)\n",
    "results = pipeline.run_inference(coco_dataset, task = 'image_captioning', max_samples = 1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample config, load from JSON or smth\n",
    "# model_part: bit_width\n",
    "\n",
    "config = {}\n",
    "config['vit_layers'] = {\n",
    "    'self_attn': 4,\n",
    "    'self_attn_output':4,\n",
    "    'fc1': 4,\n",
    "    'fc2': 4,\n",
    "}\n",
    "\n",
    "# config['qformer_layers'] = {\n",
    "#     'self_attn': 4,\n",
    "#     'self_attn_output':4,\n",
    "#     'intermediate_query':4,\n",
    "#     'output_query': 4,\n",
    "#     'cross_attn': 4,\n",
    "#     'cross_attn_output': 4\n",
    "# }\n",
    "\n",
    "config['llm_layers'] = {\n",
    "    'self_attn': 4,\n",
    "    'self_attn_output':4,\n",
    "    'fc1':4,\n",
    "    'fc2':4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantizing vit_layers: 100%|██████████| 39/39 [05:08<00:00,  7.90s/it]\n",
      "Quantizing llm_layers: 100%|██████████| 32/32 [05:30<00:00, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization time: 647.47 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply AWQ\n",
    "quantizer = Blip2ForConditionalGenerationAWQQuantizer(model, device, processor, coco_dataset, config)\n",
    "\n",
    "start = time.time()\n",
    "quantizer.quantize()\n",
    "print(f'Quantization time: {time.time() - start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'image_id': 397133,\n",
       "   'caption': 'a woman standing in a kitchen with pots and pans on the counter'}],\n",
       " 'references': [['A man is in a kitchen making pizzas.',\n",
       "   'Man in apron standing on front of oven with pans and bakeware',\n",
       "   'A baker is working in the kitchen rolling dough.',\n",
       "   'A person standing by a stove in a kitchen.',\n",
       "   'A table with pies being made and a person standing near a wall with pots and pans hanging on the wall.']]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE:make sure to move model back to device, quantizing moves layers around to save memory \n",
    "model.to(device)\n",
    "pipeline = InferencePipeline(model, device, processor)\n",
    "results = pipeline.run_inference(coco_dataset, task = 'image_captioning', max_samples = 1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantizing vit_layers: 100%|██████████| 39/39 [05:02<00:00,  7.77s/it]\n",
      "Quantizing qformer_layers: 100%|██████████| 12/12 [00:19<00:00,  1.58s/it]\n",
      "Quantizing llm_layers: 100%|██████████| 32/32 [05:28<00:00, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization time: 658.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE: below ran quantizing all parts to 4-bit, i.e config['qformer_layers'] also provided\n",
    "# NOTE: full AWQ quantization at 4 bits still seems to degrade captions to garbage\n",
    "\n",
    "\n",
    "config = {}\n",
    "config['vit_layers'] = {\n",
    "    'self_attn': 4,\n",
    "    'self_attn_output':4,\n",
    "    'fc1': 4,\n",
    "    'fc2': 4,\n",
    "}\n",
    "\n",
    "config['qformer_layers'] = {\n",
    "    'self_attn': 4,\n",
    "    'self_attn_output':4,\n",
    "    'intermediate_query':4,\n",
    "    'output_query': 4,\n",
    "    'cross_attn': 4,\n",
    "    'cross_attn_output': 4\n",
    "}\n",
    "\n",
    "config['llm_layers'] = {\n",
    "    'self_attn': 4,\n",
    "    'self_attn_output':4,\n",
    "    'fc1':4,\n",
    "    'fc2':4\n",
    "}\n",
    "\n",
    "# Apply AWQ\n",
    "quantizer = Blip2ForConditionalGenerationAWQQuantizer(model, device, processor, coco_dataset, config)\n",
    "\n",
    "start = time.time()\n",
    "quantizer.quantize()\n",
    "print(f'Quantization time: {time.time() - start:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'image_id': 397133, 'caption': 'K, and thes.'}],\n",
       " 'references': [['A man is in a kitchen making pizzas.',\n",
       "   'Man in apron standing on front of oven with pans and bakeware',\n",
       "   'A baker is working in the kitchen rolling dough.',\n",
       "   'A person standing by a stove in a kitchen.',\n",
       "   'A table with pies being made and a person standing near a wall with pots and pans hanging on the wall.']]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE:make sure to move model back to device, quantizing moves layers around to save memory \n",
    "model.to(device)\n",
    "pipeline = InferencePipeline(model, device, processor)\n",
    "results = pipeline.run_inference(coco_dataset, task = 'image_captioning', max_samples = 1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWQ Blip-2 Info-Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Salesforce/blip2-itm-vit-g\"\n",
    "model = Blip2ForImageTextRetrieval.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blip2ForImageTextRetrieval(\n",
       "  (vision_model): Blip2VisionModel(\n",
       "    (embeddings): Blip2VisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "    )\n",
       "    (encoder): Blip2Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-38): 39 x Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (embeddings): Blip2TextEmbeddings(\n",
       "    (word_embeddings): Embedding(30523, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "  )\n",
       "  (qformer): Blip2QFormerModel(\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (encoder): Blip2QFormerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vision_projection): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (text_projection): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (itm_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['vit_layers'] = {\n",
    "    'self_attn': 4,\n",
    "    'self_attn_output':4,\n",
    "    'fc1': 4,\n",
    "    'fc2': 4,\n",
    "}\n",
    "\n",
    "config['qformer_layers'] = {\n",
    "    'self_attn': 4,\n",
    "    'self_attn_output':4,\n",
    "    'intermediate_txt': 4,\n",
    "    'output_txt': 4,\n",
    "    'intermediate_query':4,\n",
    "    'output_query': 4,\n",
    "    'cross_attn': 4,\n",
    "    'cross_attn_output': 4,\n",
    "    # 'vision_proj':4,\n",
    "    # 'txt_proj':4,\n",
    "    # 'itm_head': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(224, 224), interpolation=bicubic, max_size=None, antialias=True)\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import Flickr30kEvalDataset\n",
    "import torchvision.transforms as transforms\n",
    "# import torchvision.transforms.InterpolationMode as InterpolationMode\n",
    "\n",
    "\n",
    "ann_file = '/nfshomes/vla/project_dirs/low-bit-vision/datasets/flickr30k/annotations/test.json'\n",
    "img_dir = '/nfshomes/vla/project_dirs/low-bit-vision/datasets/flickr30k/images/flickr30k-images'\n",
    "\n",
    "\n",
    "img_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(\n",
    "            (224, 224), interpolation=transforms.InterpolationMode.BICUBIC\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "    ]\n",
    ")\n",
    "\n",
    "img_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr_dataset = Flickr30kEvalDataset(ann_file, img_dir, img_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.qformer.encoder.layer[10].output.dense.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w = w.to(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-7.1526e-07,  7.7486e-07, -5.9605e-08,  ..., -1.9073e-06,\n",
       "         -1.7881e-07,  8.9407e-07],\n",
       "        [ 4.5300e-06,  2.3246e-06,  3.3975e-06,  ..., -7.7486e-07,\n",
       "          1.1921e-07,  2.8610e-06],\n",
       "        [ 4.7684e-07,  4.1127e-06, -3.9339e-06,  ...,  2.2650e-06,\n",
       "          3.2783e-06,  3.9339e-06],\n",
       "        ...,\n",
       "        [ 6.5565e-07,  1.1921e-06,  5.4240e-06,  ...,  2.0862e-06,\n",
       "         -1.4305e-06, -2.3842e-07],\n",
       "        [ 1.8477e-06, -1.7285e-06, -4.7684e-07,  ..., -6.4969e-06,\n",
       "         -4.5300e-06, -5.3644e-07],\n",
       "        [ 2.3842e-06,  1.5497e-06, -2.2650e-06,  ..., -3.3975e-06,\n",
       "          2.1458e-06,  2.0862e-06]], device='cuda:0', dtype=torch.float16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 3072])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.isnan(w).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(w)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert torch.isinf(w).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_bits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.1699e-01],\n",
       "        [1.7590e-01],\n",
       "        [2.1228e-01],\n",
       "        [3.5062e+01],\n",
       "        [2.0962e-03],\n",
       "        [1.7266e+01],\n",
       "        [6.1812e+01],\n",
       "        [1.3750e+02],\n",
       "        [4.8950e-01],\n",
       "        [5.3101e-02],\n",
       "        [1.6438e+02],\n",
       "        [2.3812e+02],\n",
       "        [4.5654e-01],\n",
       "        [1.4162e+02],\n",
       "        [1.7925e+02],\n",
       "        [2.1050e+02],\n",
       "        [3.4657e-03],\n",
       "        [1.3685e-03],\n",
       "        [1.9250e-01],\n",
       "        [3.6963e-01],\n",
       "        [4.5074e-02],\n",
       "        [3.2623e-02],\n",
       "        [1.9934e-01],\n",
       "        [3.6438e+01],\n",
       "        [2.3315e-01],\n",
       "        [8.0234e+00],\n",
       "        [3.3836e-03],\n",
       "        [2.2078e+01],\n",
       "        [5.6738e-01],\n",
       "        [8.4562e+01],\n",
       "        [8.9438e+01],\n",
       "        [2.2575e+02],\n",
       "        [1.1086e-05],\n",
       "        [3.3179e-01],\n",
       "        [4.2844e+01],\n",
       "        [5.7500e+01],\n",
       "        [8.4521e-01],\n",
       "        [1.1493e-01],\n",
       "        [1.4550e+02],\n",
       "        [8.1484e+00],\n",
       "        [1.1981e-04],\n",
       "        [9.8944e-06],\n",
       "        [2.4255e-01],\n",
       "        [7.6580e-04],\n",
       "        [1.0012e+02],\n",
       "        [1.7825e+02],\n",
       "        [1.0119e+02],\n",
       "        [4.1906e+01],\n",
       "        [2.6172e+01],\n",
       "        [1.0625e+02],\n",
       "        [9.4092e-01],\n",
       "        [3.4125e+01],\n",
       "        [5.4000e+01],\n",
       "        [1.0193e-01],\n",
       "        [3.2471e-01],\n",
       "        [4.1600e+02],\n",
       "        [3.2196e-02],\n",
       "        [9.2375e+01],\n",
       "        [3.9291e-03],\n",
       "        [4.3938e+01],\n",
       "        [3.5303e-01],\n",
       "        [2.7575e+02],\n",
       "        [1.0612e+02],\n",
       "        [6.7000e+01],\n",
       "        [5.4352e-02],\n",
       "        [2.3875e+01],\n",
       "        [2.5296e-04],\n",
       "        [1.3477e+01],\n",
       "        [6.4964e-03],\n",
       "        [4.1138e-02],\n",
       "        [1.4512e+02],\n",
       "        [1.7178e+00],\n",
       "        [1.8120e-05],\n",
       "        [3.6875e+01],\n",
       "        [4.0016e-03],\n",
       "        [9.6436e-01],\n",
       "        [5.8365e-03],\n",
       "        [2.1211e+00],\n",
       "        [1.4162e-03],\n",
       "        [3.4725e+02],\n",
       "        [1.3806e-01],\n",
       "        [6.8188e+01],\n",
       "        [8.2125e+01],\n",
       "        [3.2005e-03],\n",
       "        [6.0625e+01],\n",
       "        [2.7393e-01],\n",
       "        [9.6250e+00],\n",
       "        [9.1188e+01],\n",
       "        [3.8330e-02],\n",
       "        [1.5162e+02],\n",
       "        [3.2562e+01],\n",
       "        [1.4288e+02],\n",
       "        [1.1658e-01],\n",
       "        [1.2412e+02],\n",
       "        [9.8500e+01],\n",
       "        [3.5107e-01],\n",
       "        [1.1412e+02],\n",
       "        [8.1110e-04],\n",
       "        [2.1203e+01],\n",
       "        [7.3312e+01],\n",
       "        [3.9062e-03],\n",
       "        [3.8477e-01],\n",
       "        [2.5158e-03],\n",
       "        [1.0175e-01],\n",
       "        [1.3500e+02],\n",
       "        [4.4727e-04],\n",
       "        [1.8078e+01],\n",
       "        [6.3094e+01],\n",
       "        [3.2251e-01],\n",
       "        [3.2654e-02],\n",
       "        [1.3638e+02],\n",
       "        [2.1000e+02],\n",
       "        [7.6532e-04],\n",
       "        [1.0336e+01],\n",
       "        [5.0195e-01],\n",
       "        [1.7575e+02],\n",
       "        [1.3050e+02],\n",
       "        [6.6357e-01],\n",
       "        [2.7490e-01],\n",
       "        [1.9038e+02],\n",
       "        [1.4832e-01],\n",
       "        [1.1469e+02],\n",
       "        [3.5915e-03],\n",
       "        [4.9720e+03],\n",
       "        [1.7672e-03],\n",
       "        [3.3203e+00],\n",
       "        [8.2275e-01],\n",
       "        [1.8538e+02],\n",
       "        [3.0273e-01],\n",
       "        [1.4484e+01],\n",
       "        [1.5475e+02],\n",
       "        [1.6762e+02],\n",
       "        [2.5800e+02],\n",
       "        [1.5625e+02],\n",
       "        [1.1712e+02],\n",
       "        [2.6001e-01],\n",
       "        [9.7418e-04],\n",
       "        [4.7930e+00],\n",
       "        [3.2202e-01],\n",
       "        [1.6031e+01],\n",
       "        [1.6882e-01],\n",
       "        [6.7627e-02],\n",
       "        [7.3373e-05],\n",
       "        [3.4094e+01],\n",
       "        [6.2656e+01],\n",
       "        [2.0008e-03],\n",
       "        [1.4319e-01],\n",
       "        [7.4524e-02],\n",
       "        [1.6475e+02],\n",
       "        [4.4250e-03],\n",
       "        [1.8050e+02],\n",
       "        [1.2930e+01],\n",
       "        [3.7939e-01],\n",
       "        [2.6123e-01],\n",
       "        [4.4189e-01],\n",
       "        [9.4062e+01],\n",
       "        [1.9488e+02],\n",
       "        [6.5136e-04],\n",
       "        [1.0281e+02],\n",
       "        [2.1863e-04],\n",
       "        [2.2373e-03],\n",
       "        [7.5745e-02],\n",
       "        [5.4955e-05],\n",
       "        [2.6188e-03],\n",
       "        [2.1324e-03],\n",
       "        [8.9355e-02],\n",
       "        [1.8966e-04],\n",
       "        [1.8967e-02],\n",
       "        [1.3200e+02],\n",
       "        [7.0625e+01],\n",
       "        [2.9517e-01],\n",
       "        [4.1357e-01],\n",
       "        [7.4375e+01],\n",
       "        [2.2926e-03],\n",
       "        [1.0594e+02],\n",
       "        [1.5411e-02],\n",
       "        [7.4188e+01],\n",
       "        [3.0375e+01],\n",
       "        [1.5262e+02],\n",
       "        [1.8016e+01],\n",
       "        [2.5312e+00],\n",
       "        [7.1250e+00],\n",
       "        [1.3806e-01],\n",
       "        [1.1249e-01],\n",
       "        [1.1062e+02],\n",
       "        [1.7328e+01],\n",
       "        [2.8656e+01],\n",
       "        [3.0600e+02],\n",
       "        [3.2234e-03],\n",
       "        [3.7646e-04],\n",
       "        [4.6851e-01],\n",
       "        [5.3558e-03],\n",
       "        [2.0375e+01],\n",
       "        [5.1281e+01],\n",
       "        [4.1628e-04],\n",
       "        [3.3188e+01],\n",
       "        [7.9930e-05],\n",
       "        [2.4524e-01],\n",
       "        [1.0069e+02],\n",
       "        [1.0643e-03],\n",
       "        [2.6245e-01],\n",
       "        [3.8843e-01],\n",
       "        [9.9375e+01],\n",
       "        [6.6699e-01],\n",
       "        [2.5703e+01],\n",
       "        [4.9875e+01],\n",
       "        [1.0848e-05],\n",
       "        [4.5812e+01],\n",
       "        [9.6130e-04],\n",
       "        [1.4112e+02],\n",
       "        [1.0719e+02],\n",
       "        [2.7016e+01],\n",
       "        [1.4937e-04],\n",
       "        [2.6350e+02],\n",
       "        [5.8812e+01],\n",
       "        [5.7594e+01],\n",
       "        [3.5693e-01],\n",
       "        [1.6300e+02],\n",
       "        [1.5888e+02],\n",
       "        [1.2350e-04],\n",
       "        [2.6750e+02],\n",
       "        [1.1511e-03],\n",
       "        [6.1531e+01],\n",
       "        [2.1741e-01],\n",
       "        [5.6281e+01],\n",
       "        [2.6700e+02],\n",
       "        [3.2750e+01],\n",
       "        [4.5801e-01],\n",
       "        [5.3120e-04],\n",
       "        [3.7708e-03],\n",
       "        [6.4375e+01],\n",
       "        [5.4150e-01],\n",
       "        [2.0275e+02],\n",
       "        [1.7612e+02],\n",
       "        [6.6125e+01],\n",
       "        [1.0188e+02],\n",
       "        [5.1796e-05],\n",
       "        [1.1265e-05],\n",
       "        [9.2938e+01],\n",
       "        [1.4200e-03],\n",
       "        [2.8133e-05],\n",
       "        [1.6809e-05],\n",
       "        [2.7599e-03],\n",
       "        [3.2475e+02],\n",
       "        [5.7080e-01],\n",
       "        [1.7112e+02],\n",
       "        [4.7266e-01],\n",
       "        [2.4797e+01],\n",
       "        [2.0562e+02],\n",
       "        [1.6575e+02],\n",
       "        [1.2606e+02],\n",
       "        [3.5156e-01],\n",
       "        [2.3218e-01],\n",
       "        [4.9656e+01],\n",
       "        [7.1436e-01],\n",
       "        [3.9551e-01],\n",
       "        [5.3635e-03],\n",
       "        [1.7900e-03],\n",
       "        [3.1781e-04],\n",
       "        [5.6625e+01],\n",
       "        [2.0450e+02],\n",
       "        [2.7400e+02],\n",
       "        [2.5928e-01],\n",
       "        [1.5271e-04],\n",
       "        [6.8000e+01],\n",
       "        [8.4863e-01],\n",
       "        [8.4312e+01],\n",
       "        [3.0176e-01],\n",
       "        [6.2906e+01],\n",
       "        [3.4952e-04],\n",
       "        [9.8267e-02],\n",
       "        [1.0400e+02],\n",
       "        [8.9312e-04],\n",
       "        [2.0422e+01],\n",
       "        [3.3173e-02],\n",
       "        [1.1206e-05],\n",
       "        [8.9844e+00],\n",
       "        [2.9575e+02],\n",
       "        [3.2812e+01],\n",
       "        [3.5062e+01],\n",
       "        [1.5400e+02],\n",
       "        [1.7812e+02],\n",
       "        [1.7014e-03],\n",
       "        [4.0405e-01],\n",
       "        [9.3799e-01],\n",
       "        [5.6592e-01],\n",
       "        [2.7750e+02],\n",
       "        [1.9800e+02],\n",
       "        [1.7662e+02],\n",
       "        [3.8624e-03],\n",
       "        [2.5469e+01],\n",
       "        [1.6850e+02],\n",
       "        [2.4878e-01],\n",
       "        [3.0861e-03],\n",
       "        [1.9075e+02],\n",
       "        [8.2825e-02],\n",
       "        [7.6500e+01],\n",
       "        [9.5947e-02],\n",
       "        [1.7938e+02],\n",
       "        [2.5375e+01],\n",
       "        [2.6550e+02],\n",
       "        [3.0293e+00],\n",
       "        [1.1005e-01],\n",
       "        [3.8623e-01],\n",
       "        [2.7484e+01],\n",
       "        [1.5008e-04],\n",
       "        [9.9030e-03],\n",
       "        [5.0537e-01],\n",
       "        [3.2950e+02],\n",
       "        [1.2994e-04],\n",
       "        [4.1797e-01],\n",
       "        [1.8506e-01],\n",
       "        [5.7500e+01],\n",
       "        [2.8515e-03],\n",
       "        [4.5410e-01],\n",
       "        [9.8688e+01],\n",
       "        [6.2402e-01],\n",
       "        [2.4805e-01],\n",
       "        [4.2461e+00],\n",
       "        [4.1986e-04],\n",
       "        [1.5212e+02],\n",
       "        [1.4588e+02],\n",
       "        [7.8125e+01],\n",
       "        [7.3291e-01],\n",
       "        [1.2279e-05],\n",
       "        [6.6875e+01],\n",
       "        [6.6688e+01],\n",
       "        [1.4388e+02],\n",
       "        [3.7438e+01],\n",
       "        [4.5410e-01],\n",
       "        [2.9150e-01],\n",
       "        [8.5875e+01],\n",
       "        [2.3350e+02],\n",
       "        [1.3100e+02],\n",
       "        [1.4200e+02],\n",
       "        [6.2408e-03],\n",
       "        [1.0732e+00],\n",
       "        [8.2938e+01],\n",
       "        [3.5205e-01],\n",
       "        [1.5059e-03],\n",
       "        [1.1644e+02],\n",
       "        [1.0788e+02],\n",
       "        [5.2002e-01],\n",
       "        [2.1712e+02],\n",
       "        [1.3816e-04],\n",
       "        [1.1712e+02],\n",
       "        [9.4604e-04],\n",
       "        [4.5625e+01],\n",
       "        [2.8125e-01],\n",
       "        [2.4866e-01],\n",
       "        [1.3262e+02],\n",
       "        [3.7438e+01],\n",
       "        [3.0800e+02],\n",
       "        [3.6255e-02],\n",
       "        [1.6830e-02],\n",
       "        [7.6172e-02],\n",
       "        [2.6221e-01],\n",
       "        [2.2359e+01],\n",
       "        [2.9325e-04],\n",
       "        [7.2938e+01],\n",
       "        [1.1906e+02],\n",
       "        [9.5125e+01],\n",
       "        [1.4982e-03],\n",
       "        [1.0506e+02],\n",
       "        [3.2562e+01],\n",
       "        [5.6438e+01],\n",
       "        [9.2062e+01],\n",
       "        [6.0916e-05],\n",
       "        [4.6206e-04],\n",
       "        [6.5312e+01],\n",
       "        [1.4124e-01],\n",
       "        [1.0644e+02],\n",
       "        [1.6588e+02],\n",
       "        [2.8418e-01],\n",
       "        [1.0566e+00],\n",
       "        [3.0127e-01],\n",
       "        [7.7656e+00],\n",
       "        [9.8515e-04],\n",
       "        [1.7281e+01],\n",
       "        [5.2438e+01],\n",
       "        [1.4601e-03],\n",
       "        [1.8112e-02],\n",
       "        [4.3564e-03],\n",
       "        [8.1396e-01],\n",
       "        [2.4088e+02],\n",
       "        [1.2407e-03],\n",
       "        [3.8500e+01],\n",
       "        [1.2941e-03],\n",
       "        [6.5869e-01],\n",
       "        [5.1416e-01],\n",
       "        [4.7119e-01],\n",
       "        [1.2200e+02],\n",
       "        [2.3700e+02],\n",
       "        [6.1572e-01],\n",
       "        [3.4863e-01],\n",
       "        [5.0406e+01],\n",
       "        [1.3940e-01],\n",
       "        [6.9375e+01],\n",
       "        [1.1530e-03],\n",
       "        [7.0000e-03],\n",
       "        [1.7912e+02],\n",
       "        [4.2212e-01],\n",
       "        [1.1978e-03],\n",
       "        [4.5969e+01],\n",
       "        [1.3898e+01],\n",
       "        [7.1228e-05],\n",
       "        [1.1749e-03],\n",
       "        [9.1267e-04],\n",
       "        [8.2350e-04],\n",
       "        [4.0844e+01],\n",
       "        [1.4638e+02],\n",
       "        [2.6733e-01],\n",
       "        [1.8726e-01],\n",
       "        [7.0562e+01],\n",
       "        [1.0967e-05],\n",
       "        [9.2750e+01],\n",
       "        [5.8398e-01],\n",
       "        [5.2643e-02],\n",
       "        [4.8256e-04],\n",
       "        [1.3046e-03],\n",
       "        [2.3250e+02],\n",
       "        [2.0475e+02],\n",
       "        [2.6225e+02],\n",
       "        [3.1885e-01],\n",
       "        [3.1471e-03],\n",
       "        [7.9438e+01],\n",
       "        [4.0210e-01],\n",
       "        [1.6062e+02],\n",
       "        [2.0828e-03],\n",
       "        [2.1565e-04],\n",
       "        [4.6406e+01],\n",
       "        [2.0238e+02],\n",
       "        [1.2688e+02],\n",
       "        [2.7453e+01],\n",
       "        [2.7094e+01],\n",
       "        [1.1356e+02],\n",
       "        [1.7688e+02],\n",
       "        [1.3561e-03],\n",
       "        [8.3327e-05],\n",
       "        [1.7358e-01],\n",
       "        [2.4438e+02],\n",
       "        [1.3412e+02],\n",
       "        [3.7479e-03],\n",
       "        [4.0969e+01],\n",
       "        [3.8469e+01],\n",
       "        [2.9639e-01],\n",
       "        [1.1568e-03],\n",
       "        [5.6738e-01],\n",
       "        [2.3422e+01],\n",
       "        [2.3200e+02],\n",
       "        [1.5888e+02],\n",
       "        [2.0000e+02],\n",
       "        [4.9629e-03],\n",
       "        [9.5215e-02],\n",
       "        [7.8750e+01],\n",
       "        [1.1070e+01],\n",
       "        [4.7559e-01],\n",
       "        [1.3962e+02],\n",
       "        [3.1982e-01],\n",
       "        [5.5500e+01],\n",
       "        [4.1699e-04],\n",
       "        [2.4643e-03],\n",
       "        [2.2484e+01],\n",
       "        [8.7750e+01],\n",
       "        [1.2950e+02],\n",
       "        [3.2300e+02],\n",
       "        [1.1981e-05],\n",
       "        [3.6450e-01],\n",
       "        [6.2578e+00],\n",
       "        [5.5664e-01],\n",
       "        [7.0375e+01],\n",
       "        [1.8850e+02],\n",
       "        [2.0350e+02],\n",
       "        [7.5438e+01],\n",
       "        [4.3755e-03],\n",
       "        [1.7004e-01],\n",
       "        [8.0188e+01],\n",
       "        [6.0750e+01],\n",
       "        [4.6406e+01],\n",
       "        [8.0438e+01],\n",
       "        [1.2912e+02],\n",
       "        [1.1885e+00],\n",
       "        [1.8713e-01],\n",
       "        [1.4312e+02],\n",
       "        [1.4750e+02],\n",
       "        [1.7700e-01],\n",
       "        [1.0425e-01],\n",
       "        [7.4654e-03],\n",
       "        [4.6953e+00],\n",
       "        [1.9360e-01],\n",
       "        [2.2688e+02],\n",
       "        [7.0812e+01],\n",
       "        [1.2577e-05],\n",
       "        [1.9962e+02],\n",
       "        [3.4451e-04],\n",
       "        [1.4372e-03],\n",
       "        [4.7778e-01],\n",
       "        [2.2656e-01],\n",
       "        [3.8815e-04],\n",
       "        [1.3625e+02],\n",
       "        [1.4288e+02],\n",
       "        [7.2896e-05],\n",
       "        [5.6006e-01],\n",
       "        [6.1377e-01],\n",
       "        [7.3828e-01],\n",
       "        [3.5962e-01],\n",
       "        [2.7759e-01],\n",
       "        [4.2877e-03],\n",
       "        [3.5156e-01],\n",
       "        [6.4938e+01],\n",
       "        [8.4912e-01],\n",
       "        [6.3375e+01],\n",
       "        [1.7583e-04],\n",
       "        [7.4170e-01],\n",
       "        [2.0412e+02],\n",
       "        [3.2188e+01],\n",
       "        [4.5039e+00],\n",
       "        [3.1844e+01],\n",
       "        [9.8779e-01],\n",
       "        [6.9389e-03],\n",
       "        [2.8857e-01],\n",
       "        [1.1138e+02],\n",
       "        [1.2573e-01],\n",
       "        [6.5062e+01],\n",
       "        [2.1378e-02],\n",
       "        [7.0996e-01],\n",
       "        [5.2686e-01],\n",
       "        [4.9902e-01],\n",
       "        [1.3733e-04],\n",
       "        [1.0853e-03],\n",
       "        [7.0686e-03],\n",
       "        [3.7594e+01],\n",
       "        [2.8706e-04],\n",
       "        [6.4182e-04],\n",
       "        [4.0078e-04],\n",
       "        [1.1787e-03],\n",
       "        [1.9500e+02],\n",
       "        [4.1809e-03],\n",
       "        [1.9646e-03],\n",
       "        [2.0254e+00],\n",
       "        [3.4750e+02],\n",
       "        [3.0950e+02],\n",
       "        [5.6610e-03],\n",
       "        [3.6108e-01],\n",
       "        [2.7759e-01],\n",
       "        [1.4800e+02],\n",
       "        [1.1903e-04],\n",
       "        [3.5719e+01],\n",
       "        [2.4825e+02],\n",
       "        [1.4500e+02],\n",
       "        [2.1712e+02],\n",
       "        [1.2500e-01],\n",
       "        [9.5375e+01],\n",
       "        [1.2475e+02],\n",
       "        [8.9121e-04],\n",
       "        [8.1438e+01],\n",
       "        [1.9250e-01],\n",
       "        [6.2227e-04],\n",
       "        [4.8981e-03],\n",
       "        [2.9077e-01],\n",
       "        [7.2539e-05],\n",
       "        [9.7656e-03],\n",
       "        [1.4988e+02],\n",
       "        [8.6250e+00],\n",
       "        [5.3812e+01],\n",
       "        [9.0312e+01],\n",
       "        [9.1625e+01],\n",
       "        [1.1588e+02],\n",
       "        [1.0164e+01],\n",
       "        [8.8562e+01],\n",
       "        [5.5127e-01],\n",
       "        [1.6875e+02],\n",
       "        [2.0672e+01],\n",
       "        [2.5775e+02],\n",
       "        [1.8988e+02],\n",
       "        [2.4775e+02],\n",
       "        [5.7688e+01],\n",
       "        [7.9062e+01],\n",
       "        [1.3588e+02],\n",
       "        [1.7812e+01],\n",
       "        [3.3496e-01],\n",
       "        [8.9188e+01],\n",
       "        [2.7000e+01],\n",
       "        [6.6125e+01],\n",
       "        [9.1492e-02],\n",
       "        [1.1794e+02],\n",
       "        [1.5338e+02],\n",
       "        [3.4180e-02],\n",
       "        [8.7938e+01],\n",
       "        [1.3262e+02],\n",
       "        [2.2644e-02],\n",
       "        [1.5212e+02],\n",
       "        [1.5649e-01],\n",
       "        [8.4814e-01],\n",
       "        [6.4625e+01],\n",
       "        [6.0562e+01],\n",
       "        [1.2842e-01],\n",
       "        [4.5719e+01],\n",
       "        [3.3281e+01],\n",
       "        [1.2812e+02],\n",
       "        [1.1309e+00],\n",
       "        [1.0744e+02],\n",
       "        [1.9531e-01],\n",
       "        [6.5125e+01],\n",
       "        [2.5312e+02],\n",
       "        [3.6550e+02],\n",
       "        [3.0537e-03],\n",
       "        [1.0519e-03],\n",
       "        [5.7716e-03],\n",
       "        [2.7875e+02],\n",
       "        [1.2781e+02],\n",
       "        [1.3712e+02],\n",
       "        [1.8250e+02],\n",
       "        [3.3050e+02],\n",
       "        [1.3695e+01],\n",
       "        [5.9750e+01],\n",
       "        [1.3638e-03],\n",
       "        [8.1625e+01],\n",
       "        [1.3238e+02],\n",
       "        [2.2815e-01],\n",
       "        [3.1275e+02],\n",
       "        [2.1525e+02],\n",
       "        [4.8492e-02],\n",
       "        [1.0309e-01],\n",
       "        [4.3604e-01],\n",
       "        [1.6125e-01],\n",
       "        [9.2938e+01],\n",
       "        [1.3200e+02],\n",
       "        [9.8375e+01],\n",
       "        [1.4275e+02],\n",
       "        [6.8188e+01],\n",
       "        [1.7641e+01],\n",
       "        [1.0981e+02],\n",
       "        [1.5250e+02],\n",
       "        [4.9125e+01],\n",
       "        [5.2977e-04],\n",
       "        [6.3781e+01],\n",
       "        [2.9100e+02],\n",
       "        [1.1762e+02],\n",
       "        [1.3888e+02],\n",
       "        [1.0275e+02],\n",
       "        [2.2762e+02],\n",
       "        [1.7850e+02],\n",
       "        [3.6646e-01],\n",
       "        [2.7930e+00],\n",
       "        [1.0723e+00],\n",
       "        [1.0602e-01],\n",
       "        [8.9216e-04],\n",
       "        [2.6094e+01],\n",
       "        [2.3675e+02],\n",
       "        [2.3219e+01],\n",
       "        [1.4538e+02],\n",
       "        [4.8208e-04],\n",
       "        [1.0069e+02],\n",
       "        [7.6437e-04],\n",
       "        [6.9750e+01],\n",
       "        [1.7462e+02],\n",
       "        [1.2025e+02],\n",
       "        [5.3156e+01],\n",
       "        [1.1819e+02],\n",
       "        [4.6125e+02],\n",
       "        [5.3520e-03],\n",
       "        [1.3437e-03],\n",
       "        [5.2875e+01],\n",
       "        [1.4925e+02],\n",
       "        [6.0081e-05],\n",
       "        [2.1969e+01],\n",
       "        [1.0256e+02],\n",
       "        [1.4099e-01],\n",
       "        [2.1094e+01],\n",
       "        [1.0569e+02],\n",
       "        [1.4889e-04],\n",
       "        [1.0718e-01],\n",
       "        [9.9812e+01],\n",
       "        [2.4788e+02],\n",
       "        [9.6000e+01],\n",
       "        [1.9900e+02],\n",
       "        [1.2988e+02],\n",
       "        [8.4812e+01],\n",
       "        [1.5918e-01],\n",
       "        [1.7838e+02],\n",
       "        [8.6035e-01],\n",
       "        [1.2075e+02],\n",
       "        [6.2402e-01],\n",
       "        [3.3302e-03],\n",
       "        [1.2146e-01],\n",
       "        [2.0065e-03],\n",
       "        [1.3547e+01],\n",
       "        [5.0820e+00],\n",
       "        [9.3438e+01],\n",
       "        [1.6025e+02],\n",
       "        [2.6035e-03],\n",
       "        [2.8564e-01],\n",
       "        [4.1357e-01],\n",
       "        [9.4188e+01],\n",
       "        [3.1274e-01],\n",
       "        [2.5047e+01],\n",
       "        [6.5188e+01],\n",
       "        [1.0300e+02],\n",
       "        [1.5564e-01],\n",
       "        [1.9700e+02],\n",
       "        [2.2516e+01],\n",
       "        [2.0027e-03],\n",
       "        [3.3844e+01],\n",
       "        [2.6325e+02],\n",
       "        [1.9717e+00],\n",
       "        [1.0712e+02],\n",
       "        [1.5295e-04],\n",
       "        [9.3500e+01],\n",
       "        [1.6484e+01],\n",
       "        [3.3875e+01],\n",
       "        [2.7618e-03],\n",
       "        [3.3105e-01],\n",
       "        [1.2006e+02],\n",
       "        [3.0641e+01],\n",
       "        [5.0977e-01],\n",
       "        [1.6418e-01],\n",
       "        [2.3291e-01],\n",
       "        [9.1000e+01],\n",
       "        [1.9138e+02],\n",
       "        [1.0724e-01],\n",
       "        [1.6788e+02],\n",
       "        [3.0188e+01],\n",
       "        [4.3406e+01],\n",
       "        [5.4169e-04],\n",
       "        [8.6572e-01],\n",
       "        [5.6469e+01],\n",
       "        [3.4546e-01],\n",
       "        [1.8762e+02],\n",
       "        [4.1357e-01],\n",
       "        [1.0669e-05],\n",
       "        [3.2438e+01],\n",
       "        [9.2957e-02],\n",
       "        [3.6377e-01],\n",
       "        [1.1656e+02],\n",
       "        [1.3162e+02],\n",
       "        [4.6851e-01],\n",
       "        [4.9162e-04],\n",
       "        [3.9233e-01],\n",
       "        [2.4547e+01],\n",
       "        [8.1938e+01],\n",
       "        [4.3500e+01],\n",
       "        [8.0312e+01],\n",
       "        [5.7422e-01],\n",
       "        [8.8625e+01],\n",
       "        [1.7525e+02],\n",
       "        [1.9604e-01],\n",
       "        [1.7150e+02],\n",
       "        [7.0188e+01],\n",
       "        [2.9281e+01],\n",
       "        [3.2282e-04],\n",
       "        [1.0729e-05],\n",
       "        [3.7594e+01],\n",
       "        [7.0250e+01],\n",
       "        [2.0767e-02],\n",
       "        [1.9646e-03],\n",
       "        [1.6943e-01],\n",
       "        [2.2221e-03],\n",
       "        [1.3514e-03],\n",
       "        [8.2562e+01],\n",
       "        [1.2660e-04],\n",
       "        [1.1139e-03],\n",
       "        [1.1481e+02],\n",
       "        [3.7456e-04],\n",
       "        [4.3335e-01],\n",
       "        [2.1969e+01],\n",
       "        [1.2988e+02],\n",
       "        [1.5063e-01]], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<AmaxBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val = w.amax(dim=1, keepdim=True)\n",
    "assert torch.isnan(max_val).sum() == 0\n",
    "assert torch.isinf(max_val).sum() == 0\n",
    "max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.6925e+02],\n",
       "        [-1.1388e+02],\n",
       "        [-9.7688e+01],\n",
       "        [-1.5503e-01],\n",
       "        [-8.5688e+01],\n",
       "        [-5.3070e-02],\n",
       "        [-5.9296e-02],\n",
       "        [-1.2976e-01],\n",
       "        [-4.3150e+02],\n",
       "        [-4.3550e+02],\n",
       "        [-7.1478e-04],\n",
       "        [-6.6345e-02],\n",
       "        [-2.2938e+02],\n",
       "        [-3.0727e-03],\n",
       "        [-5.8556e-04],\n",
       "        [-1.8225e-01],\n",
       "        [-8.7125e+01],\n",
       "        [-1.9650e+02],\n",
       "        [-1.9225e+02],\n",
       "        [-6.4550e+02],\n",
       "        [-9.2562e+01],\n",
       "        [-1.1169e+02],\n",
       "        [-3.3062e+01],\n",
       "        [-8.8074e-02],\n",
       "        [-1.1106e+02],\n",
       "        [-6.6614e-04],\n",
       "        [-1.0244e+02],\n",
       "        [-8.0347e-04],\n",
       "        [-1.9888e+02],\n",
       "        [-7.8918e-02],\n",
       "        [-7.2632e-02],\n",
       "        [-6.4148e-02],\n",
       "        [-5.7469e+01],\n",
       "        [-1.3888e+02],\n",
       "        [-1.1568e-03],\n",
       "        [-5.5313e-04],\n",
       "        [-6.5375e+01],\n",
       "        [-2.4625e+02],\n",
       "        [-8.0872e-04],\n",
       "        [-1.4524e-03],\n",
       "        [-3.8625e+02],\n",
       "        [-1.8012e+02],\n",
       "        [-9.2062e+01],\n",
       "        [-2.9600e+02],\n",
       "        [-6.8855e-04],\n",
       "        [-7.3853e-02],\n",
       "        [-4.1351e-03],\n",
       "        [-7.8003e-02],\n",
       "        [-1.7212e-02],\n",
       "        [-1.0748e-03],\n",
       "        [-3.7150e+02],\n",
       "        [-2.4152e-04],\n",
       "        [-1.9484e-03],\n",
       "        [-2.4762e+02],\n",
       "        [-1.3225e+02],\n",
       "        [-4.9400e-04],\n",
       "        [-4.6725e+02],\n",
       "        [-5.2155e-02],\n",
       "        [-1.5375e+02],\n",
       "        [-4.5715e-02],\n",
       "        [-1.8612e+02],\n",
       "        [-3.6979e-04],\n",
       "        [-2.4652e-04],\n",
       "        [-1.1625e-03],\n",
       "        [-6.4062e+01],\n",
       "        [-8.0109e-03],\n",
       "        [-3.5219e+01],\n",
       "        [-2.0504e-04],\n",
       "        [-1.8538e+02],\n",
       "        [-3.8900e+02],\n",
       "        [-3.9101e-04],\n",
       "        [-5.0926e-04],\n",
       "        [-6.9562e+01],\n",
       "        [-5.4598e-04],\n",
       "        [-1.1581e+02],\n",
       "        [-1.4950e+02],\n",
       "        [-2.2938e+02],\n",
       "        [-6.6956e-02],\n",
       "        [-2.2600e+02],\n",
       "        [-7.6246e-04],\n",
       "        [-1.4125e+02],\n",
       "        [-2.3079e-04],\n",
       "        [-7.6580e-04],\n",
       "        [-2.0688e+01],\n",
       "        [-4.8232e-04],\n",
       "        [-2.1969e+01],\n",
       "        [-6.3744e-03],\n",
       "        [-7.0801e-02],\n",
       "        [-7.5500e+01],\n",
       "        [-1.3159e-01],\n",
       "        [-3.4022e-04],\n",
       "        [-2.3361e-02],\n",
       "        [-6.9312e+01],\n",
       "        [-1.2756e-01],\n",
       "        [-1.5891e-04],\n",
       "        [-3.8969e+01],\n",
       "        [-8.7524e-02],\n",
       "        [-3.3156e+01],\n",
       "        [-1.2952e-01],\n",
       "        [-5.3120e-04],\n",
       "        [-1.3788e+02],\n",
       "        [-2.5825e+02],\n",
       "        [-1.8719e+01],\n",
       "        [-3.8100e+02],\n",
       "        [-5.2071e-04],\n",
       "        [-1.0269e+02],\n",
       "        [-9.9123e-05],\n",
       "        [-2.4902e-02],\n",
       "        [-1.0900e+02],\n",
       "        [-1.8925e+02],\n",
       "        [-2.7943e-04],\n",
       "        [-1.4087e-01],\n",
       "        [-8.4500e+02],\n",
       "        [-5.0306e-04],\n",
       "        [-7.3375e+01],\n",
       "        [-1.7893e-04],\n",
       "        [-7.0190e-04],\n",
       "        [-2.6150e+02],\n",
       "        [-3.2812e+01],\n",
       "        [-5.4718e-02],\n",
       "        [-1.6325e+02],\n",
       "        [-1.1826e-03],\n",
       "        [-1.4412e+02],\n",
       "        [-3.2135e-02],\n",
       "        [-1.7012e+02],\n",
       "        [-4.3821e-04],\n",
       "        [-3.9175e+02],\n",
       "        [-1.3232e-01],\n",
       "        [-1.3100e+02],\n",
       "        [-1.0395e-03],\n",
       "        [-6.8188e-04],\n",
       "        [-7.8796e-02],\n",
       "        [-9.5224e-04],\n",
       "        [-1.4286e-03],\n",
       "        [-8.6975e-02],\n",
       "        [-1.3325e+02],\n",
       "        [-1.7862e+02],\n",
       "        [-1.8330e-03],\n",
       "        [-3.7363e+00],\n",
       "        [-1.1932e-02],\n",
       "        [-1.1762e+02],\n",
       "        [-3.8450e+02],\n",
       "        [-4.6125e+02],\n",
       "        [-5.8289e-02],\n",
       "        [-7.5317e-02],\n",
       "        [-3.2875e+02],\n",
       "        [-1.9562e+02],\n",
       "        [-8.7688e+01],\n",
       "        [-5.0879e-04],\n",
       "        [-7.7938e+01],\n",
       "        [-1.1358e-03],\n",
       "        [-5.5695e-04],\n",
       "        [-4.9250e+02],\n",
       "        [-2.1406e+01],\n",
       "        [-4.7100e+02],\n",
       "        [-2.2217e-02],\n",
       "        [-1.5149e-01],\n",
       "        [-3.7250e+02],\n",
       "        [-1.6708e-03],\n",
       "        [-1.5100e+02],\n",
       "        [-1.2362e+02],\n",
       "        [-2.4638e+02],\n",
       "        [-9.6125e+01],\n",
       "        [-1.9203e+01],\n",
       "        [-1.9650e+02],\n",
       "        [-7.2438e+01],\n",
       "        [-1.9475e+02],\n",
       "        [-2.4350e+02],\n",
       "        [-5.6124e-04],\n",
       "        [-4.8614e-04],\n",
       "        [-3.0800e+02],\n",
       "        [-2.2488e+02],\n",
       "        [-3.4241e-02],\n",
       "        [-5.2400e+02],\n",
       "        [-1.1133e-01],\n",
       "        [-2.4350e+02],\n",
       "        [-5.5481e-02],\n",
       "        [-7.2575e-04],\n",
       "        [-6.2683e-02],\n",
       "        [-9.0637e-02],\n",
       "        [       -inf],\n",
       "        [-8.5068e-04],\n",
       "        [-1.0181e+02],\n",
       "        [-1.7750e+02],\n",
       "        [-1.6870e-03],\n",
       "        [-4.1986e-04],\n",
       "        [-6.9885e-02],\n",
       "        [-1.1215e-03],\n",
       "        [-6.6438e+01],\n",
       "        [-9.9688e+01],\n",
       "        [-1.3462e+02],\n",
       "        [-3.7100e+02],\n",
       "        [-1.1029e-01],\n",
       "        [-1.0366e-03],\n",
       "        [-4.0969e+01],\n",
       "        [-2.3003e-03],\n",
       "        [-2.5475e+02],\n",
       "        [-3.5750e+01],\n",
       "        [-3.6102e-02],\n",
       "        [-1.5650e+02],\n",
       "        [-1.2144e+02],\n",
       "        [-1.7562e+02],\n",
       "        [-5.4260e-02],\n",
       "        [-1.4744e-03],\n",
       "        [-4.5586e-03],\n",
       "        [-2.2924e-04],\n",
       "        [-1.0012e+02],\n",
       "        [-6.4819e-02],\n",
       "        [-3.2450e+02],\n",
       "        [-7.7152e-04],\n",
       "        [-6.6710e-04],\n",
       "        [-4.3154e-04],\n",
       "        [-1.0456e+02],\n",
       "        [-1.9928e-02],\n",
       "        [-3.1853e-03],\n",
       "        [-4.9019e-04],\n",
       "        [-1.2731e+02],\n",
       "        [-6.5193e-03],\n",
       "        [-1.4153e-02],\n",
       "        [-3.4125e+02],\n",
       "        [-1.2474e-03],\n",
       "        [-3.2656e+01],\n",
       "        [-8.3637e-04],\n",
       "        [-4.3656e+01],\n",
       "        [-1.3130e-02],\n",
       "        [-6.4697e-02],\n",
       "        [-6.9092e-02],\n",
       "        [-4.0175e+02],\n",
       "        [-6.1768e-01],\n",
       "        [-6.8875e+01],\n",
       "        [-8.2588e-04],\n",
       "        [-2.0000e+02],\n",
       "        [-4.6968e-04],\n",
       "        [-6.8569e-04],\n",
       "        [-9.6008e-02],\n",
       "        [-7.7858e-03],\n",
       "        [-2.2075e+02],\n",
       "        [-1.3312e+02],\n",
       "        [-5.1546e-04],\n",
       "        [-2.3762e+02],\n",
       "        [-1.0016e+01],\n",
       "        [-1.2875e+02],\n",
       "        [-1.5125e+01],\n",
       "        [-2.1057e-01],\n",
       "        [-1.9650e+02],\n",
       "        [-2.7585e-04],\n",
       "        [-1.0912e+02],\n",
       "        [-1.8997e-03],\n",
       "        [-2.5249e-04],\n",
       "        [-1.2177e-01],\n",
       "        [-1.5154e-03],\n",
       "        [-2.7363e+00],\n",
       "        [-2.0266e+01],\n",
       "        [-4.5288e-02],\n",
       "        [-1.1188e+02],\n",
       "        [-3.2175e+02],\n",
       "        [-4.1800e+02],\n",
       "        [-1.3300e+02],\n",
       "        [-1.0338e+02],\n",
       "        [-5.2704e-02],\n",
       "        [-6.3467e-04],\n",
       "        [-3.1738e-02],\n",
       "        [-5.5938e+01],\n",
       "        [-1.8250e+02],\n",
       "        [-1.3227e-03],\n",
       "        [-2.5516e+01],\n",
       "        [-1.6846e-01],\n",
       "        [-3.3075e+02],\n",
       "        [-2.9648e-02],\n",
       "        [-1.5512e+02],\n",
       "        [-2.1188e+02],\n",
       "        [-8.4106e-02],\n",
       "        [-1.1650e+02],\n",
       "        [-1.3928e-01],\n",
       "        [-1.3038e+02],\n",
       "        [-1.3675e+02],\n",
       "        [-1.5438e-04],\n",
       "        [-9.0933e-04],\n",
       "        [-4.4155e-04],\n",
       "        [-9.3603e-04],\n",
       "        [-4.2542e-02],\n",
       "        [-7.3608e-02],\n",
       "        [-3.9000e+02],\n",
       "        [-3.1400e+02],\n",
       "        [-2.1225e+02],\n",
       "        [-1.3688e+02],\n",
       "        [-1.3098e-01],\n",
       "        [-9.0790e-03],\n",
       "        [-1.0424e-03],\n",
       "        [-1.5609e+01],\n",
       "        [-6.8521e-04],\n",
       "        [-3.4302e-02],\n",
       "        [-4.3000e+02],\n",
       "        [-1.4662e+02],\n",
       "        [-6.8665e-02],\n",
       "        [-6.5562e+01],\n",
       "        [-1.1148e-03],\n",
       "        [-5.5719e+01],\n",
       "        [-1.2217e-03],\n",
       "        [-4.3488e-02],\n",
       "        [-3.9744e-04],\n",
       "        [-1.1787e-03],\n",
       "        [-4.5875e+01],\n",
       "        [-1.3025e+02],\n",
       "        [-1.0462e-03],\n",
       "        [-2.8650e+02],\n",
       "        [-2.8900e+02],\n",
       "        [-8.3438e+01],\n",
       "        [-2.6474e-03],\n",
       "        [-3.4250e+01],\n",
       "        [-3.7775e+02],\n",
       "        [-5.3150e+02],\n",
       "        [-4.3335e-02],\n",
       "        [-5.0375e+01],\n",
       "        [-9.2312e+01],\n",
       "        [-9.4795e-04],\n",
       "        [-3.2925e+02],\n",
       "        [-2.7475e+02],\n",
       "        [-5.6219e-04],\n",
       "        [-4.0000e+02],\n",
       "        [-7.9203e-04],\n",
       "        [-1.5697e-03],\n",
       "        [-1.7090e-03],\n",
       "        [-2.7675e+02],\n",
       "        [-1.0398e+01],\n",
       "        [-7.2718e-04],\n",
       "        [-3.8671e-04],\n",
       "        [-7.7248e-04],\n",
       "        [-2.2964e-02],\n",
       "        [-2.4925e+02],\n",
       "        [-4.1150e+02],\n",
       "        [-7.2556e-03],\n",
       "        [-1.7941e-04],\n",
       "        [-1.1865e-01],\n",
       "        [-3.3508e-02],\n",
       "        [-2.3141e+01],\n",
       "        [-3.2375e+02],\n",
       "        [-1.7805e-03],\n",
       "        [-1.5038e+02],\n",
       "        [-4.7600e+02],\n",
       "        [-1.3623e-01],\n",
       "        [-1.1859e-01],\n",
       "        [-7.3312e+01],\n",
       "        [-3.3569e-04],\n",
       "        [-2.6575e+02],\n",
       "        [-4.4006e-02],\n",
       "        [-1.4312e+02],\n",
       "        [-9.1064e-02],\n",
       "        [-1.2538e+02],\n",
       "        [-2.8250e+02],\n",
       "        [-3.3661e-02],\n",
       "        [-4.8340e-02],\n",
       "        [-6.1981e-02],\n",
       "        [-5.3398e+00],\n",
       "        [-1.5312e+02],\n",
       "        [-2.5475e+02],\n",
       "        [-2.4600e+02],\n",
       "        [-6.4697e-03],\n",
       "        [-3.2475e+02],\n",
       "        [-1.0178e-02],\n",
       "        [-7.8125e-02],\n",
       "        [-6.8855e-04],\n",
       "        [-1.0694e+02],\n",
       "        [-7.0190e-02],\n",
       "        [-2.2736e-02],\n",
       "        [-2.1790e-02],\n",
       "        [-4.7755e-04],\n",
       "        [-5.2200e+02],\n",
       "        [-2.9969e+01],\n",
       "        [-3.0565e-04],\n",
       "        [-4.0050e+02],\n",
       "        [-7.4615e-03],\n",
       "        [-8.9169e-04],\n",
       "        [-1.8662e+02],\n",
       "        [-4.1500e+02],\n",
       "        [-1.0000e+02],\n",
       "        [-7.4482e-04],\n",
       "        [-3.1025e+02],\n",
       "        [-1.2805e-01],\n",
       "        [-6.0387e-03],\n",
       "        [-6.5250e+01],\n",
       "        [-5.6480e+04],\n",
       "        [-2.8325e+02],\n",
       "        [-3.7800e+02],\n",
       "        [-3.6560e-02],\n",
       "        [-1.7412e+02],\n",
       "        [-3.6764e-04],\n",
       "        [-5.4562e+01],\n",
       "        [-2.0675e+02],\n",
       "        [-2.9475e+02],\n",
       "        [-2.3538e+02],\n",
       "        [-1.2042e-01],\n",
       "        [-9.7168e-02],\n",
       "        [-2.5000e+02],\n",
       "        [-1.9100e+02],\n",
       "        [-1.3855e-02],\n",
       "        [-2.7225e+02],\n",
       "        [-6.7520e-04],\n",
       "        [-3.7750e+01],\n",
       "        [-1.2512e+02],\n",
       "        [-4.3121e-02],\n",
       "        [-4.3688e+01],\n",
       "        [-3.7325e+02],\n",
       "        [-3.0884e-02],\n",
       "        [-1.0994e-02],\n",
       "        [-3.8675e+02],\n",
       "        [-1.4288e+02],\n",
       "        [-2.4250e+02],\n",
       "        [-1.4575e+02],\n",
       "        [-6.6853e-04],\n",
       "        [-3.0563e-02],\n",
       "        [-4.1975e+02],\n",
       "        [-1.8162e+02],\n",
       "        [-1.6975e-04],\n",
       "        [-4.7875e+02],\n",
       "        [-4.7913e-02],\n",
       "        [-1.3647e-01],\n",
       "        [-1.8875e+01],\n",
       "        [-8.9500e+01],\n",
       "        [-2.9725e+02],\n",
       "        [-8.6880e-04],\n",
       "        [-9.8648e-03],\n",
       "        [-3.0441e-02],\n",
       "        [-4.4925e+02],\n",
       "        [-2.0575e+02],\n",
       "        [-2.5129e-04],\n",
       "        [-3.6825e+02],\n",
       "        [-1.4865e-04],\n",
       "        [-9.2000e+01],\n",
       "        [-1.1200e+02],\n",
       "        [-8.7967e-03],\n",
       "        [-1.1539e-03],\n",
       "        [-3.8576e-04],\n",
       "        [-1.1890e-01],\n",
       "        [-2.6989e-04],\n",
       "        [-9.7656e-02],\n",
       "        [-4.5288e-02],\n",
       "        [-1.8600e+02],\n",
       "        [-2.2938e+02],\n",
       "        [-2.4050e+02],\n",
       "        [-1.6937e-02],\n",
       "        [-4.3640e-02],\n",
       "        [-1.4300e+02],\n",
       "        [-4.1866e-04],\n",
       "        [-3.4666e-04],\n",
       "        [-5.4600e+02],\n",
       "        [-2.2738e+02],\n",
       "        [-1.9600e+02],\n",
       "        [-5.8937e-04],\n",
       "        [-2.6352e-02],\n",
       "        [-1.7126e-01],\n",
       "        [-5.0934e-02],\n",
       "        [-1.5000e+02],\n",
       "        [-1.7375e+01],\n",
       "        [-1.3269e-01],\n",
       "        [-1.6129e-02],\n",
       "        [-2.5575e+02],\n",
       "        [-3.8457e-04],\n",
       "        [-6.4562e+01],\n",
       "        [-5.1451e-04],\n",
       "        [-3.1078e+01],\n",
       "        [-4.1025e+02],\n",
       "        [-2.9388e-02],\n",
       "        [-2.6428e-02],\n",
       "        [-1.4319e-01],\n",
       "        [-2.4962e-04],\n",
       "        [-2.6422e+01],\n",
       "        [-2.9100e+02],\n",
       "        [-2.2268e-04],\n",
       "        [-1.0325e+02],\n",
       "        [-2.2476e-02],\n",
       "        [-7.4530e-04],\n",
       "        [-5.7459e-04],\n",
       "        [-1.3000e-01],\n",
       "        [-3.8575e+02],\n",
       "        [-3.1000e+01],\n",
       "        [-6.1005e-02],\n",
       "        [-5.3192e-02],\n",
       "        [-3.8290e-04],\n",
       "        [-7.0068e-02],\n",
       "        [-4.6661e-02],\n",
       "        [-9.9060e-02],\n",
       "        [-3.3500e+01],\n",
       "        [-4.9377e-02],\n",
       "        [-2.2259e-03],\n",
       "        [-1.4800e+02],\n",
       "        [-8.8125e+01],\n",
       "        [-4.4492e+00],\n",
       "        [-3.9886e-02],\n",
       "        [-1.4462e+02],\n",
       "        [-5.9128e-05],\n",
       "        [-6.6423e-04],\n",
       "        [-1.1331e+02],\n",
       "        [-6.1401e-02],\n",
       "        [-2.3175e+02],\n",
       "        [-3.4275e+02],\n",
       "        [-2.2175e+02],\n",
       "        [-1.5375e+02],\n",
       "        [-1.2644e+02],\n",
       "        [-2.9114e-02],\n",
       "        [-1.0586e-03],\n",
       "        [-9.1062e+01],\n",
       "        [-7.7438e+01],\n",
       "        [-2.0700e+02],\n",
       "        [-3.0900e+02],\n",
       "        [-1.9379e-03],\n",
       "        [-4.6000e+02],\n",
       "        [-2.4312e+01],\n",
       "        [-1.9388e+02],\n",
       "        [-1.1192e-02],\n",
       "        [-5.7938e+01],\n",
       "        [-3.9363e-04],\n",
       "        [-1.7638e+02],\n",
       "        [-4.7000e+02],\n",
       "        [-1.3794e-02],\n",
       "        [-4.5074e-02],\n",
       "        [-2.5387e-03],\n",
       "        [-5.2567e-03],\n",
       "        [-3.5225e+02],\n",
       "        [-2.7125e+02],\n",
       "        [-1.6025e+02],\n",
       "        [-1.3983e-04],\n",
       "        [-4.2062e+01],\n",
       "        [-3.5065e-02],\n",
       "        [-1.0956e+02],\n",
       "        [-2.9600e+02],\n",
       "        [-1.4305e+01],\n",
       "        [-1.4425e+02],\n",
       "        [-2.8900e+02],\n",
       "        [-3.7925e+02],\n",
       "        [-1.9938e+02],\n",
       "        [-2.6274e-04],\n",
       "        [-2.5062e+02],\n",
       "        [-5.3700e+02],\n",
       "        [-1.6375e+02],\n",
       "        [-5.0025e+02],\n",
       "        [-5.4216e-04],\n",
       "        [-2.9475e+02],\n",
       "        [-1.6738e+02],\n",
       "        [-3.7975e+02],\n",
       "        [-1.2598e-03],\n",
       "        [-1.8280e-02],\n",
       "        [-2.6953e+01],\n",
       "        [-1.8688e+02],\n",
       "        [-5.6406e+01],\n",
       "        [-1.0233e-03],\n",
       "        [-1.1250e+02],\n",
       "        [-9.8724e-03],\n",
       "        [-3.2353e-04],\n",
       "        [-3.7964e-02],\n",
       "        [-1.8892e-03],\n",
       "        [-6.8950e+02],\n",
       "        [-1.6136e-03],\n",
       "        [-4.4800e-02],\n",
       "        [-1.2731e+02],\n",
       "        [-8.9312e-04],\n",
       "        [-1.6969e+01],\n",
       "        [-9.8750e+01],\n",
       "        [-1.3612e+02],\n",
       "        [-7.3312e+01],\n",
       "        [-1.2062e+02],\n",
       "        [-2.9000e+02],\n",
       "        [-5.6702e-02],\n",
       "        [-6.7663e-04],\n",
       "        [-5.4993e-02],\n",
       "        [-2.7585e-04],\n",
       "        [-1.7471e-03],\n",
       "        [-2.9495e-02],\n",
       "        [-3.0994e-04],\n",
       "        [-8.8379e-02],\n",
       "        [-4.2850e+02],\n",
       "        [-9.7084e-04],\n",
       "        [-1.5022e-02],\n",
       "        [-3.9978e-02],\n",
       "        [-8.8930e-04],\n",
       "        [-3.5882e-04],\n",
       "        [-2.2519e-04],\n",
       "        [-5.5725e-02],\n",
       "        [-2.5511e-04],\n",
       "        [-9.4986e-04],\n",
       "        [-8.6688e+01],\n",
       "        [-1.2481e-04],\n",
       "        [-8.7158e-02],\n",
       "        [-2.0874e-01],\n",
       "        [-3.8562e+01],\n",
       "        [-2.8946e-02],\n",
       "        [-1.5686e-01],\n",
       "        [-1.3725e+02],\n",
       "        [-2.1439e-03],\n",
       "        [-5.0831e-04],\n",
       "        [-7.1312e+01],\n",
       "        [-1.3275e-03],\n",
       "        [-9.9625e+01],\n",
       "        [-3.8175e+02],\n",
       "        [-5.1069e-04],\n",
       "        [-5.5084e-02],\n",
       "        [-7.4297e+00],\n",
       "        [-1.3904e-01],\n",
       "        [-7.2693e-02],\n",
       "        [-6.9641e-02],\n",
       "        [-8.4473e-02],\n",
       "        [-2.8137e-02],\n",
       "        [-2.7500e+02],\n",
       "        [-4.8004e-02],\n",
       "        [-5.6763e-02],\n",
       "        [-7.1594e-02],\n",
       "        [-8.5938e+01],\n",
       "        [-2.5725e+02],\n",
       "        [-1.4088e+02],\n",
       "        [-5.2429e-02],\n",
       "        [-7.3364e-02],\n",
       "        [-7.8918e-02],\n",
       "        [-1.2720e-01],\n",
       "        [-1.6832e-04],\n",
       "        [-4.2023e-02],\n",
       "        [-2.3663e-04],\n",
       "        [-2.0188e+02],\n",
       "        [-1.7250e-04],\n",
       "        [-6.5735e-02],\n",
       "        [-2.8300e+02],\n",
       "        [-1.0852e-01],\n",
       "        [-5.6549e-02],\n",
       "        [-7.0062e+01],\n",
       "        [-1.7200e+02],\n",
       "        [-4.0525e+02],\n",
       "        [-1.6138e+02],\n",
       "        [-3.8326e-05],\n",
       "        [-1.1459e-02],\n",
       "        [-5.7602e-04],\n",
       "        [-1.4572e-02],\n",
       "        [-7.1594e-02],\n",
       "        [-8.1778e-04],\n",
       "        [-5.6549e-02],\n",
       "        [-3.8879e-02],\n",
       "        [-5.9296e-02],\n",
       "        [-1.5200e+02],\n",
       "        [-1.6241e-03],\n",
       "        [-1.3806e-01],\n",
       "        [-4.7272e-02],\n",
       "        [-2.5708e-01],\n",
       "        [-9.2745e-04],\n",
       "        [-5.0306e-04],\n",
       "        [-9.4366e-04],\n",
       "        [-3.0400e+02],\n",
       "        [-8.1299e-02],\n",
       "        [-2.5725e+02],\n",
       "        [-6.2375e+01],\n",
       "        [-1.4262e+02],\n",
       "        [-3.0853e-02],\n",
       "        [-4.4739e-02],\n",
       "        [-1.1646e-01],\n",
       "        [-1.1365e-01],\n",
       "        [-6.1625e+01],\n",
       "        [-1.5993e-03],\n",
       "        [-1.7512e+02],\n",
       "        [-1.2627e-02],\n",
       "        [-6.4270e-02],\n",
       "        [-7.6599e-02],\n",
       "        [-1.8994e-01],\n",
       "        [-3.7789e-05],\n",
       "        [-2.6035e-04],\n",
       "        [-2.3600e+02],\n",
       "        [-2.4162e+02],\n",
       "        [-6.2418e-04],\n",
       "        [-4.3915e-02],\n",
       "        [-1.8012e+02],\n",
       "        [-3.4142e-04],\n",
       "        [-7.7148e-02],\n",
       "        [-4.0400e+02],\n",
       "        [-1.1133e-01],\n",
       "        [-8.6060e-02],\n",
       "        [-1.7425e+02],\n",
       "        [-4.6275e+02],\n",
       "        [-7.0557e-02],\n",
       "        [-1.2854e-01],\n",
       "        [-3.3936e-02],\n",
       "        [-4.0253e-02],\n",
       "        [-1.9765e-04],\n",
       "        [-6.9519e-02],\n",
       "        [-5.9625e+01],\n",
       "        [-6.2103e-02],\n",
       "        [-1.0619e+02],\n",
       "        [-9.3842e-04],\n",
       "        [-1.1680e+01],\n",
       "        [-5.9600e+02],\n",
       "        [-3.6594e+01],\n",
       "        [-2.6575e+02],\n",
       "        [-2.1985e-01],\n",
       "        [-4.8876e-04],\n",
       "        [-3.3813e-02],\n",
       "        [-9.7847e-04],\n",
       "        [-7.6688e+01],\n",
       "        [-2.1662e+02],\n",
       "        [-4.6156e+01],\n",
       "        [-1.6431e-01],\n",
       "        [-7.0438e+01],\n",
       "        [-6.1321e-04],\n",
       "        [-2.0456e-04],\n",
       "        [-1.7490e-03],\n",
       "        [-2.4162e+02],\n",
       "        [-9.2041e-02],\n",
       "        [-4.3549e-02],\n",
       "        [-3.2575e+02],\n",
       "        [-1.6317e-03],\n",
       "        [-5.5389e-02],\n",
       "        [-5.6744e-04],\n",
       "        [-1.5707e-03],\n",
       "        [-9.1750e+01],\n",
       "        [-1.1499e-01],\n",
       "        [-3.4943e-02],\n",
       "        [-2.7347e-04],\n",
       "        [-2.5453e+01],\n",
       "        [-4.9000e+01],\n",
       "        [-2.3234e-04],\n",
       "        [-4.3869e-04],\n",
       "        [-2.6150e+02],\n",
       "        [-1.3050e+02],\n",
       "        [-3.2675e+02],\n",
       "        [-1.3367e-01],\n",
       "        [-7.0839e-03],\n",
       "        [-5.9680e+04],\n",
       "        [-1.3971e-03],\n",
       "        [-1.5735e-01],\n",
       "        [-1.1549e-03],\n",
       "        [-8.7125e+01],\n",
       "        [-1.0738e+02],\n",
       "        [-4.7333e-02],\n",
       "        [-2.3275e+02],\n",
       "        [-2.8362e-03],\n",
       "        [-1.8062e+02],\n",
       "        [-3.6000e+01],\n",
       "        [-1.7227e-02],\n",
       "        [-3.1500e+02],\n",
       "        [-2.5275e+02],\n",
       "        [-9.8038e-04],\n",
       "        [-4.4465e-04],\n",
       "        [-3.1900e+02],\n",
       "        [-1.1669e+02],\n",
       "        [-2.7078e+01],\n",
       "        [-6.9275e-02],\n",
       "        [-1.8167e-03],\n",
       "        [-3.9434e-04],\n",
       "        [-9.4223e-04],\n",
       "        [-2.4200e+02],\n",
       "        [-7.8979e-02],\n",
       "        [-1.6584e-03],\n",
       "        [-2.8825e+02],\n",
       "        [-5.0783e-04],\n",
       "        [-9.1492e-02],\n",
       "        [-1.7869e-04],\n",
       "        [-4.8812e+01],\n",
       "        [-2.9200e+02],\n",
       "        [-1.1420e-01],\n",
       "        [-6.6772e-02],\n",
       "        [-3.6750e+02],\n",
       "        [-1.4112e+02],\n",
       "        [-1.6375e+02],\n",
       "        [-8.1500e+01],\n",
       "        [-1.3125e+02],\n",
       "        [-3.6931e-04],\n",
       "        [-3.9500e+01],\n",
       "        [-3.9175e+02],\n",
       "        [-1.9526e-04],\n",
       "        [-1.4538e+02],\n",
       "        [-3.7100e+02],\n",
       "        [-7.3792e-02],\n",
       "        [-2.7442e-04],\n",
       "        [-1.2650e+02]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val = w.amin(dim=1, keepdim=True)\n",
    "assert torch.isnan(min_val).sum() == 0\n",
    "min_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isinf(torch.tensor([float('-inf')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_int = 2**w_bits - 1\n",
    "min_int = 0\n",
    "scales = (max_val - min_val).clamp(min=1e-5) / max_int\n",
    "\n",
    "assert torch.isnan(scales).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4996e+01],\n",
       "        [-1.4996e+01],\n",
       "        [-1.4994e+01],\n",
       "        [-3.9710e-02],\n",
       "        [-1.5000e+01],\n",
       "        [-2.7638e-02],\n",
       "        [-8.6356e-03],\n",
       "        [-8.4994e-03],\n",
       "        [-1.4997e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-3.9166e-05],\n",
       "        [-2.5095e-03],\n",
       "        [-1.4995e+01],\n",
       "        [-1.9540e-04],\n",
       "        [-2.9425e-05],\n",
       "        [-7.7956e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-1.4998e+01],\n",
       "        [-1.4999e+01],\n",
       "        [-1.4999e+01],\n",
       "        [-1.4984e+01],\n",
       "        [-2.1749e-02],\n",
       "        [-1.4994e+01],\n",
       "        [-7.4835e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-3.2794e-04],\n",
       "        [-1.4992e+01],\n",
       "        [-8.4058e-03],\n",
       "        [-7.3084e-03],\n",
       "        [-2.5604e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4993e+01],\n",
       "        [-2.4332e-04],\n",
       "        [-8.6652e-05],\n",
       "        [-1.4965e+01],\n",
       "        [-1.4999e+01],\n",
       "        [-5.0101e-05],\n",
       "        [-1.6053e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4993e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-6.1985e-05],\n",
       "        [-3.7321e-03],\n",
       "        [-3.6810e-04],\n",
       "        [-1.6756e-02],\n",
       "        [-5.9243e-03],\n",
       "        [-9.1148e-05],\n",
       "        [-1.4993e+01],\n",
       "        [-6.3767e-05],\n",
       "        [-3.2517e-04],\n",
       "        [-1.4999e+01],\n",
       "        [-1.4993e+01],\n",
       "        [-1.0700e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-5.0865e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-9.3716e-03],\n",
       "        [-1.4995e+01],\n",
       "        [-1.2085e-05],\n",
       "        [-2.0921e-05],\n",
       "        [-1.5639e-04],\n",
       "        [-1.4998e+01],\n",
       "        [-3.0224e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.3707e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-2.4274e-05],\n",
       "        [-2.6711e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.3337e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4982e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-2.7912e-01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.9787e-05],\n",
       "        [-1.4997e+01],\n",
       "        [-3.0484e-05],\n",
       "        [-8.4000e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-7.1676e-05],\n",
       "        [-1.4966e+01],\n",
       "        [-5.9619e-03],\n",
       "        [-6.9894e-03],\n",
       "        [-1.4999e+01],\n",
       "        [-7.8171e-03],\n",
       "        [-9.4125e-05],\n",
       "        [-1.4722e-03],\n",
       "        [-1.4995e+01],\n",
       "        [-9.2492e-03],\n",
       "        [-1.4534e-05],\n",
       "        [-1.4975e+01],\n",
       "        [-6.9066e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-5.4815e-02],\n",
       "        [-6.5277e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4996e+01],\n",
       "        [-1.4999e+01],\n",
       "        [-1.4999e+01],\n",
       "        [-3.4733e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-4.9381e-05],\n",
       "        [-3.5545e-03],\n",
       "        [-1.4992e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.8454e-05],\n",
       "        [-6.0434e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-4.3823e-04],\n",
       "        [-1.4981e+01],\n",
       "        [-9.1761e-06],\n",
       "        [-4.8463e-05],\n",
       "        [-1.4993e+01],\n",
       "        [-1.4977e+01],\n",
       "        [-2.5887e-03],\n",
       "        [-1.4998e+01],\n",
       "        [-9.2870e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-5.8215e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.1891e-03],\n",
       "        [-1.4994e+01],\n",
       "        [-6.4260e-03],\n",
       "        [-1.4994e+01],\n",
       "        [-6.4672e-04],\n",
       "        [-3.9682e-05],\n",
       "        [-4.2352e-03],\n",
       "        [-3.3256e-05],\n",
       "        [-8.2340e-05],\n",
       "        [-6.6874e-03],\n",
       "        [-1.4995e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-3.4427e-03],\n",
       "        [-1.4768e+01],\n",
       "        [-6.7037e-03],\n",
       "        [-1.4996e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5382e-02],\n",
       "        [-1.0823e-02],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4998e+01],\n",
       "        [-1.4998e+01],\n",
       "        [-2.7802e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-5.6697e-05],\n",
       "        [-3.8799e-04],\n",
       "        [-1.4998e+01],\n",
       "        [-1.4967e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-2.1274e-03],\n",
       "        [-6.9993e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4635e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4999e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4999e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-3.8288e-05],\n",
       "        [-6.1994e-05],\n",
       "        [-1.4997e+01],\n",
       "        [-1.4995e+01],\n",
       "        [-4.1471e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-9.4620e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-6.7356e-03],\n",
       "        [-2.1517e-04],\n",
       "        [-3.6990e-03],\n",
       "        [-4.5159e-02],\n",
       "        [        nan],\n",
       "        [-1.0752e-03],\n",
       "        [-1.4996e+01],\n",
       "        [-1.4998e+01],\n",
       "        [-1.3744e-04],\n",
       "        [-2.1822e-04],\n",
       "        [-2.1936e-02],\n",
       "        [-3.3018e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4990e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-4.8589e-02],\n",
       "        [-1.8213e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-6.2413e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4981e+01],\n",
       "        [-3.2299e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4994e+01],\n",
       "        [-1.4994e+01],\n",
       "        [-4.9162e-03],\n",
       "        [-2.1496e-02],\n",
       "        [-1.5970e-03],\n",
       "        [-4.1429e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.2741e-02],\n",
       "        [-1.5000e+01],\n",
       "        [-4.9246e-05],\n",
       "        [-5.6058e-05],\n",
       "        [-1.4384e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-6.8127e-04],\n",
       "        [-4.8784e-04],\n",
       "        [-7.6691e-05],\n",
       "        [-1.4992e+01],\n",
       "        [-3.6017e-04],\n",
       "        [-8.0256e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-4.2000e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.2247e-04],\n",
       "        [-1.4986e+01],\n",
       "        [-2.1019e-03],\n",
       "        [-2.1829e-03],\n",
       "        [-1.8992e-02],\n",
       "        [-1.4997e+01],\n",
       "        [-1.4994e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.1551e-04],\n",
       "        [-1.4993e+01],\n",
       "        [-2.0875e-05],\n",
       "        [-3.5074e-05],\n",
       "        [-1.3073e-02],\n",
       "        [-6.8847e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-4.9964e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4999e+01],\n",
       "        [-5.8415e-03],\n",
       "        [-1.4992e+01],\n",
       "        [-1.4518e-05],\n",
       "        [-1.4988e+01],\n",
       "        [-6.9025e-04],\n",
       "        [-1.1058e-05],\n",
       "        [-6.6148e-03],\n",
       "        [-1.0831e-04],\n",
       "        [-1.4657e+01],\n",
       "        [-1.4969e+01],\n",
       "        [-8.2110e-03],\n",
       "        [-1.4983e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-8.3832e-03],\n",
       "        [-2.7959e-05],\n",
       "        [-1.0434e-03],\n",
       "        [-1.4987e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.7520e-04],\n",
       "        [-1.4910e+01],\n",
       "        [-1.7979e-02],\n",
       "        [-1.4998e+01],\n",
       "        [-4.2443e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4999e+01],\n",
       "        [-7.2837e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-6.1197e-02],\n",
       "        [-1.4999e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5486e-04],\n",
       "        [-2.7695e-05],\n",
       "        [-1.2125e-04],\n",
       "        [-2.4039e-04],\n",
       "        [-2.4874e-03],\n",
       "        [-3.7229e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4996e+01],\n",
       "        [-1.4988e+01],\n",
       "        [-1.4989e+01],\n",
       "        [-4.2514e-03],\n",
       "        [-4.1298e-04],\n",
       "        [-5.3182e-05],\n",
       "        [-1.4999e+01],\n",
       "        [-2.4237e-04],\n",
       "        [-1.8341e-03],\n",
       "        [-1.4998e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-3.2433e-03],\n",
       "        [-1.4997e+01],\n",
       "        [-1.3129e-04],\n",
       "        [-1.4995e+01],\n",
       "        [-6.1338e-05],\n",
       "        [-1.5423e-02],\n",
       "        [-1.3488e-05],\n",
       "        [-3.5053e-03],\n",
       "        [-1.4993e+01],\n",
       "        [-1.4992e+01],\n",
       "        [-3.4300e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4983e+01],\n",
       "        [-7.2399e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-1.4999e+01],\n",
       "        [-6.7857e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4987e+01],\n",
       "        [-8.6505e-05],\n",
       "        [-1.4995e+01],\n",
       "        [-1.4998e+01],\n",
       "        [-1.1933e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-4.6888e-05],\n",
       "        [-9.6897e-05],\n",
       "        [-1.9700e-04],\n",
       "        [-1.4993e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-9.7936e-05],\n",
       "        [-5.2229e-05],\n",
       "        [-4.8355e-05],\n",
       "        [-5.5260e-03],\n",
       "        [-1.4995e+01],\n",
       "        [-1.4998e+01],\n",
       "        [-7.6103e-04],\n",
       "        [-6.9226e-06],\n",
       "        [-8.1504e-03],\n",
       "        [-2.1261e-03],\n",
       "        [-1.4999e+01],\n",
       "        [-1.4991e+01],\n",
       "        [-1.9336e-04],\n",
       "        [-1.4994e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.0533e-02],\n",
       "        [-9.8967e-03],\n",
       "        [-1.4981e+01],\n",
       "        [-1.3929e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-3.3843e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.7952e-02],\n",
       "        [-1.4994e+01],\n",
       "        [-1.4998e+01],\n",
       "        [-2.2869e-03],\n",
       "        [-1.1627e-02],\n",
       "        [-1.8121e-03],\n",
       "        [-1.4981e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4999e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-2.6070e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.2570e-03],\n",
       "        [-5.9088e-03],\n",
       "        [-6.5214e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-6.0139e-03],\n",
       "        [-6.2873e-03],\n",
       "        [-3.4786e-03],\n",
       "        [-4.6742e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-4.2159e-05],\n",
       "        [-1.4999e+01],\n",
       "        [-6.3142e-04],\n",
       "        [-4.8417e-05],\n",
       "        [-1.4996e+01],\n",
       "        [-1.4993e+01],\n",
       "        [-1.4992e+01],\n",
       "        [-8.6403e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-6.6477e-02],\n",
       "        [-1.0374e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4994e+01],\n",
       "        [-1.3675e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-8.5998e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4991e+01],\n",
       "        [-1.4995e+01],\n",
       "        [-1.4995e+01],\n",
       "        [-8.8875e-03],\n",
       "        [-3.6937e-03],\n",
       "        [-1.4993e+01],\n",
       "        [-1.4995e+01],\n",
       "        [-2.4755e-03],\n",
       "        [-1.4999e+01],\n",
       "        [-8.7688e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-2.1684e-03],\n",
       "        [-1.4974e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-6.0483e-03],\n",
       "        [-7.1230e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4747e-04],\n",
       "        [-1.8816e-03],\n",
       "        [-1.4998e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-2.1682e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-4.6503e-03],\n",
       "        [-1.8473e+00],\n",
       "        [-1.4992e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-3.3652e-05],\n",
       "        [-4.3424e-04],\n",
       "        [-1.0454e-03],\n",
       "        [-1.4998e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-2.8502e-05],\n",
       "        [-1.4997e+01],\n",
       "        [-8.3357e-06],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.7079e-03],\n",
       "        [-5.1362e-05],\n",
       "        [-2.7391e-05],\n",
       "        [-3.8908e-02],\n",
       "        [-8.9714e-05],\n",
       "        [-7.7465e-03],\n",
       "        [-2.3063e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4998e+01],\n",
       "        [-6.2420e-04],\n",
       "        [-2.9299e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-9.2013e-05],\n",
       "        [-8.1248e-05],\n",
       "        [-1.4999e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4992e+01],\n",
       "        [-2.2668e-04],\n",
       "        [-1.0233e-03],\n",
       "        [-9.7063e-03],\n",
       "        [-2.2940e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4985e+01],\n",
       "        [-1.5164e-02],\n",
       "        [-1.3121e-02],\n",
       "        [-1.4995e+01],\n",
       "        [-2.4811e-05],\n",
       "        [-1.4986e+01],\n",
       "        [-8.3490e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.1766e-02],\n",
       "        [-2.7124e-03],\n",
       "        [-9.9543e-03],\n",
       "        [-6.9598e-06],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-3.2074e-04],\n",
       "        [-1.4985e+01],\n",
       "        [-2.8764e-03],\n",
       "        [-3.5603e-05],\n",
       "        [-2.5424e-05],\n",
       "        [-1.5507e-02],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4985e+01],\n",
       "        [-6.8513e-03],\n",
       "        [-7.8810e-03],\n",
       "        [-7.4349e-05],\n",
       "        [-7.8467e-03],\n",
       "        [-3.2547e-03],\n",
       "        [-7.1487e-01],\n",
       "        [-1.4985e+01],\n",
       "        [-3.1081e-03],\n",
       "        [-1.3593e-04],\n",
       "        [-1.4997e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-1.4996e+01],\n",
       "        [-7.6155e-02],\n",
       "        [-1.4996e+01],\n",
       "        [-2.3479e-06],\n",
       "        [-8.4481e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-2.7695e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4994e+01],\n",
       "        [-1.4996e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.9236e-03],\n",
       "        [-6.6717e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4980e+01],\n",
       "        [-1.4992e+01],\n",
       "        [-1.4993e+01],\n",
       "        [-1.6004e-01],\n",
       "        [-1.4998e+01],\n",
       "        [-1.4999e+01],\n",
       "        [-1.4995e+01],\n",
       "        [-1.5525e-03],\n",
       "        [-1.4960e+01],\n",
       "        [-5.5933e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4996e+01],\n",
       "        [-6.0898e-04],\n",
       "        [-1.2598e-02],\n",
       "        [-5.0783e-03],\n",
       "        [-1.4876e-03],\n",
       "        [-1.4992e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4995e+01],\n",
       "        [-1.1307e-05],\n",
       "        [-1.4992e+01],\n",
       "        [-4.8545e-03],\n",
       "        [-1.4999e+01],\n",
       "        [-1.4993e+01],\n",
       "        [-1.4900e+01],\n",
       "        [-1.4991e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-6.2994e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-2.5061e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4985e+01],\n",
       "        [-3.2666e-05],\n",
       "        [-5.3241e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4995e+01],\n",
       "        [-1.4987e+01],\n",
       "        [-6.2301e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-2.4884e-03],\n",
       "        [-1.1736e-05],\n",
       "        [-2.3589e-03],\n",
       "        [-7.8391e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5247e-04],\n",
       "        [-3.2359e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-9.8777e-05],\n",
       "        [-1.4969e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4989e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-3.4064e-03],\n",
       "        [-7.0679e-04],\n",
       "        [-9.2046e-03],\n",
       "        [-2.7516e-05],\n",
       "        [-1.7185e-04],\n",
       "        [-2.2935e-03],\n",
       "        [-2.7474e-04],\n",
       "        [-8.9899e-03],\n",
       "        [-1.4996e+01],\n",
       "        [-5.1824e-05],\n",
       "        [-6.5404e-03],\n",
       "        [-1.3969e-03],\n",
       "        [-4.2214e-05],\n",
       "        [-1.3048e-05],\n",
       "        [-3.5162e-05],\n",
       "        [-6.3478e-03],\n",
       "        [-1.6923e-05],\n",
       "        [-4.8042e-04],\n",
       "        [-1.4989e+01],\n",
       "        [-1.2607e-05],\n",
       "        [-2.9037e-02],\n",
       "        [-2.8395e-02],\n",
       "        [-1.4994e+01],\n",
       "        [-2.2107e-03],\n",
       "        [-9.2034e-03],\n",
       "        [-1.4999e+01],\n",
       "        [-2.1969e-04],\n",
       "        [-3.4540e-05],\n",
       "        [-1.4999e+01],\n",
       "        [-7.8590e-05],\n",
       "        [-1.4996e+01],\n",
       "        [-1.4994e+01],\n",
       "        [-7.1218e-05],\n",
       "        [-8.1916e-03],\n",
       "        [-1.4953e+01],\n",
       "        [-2.7347e-02],\n",
       "        [-1.9654e-02],\n",
       "        [-4.8941e-03],\n",
       "        [-6.4408e-01],\n",
       "        [-2.3591e-03],\n",
       "        [-1.4998e+01],\n",
       "        [-6.6374e-03],\n",
       "        [-2.0198e-03],\n",
       "        [-1.7646e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.6947e-03],\n",
       "        [-5.1677e-03],\n",
       "        [-5.1817e-03],\n",
       "        [-6.2736e-03],\n",
       "        [-4.5865e-06],\n",
       "        [-2.7599e-02],\n",
       "        [-3.5695e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.9043e-05],\n",
       "        [-4.4704e-03],\n",
       "        [-1.4998e+01],\n",
       "        [-3.1267e-03],\n",
       "        [-2.3673e-03],\n",
       "        [-1.4998e+01],\n",
       "        [-1.4998e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-3.7149e-06],\n",
       "        [-7.8172e-04],\n",
       "        [-5.2765e-05],\n",
       "        [-9.1981e-04],\n",
       "        [-9.4506e-03],\n",
       "        [-4.1780e-04],\n",
       "        [-4.6369e-03],\n",
       "        [-2.2968e-03],\n",
       "        [-1.0864e-02],\n",
       "        [-1.5000e+01],\n",
       "        [-2.2942e-04],\n",
       "        [-4.2709e-03],\n",
       "        [-3.6192e-03],\n",
       "        [-1.6666e-02],\n",
       "        [-8.1355e-05],\n",
       "        [-1.9910e-05],\n",
       "        [-4.7619e-05],\n",
       "        [-1.4997e+01],\n",
       "        [-2.5783e-01],\n",
       "        [-1.4989e+01],\n",
       "        [-1.4995e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.0647e-02],\n",
       "        [-1.7020e-03],\n",
       "        [-4.5053e-02],\n",
       "        [-7.0410e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4311e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-1.6308e-03],\n",
       "        [-3.3150e-03],\n",
       "        [-5.7356e-03],\n",
       "        [-3.2125e-02],\n",
       "        [-2.8792e-06],\n",
       "        [-5.0850e-06],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.0632e-04],\n",
       "        [-2.6503e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.3995e-04],\n",
       "        [-6.7743e-03],\n",
       "        [-1.4999e+01],\n",
       "        [-4.7392e-02],\n",
       "        [-7.3362e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4999e+01],\n",
       "        [-6.3633e-03],\n",
       "        [-4.6699e-03],\n",
       "        [-3.1833e-03],\n",
       "        [-1.8212e-03],\n",
       "        [-1.3710e-05],\n",
       "        [-7.3855e-03],\n",
       "        [-1.4993e+01],\n",
       "        [-3.1359e-03],\n",
       "        [-1.4978e+01],\n",
       "        [-7.0031e-05],\n",
       "        [-1.4855e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4991e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4475e-01],\n",
       "        [-8.6645e-04],\n",
       "        [-3.2584e-03],\n",
       "        [-5.5022e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4996e+01],\n",
       "        [-1.4976e+01],\n",
       "        [-1.5707e-02],\n",
       "        [-1.4988e+01],\n",
       "        [-2.2048e-04],\n",
       "        [-2.8264e-05],\n",
       "        [-1.5298e-04],\n",
       "        [-1.4998e+01],\n",
       "        [-4.2080e-03],\n",
       "        [-1.7399e-02],\n",
       "        [-1.5000e+01],\n",
       "        [-4.3439e-04],\n",
       "        [-1.8956e-03],\n",
       "        [-2.5920e-03],\n",
       "        [-1.3208e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-1.1075e-02],\n",
       "        [-1.9068e-02],\n",
       "        [-7.2722e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4982e+01],\n",
       "        [-1.7436e-05],\n",
       "        [-1.2895e-04],\n",
       "        [-1.4995e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-1.4998e+01],\n",
       "        [-1.3223e-02],\n",
       "        [-3.3335e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-7.4980e-05],\n",
       "        [-4.6823e-02],\n",
       "        [-2.3977e-04],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4978e+01],\n",
       "        [-7.5443e-03],\n",
       "        [-1.4996e+01],\n",
       "        [-1.3614e-04],\n",
       "        [-1.4994e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-4.7866e-03],\n",
       "        [-1.4999e+01],\n",
       "        [-1.4996e+01],\n",
       "        [-7.5802e-05],\n",
       "        [-3.0438e-05],\n",
       "        [-1.4996e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4960e+01],\n",
       "        [-2.5379e-02],\n",
       "        [-1.9964e-04],\n",
       "        [-8.1658e-05],\n",
       "        [-1.0567e-04],\n",
       "        [-1.4994e+01],\n",
       "        [-8.0207e-03],\n",
       "        [-8.5266e-05],\n",
       "        [-1.4998e+01],\n",
       "        [-2.6681e-05],\n",
       "        [-1.1733e-02],\n",
       "        [-5.4983e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-2.7316e-02],\n",
       "        [-8.5603e-03],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-4.0288e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5000e+01],\n",
       "        [-1.5325e-05],\n",
       "        [-1.5000e+01],\n",
       "        [-1.4997e+01],\n",
       "        [-3.0212e-02],\n",
       "        [-1.9035e-05],\n",
       "        [-1.4997e+01]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = min_val / scales\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ nan],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -2.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -1.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -1.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [-15.],\n",
       "        [-15.],\n",
       "        [ -0.],\n",
       "        [ -0.],\n",
       "        [-15.]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(min_val / scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m zeros \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mround(min_val \u001b[38;5;241m/\u001b[39m scales))\u001b[38;5;241m.\u001b[39mclamp_(min_int, max_int)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(zeros)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "zeros = (-torch.round(min_val / scales)).clamp_(min_int, max_int)\n",
    "\n",
    "assert torch.isnan(zeros).sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_w = (\n",
    "    torch.clamp(torch.round(w / scales) + zeros, min_int, max_int) - zeros\n",
    ") * scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.1934, -2.0527, -1.5742,  ...,  0.4292,  0.4929,  0.5723],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<Unique2Backward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madge = q_w.unique()\n",
    "madge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.isnan(q_w).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).data.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awq.quantizer import Blip2ForImageTextRetrievalAWQQuantizer\n",
    "quantizer = Blip2ForImageTextRetrievalAWQQuantizer(model, device, processor, flickr_dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding inputs for image tokens in BLIP-2 should be done in processing. Please follow instruction here (https://gist.github.com/zucchini-nlp/e9f20b054fa322f84ac9311d9ab67042) to update your BLIP-2 model. Using processors without these attributes in the config is deprecated and will throw an error in v4.47.\n",
      "Quantizing vit_layers:   0%|          | 0/39 [00:00<?, ?it/s]\n",
      "Quantizing qformer_layers: 100%|██████████| 12/12 [00:32<00:00,  2.70s/it]\n"
     ]
    }
   ],
   "source": [
    "quantizer.quantize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blip2ForImageTextRetrieval(\n",
       "  (vision_model): Blip2VisionModel(\n",
       "    (embeddings): Blip2VisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n",
       "    )\n",
       "    (encoder): Blip2Encoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-38): 39 x Blip2EncoderLayer(\n",
       "          (self_attn): Blip2Attention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "            (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Blip2MLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "            (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (embeddings): Blip2TextEmbeddings(\n",
       "    (word_embeddings): Embedding(30523, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "  )\n",
       "  (qformer): Blip2QFormerModel(\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (encoder): Blip2QFormerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): ScaledModule(\n",
       "              (module): Blip2QFormerMultiHeadAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (key): ScaledModule(\n",
       "                (module): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              )\n",
       "              (value): ScaledModule(\n",
       "                (module): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): ScaledModule(\n",
       "              (module): Blip2QFormerMultiHeadAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): ScaledModule(\n",
       "              (module): Blip2QFormerMultiHeadAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (key): ScaledModule(\n",
       "                (module): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              )\n",
       "              (value): ScaledModule(\n",
       "                (module): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): ScaledModule(\n",
       "              (module): Blip2QFormerMultiHeadAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): ScaledModule(\n",
       "              (module): Blip2QFormerMultiHeadAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (key): ScaledModule(\n",
       "                (module): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              )\n",
       "              (value): ScaledModule(\n",
       "                (module): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): ScaledModule(\n",
       "              (module): Blip2QFormerMultiHeadAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): ScaledModule(\n",
       "              (module): Blip2QFormerMultiHeadAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (key): ScaledModule(\n",
       "                (module): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              )\n",
       "              (value): ScaledModule(\n",
       "                (module): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): ScaledModule(\n",
       "              (module): Blip2QFormerMultiHeadAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): ScaledModule(\n",
       "              (module): Blip2QFormerMultiHeadAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (key): ScaledModule(\n",
       "                (module): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              )\n",
       "              (value): ScaledModule(\n",
       "                (module): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): ScaledModule(\n",
       "              (module): Blip2QFormerMultiHeadAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): ScaledModule(\n",
       "              (module): Blip2QFormerMultiHeadAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (crossattention): Blip2QFormerAttention(\n",
       "            (attention): Blip2QFormerMultiHeadAttention(\n",
       "              (query): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (key): ScaledModule(\n",
       "                (module): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              )\n",
       "              (value): ScaledModule(\n",
       "                (module): Linear(in_features=1408, out_features=768, bias=True)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Blip2QFormerLayer(\n",
       "          (attention): Blip2QFormerAttention(\n",
       "            (attention): ScaledModule(\n",
       "              (module): Blip2QFormerMultiHeadAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (output): Blip2QFormerSelfOutput(\n",
       "              (dense): ScaledModule(\n",
       "                (module): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate_query): Blip2QFormerIntermediate(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output_query): Blip2QFormerOutput(\n",
       "            (dense): ScaledModule(\n",
       "              (module): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (vision_projection): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (text_projection): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (itm_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs/nexus-scratch/vla/micromamba/envs/MMQ/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1602: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting text embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [00:11<00:00, 104.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting image embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:53<00:00, 18.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating i2t score matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:14<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating t2i score matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [09:17<00:00,  8.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'scores_i2t': array([[-100., -100.,   nan, ..., -100., -100., -100.],\n",
       "        [-100., -100.,   nan, ..., -100., -100., -100.],\n",
       "        [-100., -100.,   nan, ..., -100., -100., -100.],\n",
       "        ...,\n",
       "        [-100., -100.,   nan, ..., -100., -100., -100.],\n",
       "        [-100., -100.,   nan, ..., -100., -100., -100.],\n",
       "        [-100., -100.,   nan, ..., -100., -100., -100.]], dtype=float32),\n",
       " 'scores_t2i': array([[-100.        , -100.        , -100.        , ..., -100.        ,\n",
       "         -100.        , -100.        ],\n",
       "        [-100.        , -100.        , -100.        , ..., -100.        ,\n",
       "         -100.        , -100.        ],\n",
       "        [          nan,           nan,           nan, ..., -100.        ,\n",
       "         -100.        , -100.        ],\n",
       "        ...,\n",
       "        [-100.        , -100.        , -100.        , ..., -100.        ,\n",
       "         -100.        , -100.        ],\n",
       "        [-100.        , -100.        , -100.        , ...,    0.98516846,\n",
       "            1.3724365 , -100.        ],\n",
       "        [-100.        , -100.        , -100.        , ..., -100.        ,\n",
       "         -100.        , -100.        ]], dtype=float32),\n",
       " 'txt2img': {0: 0,\n",
       "  1: 0,\n",
       "  2: 0,\n",
       "  3: 0,\n",
       "  4: 0,\n",
       "  5: 1,\n",
       "  6: 1,\n",
       "  7: 1,\n",
       "  8: 1,\n",
       "  9: 1,\n",
       "  10: 2,\n",
       "  11: 2,\n",
       "  12: 2,\n",
       "  13: 2,\n",
       "  14: 2,\n",
       "  15: 3,\n",
       "  16: 3,\n",
       "  17: 3,\n",
       "  18: 3,\n",
       "  19: 3,\n",
       "  20: 4,\n",
       "  21: 4,\n",
       "  22: 4,\n",
       "  23: 4,\n",
       "  24: 4,\n",
       "  25: 5,\n",
       "  26: 5,\n",
       "  27: 5,\n",
       "  28: 5,\n",
       "  29: 5,\n",
       "  30: 6,\n",
       "  31: 6,\n",
       "  32: 6,\n",
       "  33: 6,\n",
       "  34: 6,\n",
       "  35: 7,\n",
       "  36: 7,\n",
       "  37: 7,\n",
       "  38: 7,\n",
       "  39: 7,\n",
       "  40: 8,\n",
       "  41: 8,\n",
       "  42: 8,\n",
       "  43: 8,\n",
       "  44: 8,\n",
       "  45: 9,\n",
       "  46: 9,\n",
       "  47: 9,\n",
       "  48: 9,\n",
       "  49: 9,\n",
       "  50: 10,\n",
       "  51: 10,\n",
       "  52: 10,\n",
       "  53: 10,\n",
       "  54: 10,\n",
       "  55: 11,\n",
       "  56: 11,\n",
       "  57: 11,\n",
       "  58: 11,\n",
       "  59: 11,\n",
       "  60: 12,\n",
       "  61: 12,\n",
       "  62: 12,\n",
       "  63: 12,\n",
       "  64: 12,\n",
       "  65: 13,\n",
       "  66: 13,\n",
       "  67: 13,\n",
       "  68: 13,\n",
       "  69: 13,\n",
       "  70: 14,\n",
       "  71: 14,\n",
       "  72: 14,\n",
       "  73: 14,\n",
       "  74: 14,\n",
       "  75: 15,\n",
       "  76: 15,\n",
       "  77: 15,\n",
       "  78: 15,\n",
       "  79: 15,\n",
       "  80: 16,\n",
       "  81: 16,\n",
       "  82: 16,\n",
       "  83: 16,\n",
       "  84: 16,\n",
       "  85: 17,\n",
       "  86: 17,\n",
       "  87: 17,\n",
       "  88: 17,\n",
       "  89: 17,\n",
       "  90: 18,\n",
       "  91: 18,\n",
       "  92: 18,\n",
       "  93: 18,\n",
       "  94: 18,\n",
       "  95: 19,\n",
       "  96: 19,\n",
       "  97: 19,\n",
       "  98: 19,\n",
       "  99: 19,\n",
       "  100: 20,\n",
       "  101: 20,\n",
       "  102: 20,\n",
       "  103: 20,\n",
       "  104: 20,\n",
       "  105: 21,\n",
       "  106: 21,\n",
       "  107: 21,\n",
       "  108: 21,\n",
       "  109: 21,\n",
       "  110: 22,\n",
       "  111: 22,\n",
       "  112: 22,\n",
       "  113: 22,\n",
       "  114: 22,\n",
       "  115: 23,\n",
       "  116: 23,\n",
       "  117: 23,\n",
       "  118: 23,\n",
       "  119: 23,\n",
       "  120: 24,\n",
       "  121: 24,\n",
       "  122: 24,\n",
       "  123: 24,\n",
       "  124: 24,\n",
       "  125: 25,\n",
       "  126: 25,\n",
       "  127: 25,\n",
       "  128: 25,\n",
       "  129: 25,\n",
       "  130: 26,\n",
       "  131: 26,\n",
       "  132: 26,\n",
       "  133: 26,\n",
       "  134: 26,\n",
       "  135: 27,\n",
       "  136: 27,\n",
       "  137: 27,\n",
       "  138: 27,\n",
       "  139: 27,\n",
       "  140: 28,\n",
       "  141: 28,\n",
       "  142: 28,\n",
       "  143: 28,\n",
       "  144: 28,\n",
       "  145: 29,\n",
       "  146: 29,\n",
       "  147: 29,\n",
       "  148: 29,\n",
       "  149: 29,\n",
       "  150: 30,\n",
       "  151: 30,\n",
       "  152: 30,\n",
       "  153: 30,\n",
       "  154: 30,\n",
       "  155: 31,\n",
       "  156: 31,\n",
       "  157: 31,\n",
       "  158: 31,\n",
       "  159: 31,\n",
       "  160: 32,\n",
       "  161: 32,\n",
       "  162: 32,\n",
       "  163: 32,\n",
       "  164: 32,\n",
       "  165: 33,\n",
       "  166: 33,\n",
       "  167: 33,\n",
       "  168: 33,\n",
       "  169: 33,\n",
       "  170: 34,\n",
       "  171: 34,\n",
       "  172: 34,\n",
       "  173: 34,\n",
       "  174: 34,\n",
       "  175: 35,\n",
       "  176: 35,\n",
       "  177: 35,\n",
       "  178: 35,\n",
       "  179: 35,\n",
       "  180: 36,\n",
       "  181: 36,\n",
       "  182: 36,\n",
       "  183: 36,\n",
       "  184: 36,\n",
       "  185: 37,\n",
       "  186: 37,\n",
       "  187: 37,\n",
       "  188: 37,\n",
       "  189: 37,\n",
       "  190: 38,\n",
       "  191: 38,\n",
       "  192: 38,\n",
       "  193: 38,\n",
       "  194: 38,\n",
       "  195: 39,\n",
       "  196: 39,\n",
       "  197: 39,\n",
       "  198: 39,\n",
       "  199: 39,\n",
       "  200: 40,\n",
       "  201: 40,\n",
       "  202: 40,\n",
       "  203: 40,\n",
       "  204: 40,\n",
       "  205: 41,\n",
       "  206: 41,\n",
       "  207: 41,\n",
       "  208: 41,\n",
       "  209: 41,\n",
       "  210: 42,\n",
       "  211: 42,\n",
       "  212: 42,\n",
       "  213: 42,\n",
       "  214: 42,\n",
       "  215: 43,\n",
       "  216: 43,\n",
       "  217: 43,\n",
       "  218: 43,\n",
       "  219: 43,\n",
       "  220: 44,\n",
       "  221: 44,\n",
       "  222: 44,\n",
       "  223: 44,\n",
       "  224: 44,\n",
       "  225: 45,\n",
       "  226: 45,\n",
       "  227: 45,\n",
       "  228: 45,\n",
       "  229: 45,\n",
       "  230: 46,\n",
       "  231: 46,\n",
       "  232: 46,\n",
       "  233: 46,\n",
       "  234: 46,\n",
       "  235: 47,\n",
       "  236: 47,\n",
       "  237: 47,\n",
       "  238: 47,\n",
       "  239: 47,\n",
       "  240: 48,\n",
       "  241: 48,\n",
       "  242: 48,\n",
       "  243: 48,\n",
       "  244: 48,\n",
       "  245: 49,\n",
       "  246: 49,\n",
       "  247: 49,\n",
       "  248: 49,\n",
       "  249: 49,\n",
       "  250: 50,\n",
       "  251: 50,\n",
       "  252: 50,\n",
       "  253: 50,\n",
       "  254: 50,\n",
       "  255: 51,\n",
       "  256: 51,\n",
       "  257: 51,\n",
       "  258: 51,\n",
       "  259: 51,\n",
       "  260: 52,\n",
       "  261: 52,\n",
       "  262: 52,\n",
       "  263: 52,\n",
       "  264: 52,\n",
       "  265: 53,\n",
       "  266: 53,\n",
       "  267: 53,\n",
       "  268: 53,\n",
       "  269: 53,\n",
       "  270: 54,\n",
       "  271: 54,\n",
       "  272: 54,\n",
       "  273: 54,\n",
       "  274: 54,\n",
       "  275: 55,\n",
       "  276: 55,\n",
       "  277: 55,\n",
       "  278: 55,\n",
       "  279: 55,\n",
       "  280: 56,\n",
       "  281: 56,\n",
       "  282: 56,\n",
       "  283: 56,\n",
       "  284: 56,\n",
       "  285: 57,\n",
       "  286: 57,\n",
       "  287: 57,\n",
       "  288: 57,\n",
       "  289: 57,\n",
       "  290: 58,\n",
       "  291: 58,\n",
       "  292: 58,\n",
       "  293: 58,\n",
       "  294: 58,\n",
       "  295: 59,\n",
       "  296: 59,\n",
       "  297: 59,\n",
       "  298: 59,\n",
       "  299: 59,\n",
       "  300: 60,\n",
       "  301: 60,\n",
       "  302: 60,\n",
       "  303: 60,\n",
       "  304: 60,\n",
       "  305: 61,\n",
       "  306: 61,\n",
       "  307: 61,\n",
       "  308: 61,\n",
       "  309: 61,\n",
       "  310: 62,\n",
       "  311: 62,\n",
       "  312: 62,\n",
       "  313: 62,\n",
       "  314: 62,\n",
       "  315: 63,\n",
       "  316: 63,\n",
       "  317: 63,\n",
       "  318: 63,\n",
       "  319: 63,\n",
       "  320: 64,\n",
       "  321: 64,\n",
       "  322: 64,\n",
       "  323: 64,\n",
       "  324: 64,\n",
       "  325: 65,\n",
       "  326: 65,\n",
       "  327: 65,\n",
       "  328: 65,\n",
       "  329: 65,\n",
       "  330: 66,\n",
       "  331: 66,\n",
       "  332: 66,\n",
       "  333: 66,\n",
       "  334: 66,\n",
       "  335: 67,\n",
       "  336: 67,\n",
       "  337: 67,\n",
       "  338: 67,\n",
       "  339: 67,\n",
       "  340: 68,\n",
       "  341: 68,\n",
       "  342: 68,\n",
       "  343: 68,\n",
       "  344: 68,\n",
       "  345: 69,\n",
       "  346: 69,\n",
       "  347: 69,\n",
       "  348: 69,\n",
       "  349: 69,\n",
       "  350: 70,\n",
       "  351: 70,\n",
       "  352: 70,\n",
       "  353: 70,\n",
       "  354: 70,\n",
       "  355: 71,\n",
       "  356: 71,\n",
       "  357: 71,\n",
       "  358: 71,\n",
       "  359: 71,\n",
       "  360: 72,\n",
       "  361: 72,\n",
       "  362: 72,\n",
       "  363: 72,\n",
       "  364: 72,\n",
       "  365: 73,\n",
       "  366: 73,\n",
       "  367: 73,\n",
       "  368: 73,\n",
       "  369: 73,\n",
       "  370: 74,\n",
       "  371: 74,\n",
       "  372: 74,\n",
       "  373: 74,\n",
       "  374: 74,\n",
       "  375: 75,\n",
       "  376: 75,\n",
       "  377: 75,\n",
       "  378: 75,\n",
       "  379: 75,\n",
       "  380: 76,\n",
       "  381: 76,\n",
       "  382: 76,\n",
       "  383: 76,\n",
       "  384: 76,\n",
       "  385: 77,\n",
       "  386: 77,\n",
       "  387: 77,\n",
       "  388: 77,\n",
       "  389: 77,\n",
       "  390: 78,\n",
       "  391: 78,\n",
       "  392: 78,\n",
       "  393: 78,\n",
       "  394: 78,\n",
       "  395: 79,\n",
       "  396: 79,\n",
       "  397: 79,\n",
       "  398: 79,\n",
       "  399: 79,\n",
       "  400: 80,\n",
       "  401: 80,\n",
       "  402: 80,\n",
       "  403: 80,\n",
       "  404: 80,\n",
       "  405: 81,\n",
       "  406: 81,\n",
       "  407: 81,\n",
       "  408: 81,\n",
       "  409: 81,\n",
       "  410: 82,\n",
       "  411: 82,\n",
       "  412: 82,\n",
       "  413: 82,\n",
       "  414: 82,\n",
       "  415: 83,\n",
       "  416: 83,\n",
       "  417: 83,\n",
       "  418: 83,\n",
       "  419: 83,\n",
       "  420: 84,\n",
       "  421: 84,\n",
       "  422: 84,\n",
       "  423: 84,\n",
       "  424: 84,\n",
       "  425: 85,\n",
       "  426: 85,\n",
       "  427: 85,\n",
       "  428: 85,\n",
       "  429: 85,\n",
       "  430: 86,\n",
       "  431: 86,\n",
       "  432: 86,\n",
       "  433: 86,\n",
       "  434: 86,\n",
       "  435: 87,\n",
       "  436: 87,\n",
       "  437: 87,\n",
       "  438: 87,\n",
       "  439: 87,\n",
       "  440: 88,\n",
       "  441: 88,\n",
       "  442: 88,\n",
       "  443: 88,\n",
       "  444: 88,\n",
       "  445: 89,\n",
       "  446: 89,\n",
       "  447: 89,\n",
       "  448: 89,\n",
       "  449: 89,\n",
       "  450: 90,\n",
       "  451: 90,\n",
       "  452: 90,\n",
       "  453: 90,\n",
       "  454: 90,\n",
       "  455: 91,\n",
       "  456: 91,\n",
       "  457: 91,\n",
       "  458: 91,\n",
       "  459: 91,\n",
       "  460: 92,\n",
       "  461: 92,\n",
       "  462: 92,\n",
       "  463: 92,\n",
       "  464: 92,\n",
       "  465: 93,\n",
       "  466: 93,\n",
       "  467: 93,\n",
       "  468: 93,\n",
       "  469: 93,\n",
       "  470: 94,\n",
       "  471: 94,\n",
       "  472: 94,\n",
       "  473: 94,\n",
       "  474: 94,\n",
       "  475: 95,\n",
       "  476: 95,\n",
       "  477: 95,\n",
       "  478: 95,\n",
       "  479: 95,\n",
       "  480: 96,\n",
       "  481: 96,\n",
       "  482: 96,\n",
       "  483: 96,\n",
       "  484: 96,\n",
       "  485: 97,\n",
       "  486: 97,\n",
       "  487: 97,\n",
       "  488: 97,\n",
       "  489: 97,\n",
       "  490: 98,\n",
       "  491: 98,\n",
       "  492: 98,\n",
       "  493: 98,\n",
       "  494: 98,\n",
       "  495: 99,\n",
       "  496: 99,\n",
       "  497: 99,\n",
       "  498: 99,\n",
       "  499: 99,\n",
       "  500: 100,\n",
       "  501: 100,\n",
       "  502: 100,\n",
       "  503: 100,\n",
       "  504: 100,\n",
       "  505: 101,\n",
       "  506: 101,\n",
       "  507: 101,\n",
       "  508: 101,\n",
       "  509: 101,\n",
       "  510: 102,\n",
       "  511: 102,\n",
       "  512: 102,\n",
       "  513: 102,\n",
       "  514: 102,\n",
       "  515: 103,\n",
       "  516: 103,\n",
       "  517: 103,\n",
       "  518: 103,\n",
       "  519: 103,\n",
       "  520: 104,\n",
       "  521: 104,\n",
       "  522: 104,\n",
       "  523: 104,\n",
       "  524: 104,\n",
       "  525: 105,\n",
       "  526: 105,\n",
       "  527: 105,\n",
       "  528: 105,\n",
       "  529: 105,\n",
       "  530: 106,\n",
       "  531: 106,\n",
       "  532: 106,\n",
       "  533: 106,\n",
       "  534: 106,\n",
       "  535: 107,\n",
       "  536: 107,\n",
       "  537: 107,\n",
       "  538: 107,\n",
       "  539: 107,\n",
       "  540: 108,\n",
       "  541: 108,\n",
       "  542: 108,\n",
       "  543: 108,\n",
       "  544: 108,\n",
       "  545: 109,\n",
       "  546: 109,\n",
       "  547: 109,\n",
       "  548: 109,\n",
       "  549: 109,\n",
       "  550: 110,\n",
       "  551: 110,\n",
       "  552: 110,\n",
       "  553: 110,\n",
       "  554: 110,\n",
       "  555: 111,\n",
       "  556: 111,\n",
       "  557: 111,\n",
       "  558: 111,\n",
       "  559: 111,\n",
       "  560: 112,\n",
       "  561: 112,\n",
       "  562: 112,\n",
       "  563: 112,\n",
       "  564: 112,\n",
       "  565: 113,\n",
       "  566: 113,\n",
       "  567: 113,\n",
       "  568: 113,\n",
       "  569: 113,\n",
       "  570: 114,\n",
       "  571: 114,\n",
       "  572: 114,\n",
       "  573: 114,\n",
       "  574: 114,\n",
       "  575: 115,\n",
       "  576: 115,\n",
       "  577: 115,\n",
       "  578: 115,\n",
       "  579: 115,\n",
       "  580: 116,\n",
       "  581: 116,\n",
       "  582: 116,\n",
       "  583: 116,\n",
       "  584: 116,\n",
       "  585: 117,\n",
       "  586: 117,\n",
       "  587: 117,\n",
       "  588: 117,\n",
       "  589: 117,\n",
       "  590: 118,\n",
       "  591: 118,\n",
       "  592: 118,\n",
       "  593: 118,\n",
       "  594: 118,\n",
       "  595: 119,\n",
       "  596: 119,\n",
       "  597: 119,\n",
       "  598: 119,\n",
       "  599: 119,\n",
       "  600: 120,\n",
       "  601: 120,\n",
       "  602: 120,\n",
       "  603: 120,\n",
       "  604: 120,\n",
       "  605: 121,\n",
       "  606: 121,\n",
       "  607: 121,\n",
       "  608: 121,\n",
       "  609: 121,\n",
       "  610: 122,\n",
       "  611: 122,\n",
       "  612: 122,\n",
       "  613: 122,\n",
       "  614: 122,\n",
       "  615: 123,\n",
       "  616: 123,\n",
       "  617: 123,\n",
       "  618: 123,\n",
       "  619: 123,\n",
       "  620: 124,\n",
       "  621: 124,\n",
       "  622: 124,\n",
       "  623: 124,\n",
       "  624: 124,\n",
       "  625: 125,\n",
       "  626: 125,\n",
       "  627: 125,\n",
       "  628: 125,\n",
       "  629: 125,\n",
       "  630: 126,\n",
       "  631: 126,\n",
       "  632: 126,\n",
       "  633: 126,\n",
       "  634: 126,\n",
       "  635: 127,\n",
       "  636: 127,\n",
       "  637: 127,\n",
       "  638: 127,\n",
       "  639: 127,\n",
       "  640: 128,\n",
       "  641: 128,\n",
       "  642: 128,\n",
       "  643: 128,\n",
       "  644: 128,\n",
       "  645: 129,\n",
       "  646: 129,\n",
       "  647: 129,\n",
       "  648: 129,\n",
       "  649: 129,\n",
       "  650: 130,\n",
       "  651: 130,\n",
       "  652: 130,\n",
       "  653: 130,\n",
       "  654: 130,\n",
       "  655: 131,\n",
       "  656: 131,\n",
       "  657: 131,\n",
       "  658: 131,\n",
       "  659: 131,\n",
       "  660: 132,\n",
       "  661: 132,\n",
       "  662: 132,\n",
       "  663: 132,\n",
       "  664: 132,\n",
       "  665: 133,\n",
       "  666: 133,\n",
       "  667: 133,\n",
       "  668: 133,\n",
       "  669: 133,\n",
       "  670: 134,\n",
       "  671: 134,\n",
       "  672: 134,\n",
       "  673: 134,\n",
       "  674: 134,\n",
       "  675: 135,\n",
       "  676: 135,\n",
       "  677: 135,\n",
       "  678: 135,\n",
       "  679: 135,\n",
       "  680: 136,\n",
       "  681: 136,\n",
       "  682: 136,\n",
       "  683: 136,\n",
       "  684: 136,\n",
       "  685: 137,\n",
       "  686: 137,\n",
       "  687: 137,\n",
       "  688: 137,\n",
       "  689: 137,\n",
       "  690: 138,\n",
       "  691: 138,\n",
       "  692: 138,\n",
       "  693: 138,\n",
       "  694: 138,\n",
       "  695: 139,\n",
       "  696: 139,\n",
       "  697: 139,\n",
       "  698: 139,\n",
       "  699: 139,\n",
       "  700: 140,\n",
       "  701: 140,\n",
       "  702: 140,\n",
       "  703: 140,\n",
       "  704: 140,\n",
       "  705: 141,\n",
       "  706: 141,\n",
       "  707: 141,\n",
       "  708: 141,\n",
       "  709: 141,\n",
       "  710: 142,\n",
       "  711: 142,\n",
       "  712: 142,\n",
       "  713: 142,\n",
       "  714: 142,\n",
       "  715: 143,\n",
       "  716: 143,\n",
       "  717: 143,\n",
       "  718: 143,\n",
       "  719: 143,\n",
       "  720: 144,\n",
       "  721: 144,\n",
       "  722: 144,\n",
       "  723: 144,\n",
       "  724: 144,\n",
       "  725: 145,\n",
       "  726: 145,\n",
       "  727: 145,\n",
       "  728: 145,\n",
       "  729: 145,\n",
       "  730: 146,\n",
       "  731: 146,\n",
       "  732: 146,\n",
       "  733: 146,\n",
       "  734: 146,\n",
       "  735: 147,\n",
       "  736: 147,\n",
       "  737: 147,\n",
       "  738: 147,\n",
       "  739: 147,\n",
       "  740: 148,\n",
       "  741: 148,\n",
       "  742: 148,\n",
       "  743: 148,\n",
       "  744: 148,\n",
       "  745: 149,\n",
       "  746: 149,\n",
       "  747: 149,\n",
       "  748: 149,\n",
       "  749: 149,\n",
       "  750: 150,\n",
       "  751: 150,\n",
       "  752: 150,\n",
       "  753: 150,\n",
       "  754: 150,\n",
       "  755: 151,\n",
       "  756: 151,\n",
       "  757: 151,\n",
       "  758: 151,\n",
       "  759: 151,\n",
       "  760: 152,\n",
       "  761: 152,\n",
       "  762: 152,\n",
       "  763: 152,\n",
       "  764: 152,\n",
       "  765: 153,\n",
       "  766: 153,\n",
       "  767: 153,\n",
       "  768: 153,\n",
       "  769: 153,\n",
       "  770: 154,\n",
       "  771: 154,\n",
       "  772: 154,\n",
       "  773: 154,\n",
       "  774: 154,\n",
       "  775: 155,\n",
       "  776: 155,\n",
       "  777: 155,\n",
       "  778: 155,\n",
       "  779: 155,\n",
       "  780: 156,\n",
       "  781: 156,\n",
       "  782: 156,\n",
       "  783: 156,\n",
       "  784: 156,\n",
       "  785: 157,\n",
       "  786: 157,\n",
       "  787: 157,\n",
       "  788: 157,\n",
       "  789: 157,\n",
       "  790: 158,\n",
       "  791: 158,\n",
       "  792: 158,\n",
       "  793: 158,\n",
       "  794: 158,\n",
       "  795: 159,\n",
       "  796: 159,\n",
       "  797: 159,\n",
       "  798: 159,\n",
       "  799: 159,\n",
       "  800: 160,\n",
       "  801: 160,\n",
       "  802: 160,\n",
       "  803: 160,\n",
       "  804: 160,\n",
       "  805: 161,\n",
       "  806: 161,\n",
       "  807: 161,\n",
       "  808: 161,\n",
       "  809: 161,\n",
       "  810: 162,\n",
       "  811: 162,\n",
       "  812: 162,\n",
       "  813: 162,\n",
       "  814: 162,\n",
       "  815: 163,\n",
       "  816: 163,\n",
       "  817: 163,\n",
       "  818: 163,\n",
       "  819: 163,\n",
       "  820: 164,\n",
       "  821: 164,\n",
       "  822: 164,\n",
       "  823: 164,\n",
       "  824: 164,\n",
       "  825: 165,\n",
       "  826: 165,\n",
       "  827: 165,\n",
       "  828: 165,\n",
       "  829: 165,\n",
       "  830: 166,\n",
       "  831: 166,\n",
       "  832: 166,\n",
       "  833: 166,\n",
       "  834: 166,\n",
       "  835: 167,\n",
       "  836: 167,\n",
       "  837: 167,\n",
       "  838: 167,\n",
       "  839: 167,\n",
       "  840: 168,\n",
       "  841: 168,\n",
       "  842: 168,\n",
       "  843: 168,\n",
       "  844: 168,\n",
       "  845: 169,\n",
       "  846: 169,\n",
       "  847: 169,\n",
       "  848: 169,\n",
       "  849: 169,\n",
       "  850: 170,\n",
       "  851: 170,\n",
       "  852: 170,\n",
       "  853: 170,\n",
       "  854: 170,\n",
       "  855: 171,\n",
       "  856: 171,\n",
       "  857: 171,\n",
       "  858: 171,\n",
       "  859: 171,\n",
       "  860: 172,\n",
       "  861: 172,\n",
       "  862: 172,\n",
       "  863: 172,\n",
       "  864: 172,\n",
       "  865: 173,\n",
       "  866: 173,\n",
       "  867: 173,\n",
       "  868: 173,\n",
       "  869: 173,\n",
       "  870: 174,\n",
       "  871: 174,\n",
       "  872: 174,\n",
       "  873: 174,\n",
       "  874: 174,\n",
       "  875: 175,\n",
       "  876: 175,\n",
       "  877: 175,\n",
       "  878: 175,\n",
       "  879: 175,\n",
       "  880: 176,\n",
       "  881: 176,\n",
       "  882: 176,\n",
       "  883: 176,\n",
       "  884: 176,\n",
       "  885: 177,\n",
       "  886: 177,\n",
       "  887: 177,\n",
       "  888: 177,\n",
       "  889: 177,\n",
       "  890: 178,\n",
       "  891: 178,\n",
       "  892: 178,\n",
       "  893: 178,\n",
       "  894: 178,\n",
       "  895: 179,\n",
       "  896: 179,\n",
       "  897: 179,\n",
       "  898: 179,\n",
       "  899: 179,\n",
       "  900: 180,\n",
       "  901: 180,\n",
       "  902: 180,\n",
       "  903: 180,\n",
       "  904: 180,\n",
       "  905: 181,\n",
       "  906: 181,\n",
       "  907: 181,\n",
       "  908: 181,\n",
       "  909: 181,\n",
       "  910: 182,\n",
       "  911: 182,\n",
       "  912: 182,\n",
       "  913: 182,\n",
       "  914: 182,\n",
       "  915: 183,\n",
       "  916: 183,\n",
       "  917: 183,\n",
       "  918: 183,\n",
       "  919: 183,\n",
       "  920: 184,\n",
       "  921: 184,\n",
       "  922: 184,\n",
       "  923: 184,\n",
       "  924: 184,\n",
       "  925: 185,\n",
       "  926: 185,\n",
       "  927: 185,\n",
       "  928: 185,\n",
       "  929: 185,\n",
       "  930: 186,\n",
       "  931: 186,\n",
       "  932: 186,\n",
       "  933: 186,\n",
       "  934: 186,\n",
       "  935: 187,\n",
       "  936: 187,\n",
       "  937: 187,\n",
       "  938: 187,\n",
       "  939: 187,\n",
       "  940: 188,\n",
       "  941: 188,\n",
       "  942: 188,\n",
       "  943: 188,\n",
       "  944: 188,\n",
       "  945: 189,\n",
       "  946: 189,\n",
       "  947: 189,\n",
       "  948: 189,\n",
       "  949: 189,\n",
       "  950: 190,\n",
       "  951: 190,\n",
       "  952: 190,\n",
       "  953: 190,\n",
       "  954: 190,\n",
       "  955: 191,\n",
       "  956: 191,\n",
       "  957: 191,\n",
       "  958: 191,\n",
       "  959: 191,\n",
       "  960: 192,\n",
       "  961: 192,\n",
       "  962: 192,\n",
       "  963: 192,\n",
       "  964: 192,\n",
       "  965: 193,\n",
       "  966: 193,\n",
       "  967: 193,\n",
       "  968: 193,\n",
       "  969: 193,\n",
       "  970: 194,\n",
       "  971: 194,\n",
       "  972: 194,\n",
       "  973: 194,\n",
       "  974: 194,\n",
       "  975: 195,\n",
       "  976: 195,\n",
       "  977: 195,\n",
       "  978: 195,\n",
       "  979: 195,\n",
       "  980: 196,\n",
       "  981: 196,\n",
       "  982: 196,\n",
       "  983: 196,\n",
       "  984: 196,\n",
       "  985: 197,\n",
       "  986: 197,\n",
       "  987: 197,\n",
       "  988: 197,\n",
       "  989: 197,\n",
       "  990: 198,\n",
       "  991: 198,\n",
       "  992: 198,\n",
       "  993: 198,\n",
       "  994: 198,\n",
       "  995: 199,\n",
       "  996: 199,\n",
       "  997: 199,\n",
       "  998: 199,\n",
       "  999: 199,\n",
       "  ...},\n",
       " 'img2txt': {0: [0, 1, 2, 3, 4],\n",
       "  1: [5, 6, 7, 8, 9],\n",
       "  2: [10, 11, 12, 13, 14],\n",
       "  3: [15, 16, 17, 18, 19],\n",
       "  4: [20, 21, 22, 23, 24],\n",
       "  5: [25, 26, 27, 28, 29],\n",
       "  6: [30, 31, 32, 33, 34],\n",
       "  7: [35, 36, 37, 38, 39],\n",
       "  8: [40, 41, 42, 43, 44],\n",
       "  9: [45, 46, 47, 48, 49],\n",
       "  10: [50, 51, 52, 53, 54],\n",
       "  11: [55, 56, 57, 58, 59],\n",
       "  12: [60, 61, 62, 63, 64],\n",
       "  13: [65, 66, 67, 68, 69],\n",
       "  14: [70, 71, 72, 73, 74],\n",
       "  15: [75, 76, 77, 78, 79],\n",
       "  16: [80, 81, 82, 83, 84],\n",
       "  17: [85, 86, 87, 88, 89],\n",
       "  18: [90, 91, 92, 93, 94],\n",
       "  19: [95, 96, 97, 98, 99],\n",
       "  20: [100, 101, 102, 103, 104],\n",
       "  21: [105, 106, 107, 108, 109],\n",
       "  22: [110, 111, 112, 113, 114],\n",
       "  23: [115, 116, 117, 118, 119],\n",
       "  24: [120, 121, 122, 123, 124],\n",
       "  25: [125, 126, 127, 128, 129],\n",
       "  26: [130, 131, 132, 133, 134],\n",
       "  27: [135, 136, 137, 138, 139],\n",
       "  28: [140, 141, 142, 143, 144],\n",
       "  29: [145, 146, 147, 148, 149],\n",
       "  30: [150, 151, 152, 153, 154],\n",
       "  31: [155, 156, 157, 158, 159],\n",
       "  32: [160, 161, 162, 163, 164],\n",
       "  33: [165, 166, 167, 168, 169],\n",
       "  34: [170, 171, 172, 173, 174],\n",
       "  35: [175, 176, 177, 178, 179],\n",
       "  36: [180, 181, 182, 183, 184],\n",
       "  37: [185, 186, 187, 188, 189],\n",
       "  38: [190, 191, 192, 193, 194],\n",
       "  39: [195, 196, 197, 198, 199],\n",
       "  40: [200, 201, 202, 203, 204],\n",
       "  41: [205, 206, 207, 208, 209],\n",
       "  42: [210, 211, 212, 213, 214],\n",
       "  43: [215, 216, 217, 218, 219],\n",
       "  44: [220, 221, 222, 223, 224],\n",
       "  45: [225, 226, 227, 228, 229],\n",
       "  46: [230, 231, 232, 233, 234],\n",
       "  47: [235, 236, 237, 238, 239],\n",
       "  48: [240, 241, 242, 243, 244],\n",
       "  49: [245, 246, 247, 248, 249],\n",
       "  50: [250, 251, 252, 253, 254],\n",
       "  51: [255, 256, 257, 258, 259],\n",
       "  52: [260, 261, 262, 263, 264],\n",
       "  53: [265, 266, 267, 268, 269],\n",
       "  54: [270, 271, 272, 273, 274],\n",
       "  55: [275, 276, 277, 278, 279],\n",
       "  56: [280, 281, 282, 283, 284],\n",
       "  57: [285, 286, 287, 288, 289],\n",
       "  58: [290, 291, 292, 293, 294],\n",
       "  59: [295, 296, 297, 298, 299],\n",
       "  60: [300, 301, 302, 303, 304],\n",
       "  61: [305, 306, 307, 308, 309],\n",
       "  62: [310, 311, 312, 313, 314],\n",
       "  63: [315, 316, 317, 318, 319],\n",
       "  64: [320, 321, 322, 323, 324],\n",
       "  65: [325, 326, 327, 328, 329],\n",
       "  66: [330, 331, 332, 333, 334],\n",
       "  67: [335, 336, 337, 338, 339],\n",
       "  68: [340, 341, 342, 343, 344],\n",
       "  69: [345, 346, 347, 348, 349],\n",
       "  70: [350, 351, 352, 353, 354],\n",
       "  71: [355, 356, 357, 358, 359],\n",
       "  72: [360, 361, 362, 363, 364],\n",
       "  73: [365, 366, 367, 368, 369],\n",
       "  74: [370, 371, 372, 373, 374],\n",
       "  75: [375, 376, 377, 378, 379],\n",
       "  76: [380, 381, 382, 383, 384],\n",
       "  77: [385, 386, 387, 388, 389],\n",
       "  78: [390, 391, 392, 393, 394],\n",
       "  79: [395, 396, 397, 398, 399],\n",
       "  80: [400, 401, 402, 403, 404],\n",
       "  81: [405, 406, 407, 408, 409],\n",
       "  82: [410, 411, 412, 413, 414],\n",
       "  83: [415, 416, 417, 418, 419],\n",
       "  84: [420, 421, 422, 423, 424],\n",
       "  85: [425, 426, 427, 428, 429],\n",
       "  86: [430, 431, 432, 433, 434],\n",
       "  87: [435, 436, 437, 438, 439],\n",
       "  88: [440, 441, 442, 443, 444],\n",
       "  89: [445, 446, 447, 448, 449],\n",
       "  90: [450, 451, 452, 453, 454],\n",
       "  91: [455, 456, 457, 458, 459],\n",
       "  92: [460, 461, 462, 463, 464],\n",
       "  93: [465, 466, 467, 468, 469],\n",
       "  94: [470, 471, 472, 473, 474],\n",
       "  95: [475, 476, 477, 478, 479],\n",
       "  96: [480, 481, 482, 483, 484],\n",
       "  97: [485, 486, 487, 488, 489],\n",
       "  98: [490, 491, 492, 493, 494],\n",
       "  99: [495, 496, 497, 498, 499],\n",
       "  100: [500, 501, 502, 503, 504],\n",
       "  101: [505, 506, 507, 508, 509],\n",
       "  102: [510, 511, 512, 513, 514],\n",
       "  103: [515, 516, 517, 518, 519],\n",
       "  104: [520, 521, 522, 523, 524],\n",
       "  105: [525, 526, 527, 528, 529],\n",
       "  106: [530, 531, 532, 533, 534],\n",
       "  107: [535, 536, 537, 538, 539],\n",
       "  108: [540, 541, 542, 543, 544],\n",
       "  109: [545, 546, 547, 548, 549],\n",
       "  110: [550, 551, 552, 553, 554],\n",
       "  111: [555, 556, 557, 558, 559],\n",
       "  112: [560, 561, 562, 563, 564],\n",
       "  113: [565, 566, 567, 568, 569],\n",
       "  114: [570, 571, 572, 573, 574],\n",
       "  115: [575, 576, 577, 578, 579],\n",
       "  116: [580, 581, 582, 583, 584],\n",
       "  117: [585, 586, 587, 588, 589],\n",
       "  118: [590, 591, 592, 593, 594],\n",
       "  119: [595, 596, 597, 598, 599],\n",
       "  120: [600, 601, 602, 603, 604],\n",
       "  121: [605, 606, 607, 608, 609],\n",
       "  122: [610, 611, 612, 613, 614],\n",
       "  123: [615, 616, 617, 618, 619],\n",
       "  124: [620, 621, 622, 623, 624],\n",
       "  125: [625, 626, 627, 628, 629],\n",
       "  126: [630, 631, 632, 633, 634],\n",
       "  127: [635, 636, 637, 638, 639],\n",
       "  128: [640, 641, 642, 643, 644],\n",
       "  129: [645, 646, 647, 648, 649],\n",
       "  130: [650, 651, 652, 653, 654],\n",
       "  131: [655, 656, 657, 658, 659],\n",
       "  132: [660, 661, 662, 663, 664],\n",
       "  133: [665, 666, 667, 668, 669],\n",
       "  134: [670, 671, 672, 673, 674],\n",
       "  135: [675, 676, 677, 678, 679],\n",
       "  136: [680, 681, 682, 683, 684],\n",
       "  137: [685, 686, 687, 688, 689],\n",
       "  138: [690, 691, 692, 693, 694],\n",
       "  139: [695, 696, 697, 698, 699],\n",
       "  140: [700, 701, 702, 703, 704],\n",
       "  141: [705, 706, 707, 708, 709],\n",
       "  142: [710, 711, 712, 713, 714],\n",
       "  143: [715, 716, 717, 718, 719],\n",
       "  144: [720, 721, 722, 723, 724],\n",
       "  145: [725, 726, 727, 728, 729],\n",
       "  146: [730, 731, 732, 733, 734],\n",
       "  147: [735, 736, 737, 738, 739],\n",
       "  148: [740, 741, 742, 743, 744],\n",
       "  149: [745, 746, 747, 748, 749],\n",
       "  150: [750, 751, 752, 753, 754],\n",
       "  151: [755, 756, 757, 758, 759],\n",
       "  152: [760, 761, 762, 763, 764],\n",
       "  153: [765, 766, 767, 768, 769],\n",
       "  154: [770, 771, 772, 773, 774],\n",
       "  155: [775, 776, 777, 778, 779],\n",
       "  156: [780, 781, 782, 783, 784],\n",
       "  157: [785, 786, 787, 788, 789],\n",
       "  158: [790, 791, 792, 793, 794],\n",
       "  159: [795, 796, 797, 798, 799],\n",
       "  160: [800, 801, 802, 803, 804],\n",
       "  161: [805, 806, 807, 808, 809],\n",
       "  162: [810, 811, 812, 813, 814],\n",
       "  163: [815, 816, 817, 818, 819],\n",
       "  164: [820, 821, 822, 823, 824],\n",
       "  165: [825, 826, 827, 828, 829],\n",
       "  166: [830, 831, 832, 833, 834],\n",
       "  167: [835, 836, 837, 838, 839],\n",
       "  168: [840, 841, 842, 843, 844],\n",
       "  169: [845, 846, 847, 848, 849],\n",
       "  170: [850, 851, 852, 853, 854],\n",
       "  171: [855, 856, 857, 858, 859],\n",
       "  172: [860, 861, 862, 863, 864],\n",
       "  173: [865, 866, 867, 868, 869],\n",
       "  174: [870, 871, 872, 873, 874],\n",
       "  175: [875, 876, 877, 878, 879],\n",
       "  176: [880, 881, 882, 883, 884],\n",
       "  177: [885, 886, 887, 888, 889],\n",
       "  178: [890, 891, 892, 893, 894],\n",
       "  179: [895, 896, 897, 898, 899],\n",
       "  180: [900, 901, 902, 903, 904],\n",
       "  181: [905, 906, 907, 908, 909],\n",
       "  182: [910, 911, 912, 913, 914],\n",
       "  183: [915, 916, 917, 918, 919],\n",
       "  184: [920, 921, 922, 923, 924],\n",
       "  185: [925, 926, 927, 928, 929],\n",
       "  186: [930, 931, 932, 933, 934],\n",
       "  187: [935, 936, 937, 938, 939],\n",
       "  188: [940, 941, 942, 943, 944],\n",
       "  189: [945, 946, 947, 948, 949],\n",
       "  190: [950, 951, 952, 953, 954],\n",
       "  191: [955, 956, 957, 958, 959],\n",
       "  192: [960, 961, 962, 963, 964],\n",
       "  193: [965, 966, 967, 968, 969],\n",
       "  194: [970, 971, 972, 973, 974],\n",
       "  195: [975, 976, 977, 978, 979],\n",
       "  196: [980, 981, 982, 983, 984],\n",
       "  197: [985, 986, 987, 988, 989],\n",
       "  198: [990, 991, 992, 993, 994],\n",
       "  199: [995, 996, 997, 998, 999],\n",
       "  200: [1000, 1001, 1002, 1003, 1004],\n",
       "  201: [1005, 1006, 1007, 1008, 1009],\n",
       "  202: [1010, 1011, 1012, 1013, 1014],\n",
       "  203: [1015, 1016, 1017, 1018, 1019],\n",
       "  204: [1020, 1021, 1022, 1023, 1024],\n",
       "  205: [1025, 1026, 1027, 1028, 1029],\n",
       "  206: [1030, 1031, 1032, 1033, 1034],\n",
       "  207: [1035, 1036, 1037, 1038, 1039],\n",
       "  208: [1040, 1041, 1042, 1043, 1044],\n",
       "  209: [1045, 1046, 1047, 1048, 1049],\n",
       "  210: [1050, 1051, 1052, 1053, 1054],\n",
       "  211: [1055, 1056, 1057, 1058, 1059],\n",
       "  212: [1060, 1061, 1062, 1063, 1064],\n",
       "  213: [1065, 1066, 1067, 1068, 1069],\n",
       "  214: [1070, 1071, 1072, 1073, 1074],\n",
       "  215: [1075, 1076, 1077, 1078, 1079],\n",
       "  216: [1080, 1081, 1082, 1083, 1084],\n",
       "  217: [1085, 1086, 1087, 1088, 1089],\n",
       "  218: [1090, 1091, 1092, 1093, 1094],\n",
       "  219: [1095, 1096, 1097, 1098, 1099],\n",
       "  220: [1100, 1101, 1102, 1103, 1104],\n",
       "  221: [1105, 1106, 1107, 1108, 1109],\n",
       "  222: [1110, 1111, 1112, 1113, 1114],\n",
       "  223: [1115, 1116, 1117, 1118, 1119],\n",
       "  224: [1120, 1121, 1122, 1123, 1124],\n",
       "  225: [1125, 1126, 1127, 1128, 1129],\n",
       "  226: [1130, 1131, 1132, 1133, 1134],\n",
       "  227: [1135, 1136, 1137, 1138, 1139],\n",
       "  228: [1140, 1141, 1142, 1143, 1144],\n",
       "  229: [1145, 1146, 1147, 1148, 1149],\n",
       "  230: [1150, 1151, 1152, 1153, 1154],\n",
       "  231: [1155, 1156, 1157, 1158, 1159],\n",
       "  232: [1160, 1161, 1162, 1163, 1164],\n",
       "  233: [1165, 1166, 1167, 1168, 1169],\n",
       "  234: [1170, 1171, 1172, 1173, 1174],\n",
       "  235: [1175, 1176, 1177, 1178, 1179],\n",
       "  236: [1180, 1181, 1182, 1183, 1184],\n",
       "  237: [1185, 1186, 1187, 1188, 1189],\n",
       "  238: [1190, 1191, 1192, 1193, 1194],\n",
       "  239: [1195, 1196, 1197, 1198, 1199],\n",
       "  240: [1200, 1201, 1202, 1203, 1204],\n",
       "  241: [1205, 1206, 1207, 1208, 1209],\n",
       "  242: [1210, 1211, 1212, 1213, 1214],\n",
       "  243: [1215, 1216, 1217, 1218, 1219],\n",
       "  244: [1220, 1221, 1222, 1223, 1224],\n",
       "  245: [1225, 1226, 1227, 1228, 1229],\n",
       "  246: [1230, 1231, 1232, 1233, 1234],\n",
       "  247: [1235, 1236, 1237, 1238, 1239],\n",
       "  248: [1240, 1241, 1242, 1243, 1244],\n",
       "  249: [1245, 1246, 1247, 1248, 1249],\n",
       "  250: [1250, 1251, 1252, 1253, 1254],\n",
       "  251: [1255, 1256, 1257, 1258, 1259],\n",
       "  252: [1260, 1261, 1262, 1263, 1264],\n",
       "  253: [1265, 1266, 1267, 1268, 1269],\n",
       "  254: [1270, 1271, 1272, 1273, 1274],\n",
       "  255: [1275, 1276, 1277, 1278, 1279],\n",
       "  256: [1280, 1281, 1282, 1283, 1284],\n",
       "  257: [1285, 1286, 1287, 1288, 1289],\n",
       "  258: [1290, 1291, 1292, 1293, 1294],\n",
       "  259: [1295, 1296, 1297, 1298, 1299],\n",
       "  260: [1300, 1301, 1302, 1303, 1304],\n",
       "  261: [1305, 1306, 1307, 1308, 1309],\n",
       "  262: [1310, 1311, 1312, 1313, 1314],\n",
       "  263: [1315, 1316, 1317, 1318, 1319],\n",
       "  264: [1320, 1321, 1322, 1323, 1324],\n",
       "  265: [1325, 1326, 1327, 1328, 1329],\n",
       "  266: [1330, 1331, 1332, 1333, 1334],\n",
       "  267: [1335, 1336, 1337, 1338, 1339],\n",
       "  268: [1340, 1341, 1342, 1343, 1344],\n",
       "  269: [1345, 1346, 1347, 1348, 1349],\n",
       "  270: [1350, 1351, 1352, 1353, 1354],\n",
       "  271: [1355, 1356, 1357, 1358, 1359],\n",
       "  272: [1360, 1361, 1362, 1363, 1364],\n",
       "  273: [1365, 1366, 1367, 1368, 1369],\n",
       "  274: [1370, 1371, 1372, 1373, 1374],\n",
       "  275: [1375, 1376, 1377, 1378, 1379],\n",
       "  276: [1380, 1381, 1382, 1383, 1384],\n",
       "  277: [1385, 1386, 1387, 1388, 1389],\n",
       "  278: [1390, 1391, 1392, 1393, 1394],\n",
       "  279: [1395, 1396, 1397, 1398, 1399],\n",
       "  280: [1400, 1401, 1402, 1403, 1404],\n",
       "  281: [1405, 1406, 1407, 1408, 1409],\n",
       "  282: [1410, 1411, 1412, 1413, 1414],\n",
       "  283: [1415, 1416, 1417, 1418, 1419],\n",
       "  284: [1420, 1421, 1422, 1423, 1424],\n",
       "  285: [1425, 1426, 1427, 1428, 1429],\n",
       "  286: [1430, 1431, 1432, 1433, 1434],\n",
       "  287: [1435, 1436, 1437, 1438, 1439],\n",
       "  288: [1440, 1441, 1442, 1443, 1444],\n",
       "  289: [1445, 1446, 1447, 1448, 1449],\n",
       "  290: [1450, 1451, 1452, 1453, 1454],\n",
       "  291: [1455, 1456, 1457, 1458, 1459],\n",
       "  292: [1460, 1461, 1462, 1463, 1464],\n",
       "  293: [1465, 1466, 1467, 1468, 1469],\n",
       "  294: [1470, 1471, 1472, 1473, 1474],\n",
       "  295: [1475, 1476, 1477, 1478, 1479],\n",
       "  296: [1480, 1481, 1482, 1483, 1484],\n",
       "  297: [1485, 1486, 1487, 1488, 1489],\n",
       "  298: [1490, 1491, 1492, 1493, 1494],\n",
       "  299: [1495, 1496, 1497, 1498, 1499],\n",
       "  300: [1500, 1501, 1502, 1503, 1504],\n",
       "  301: [1505, 1506, 1507, 1508, 1509],\n",
       "  302: [1510, 1511, 1512, 1513, 1514],\n",
       "  303: [1515, 1516, 1517, 1518, 1519],\n",
       "  304: [1520, 1521, 1522, 1523, 1524],\n",
       "  305: [1525, 1526, 1527, 1528, 1529],\n",
       "  306: [1530, 1531, 1532, 1533, 1534],\n",
       "  307: [1535, 1536, 1537, 1538, 1539],\n",
       "  308: [1540, 1541, 1542, 1543, 1544],\n",
       "  309: [1545, 1546, 1547, 1548, 1549],\n",
       "  310: [1550, 1551, 1552, 1553, 1554],\n",
       "  311: [1555, 1556, 1557, 1558, 1559],\n",
       "  312: [1560, 1561, 1562, 1563, 1564],\n",
       "  313: [1565, 1566, 1567, 1568, 1569],\n",
       "  314: [1570, 1571, 1572, 1573, 1574],\n",
       "  315: [1575, 1576, 1577, 1578, 1579],\n",
       "  316: [1580, 1581, 1582, 1583, 1584],\n",
       "  317: [1585, 1586, 1587, 1588, 1589],\n",
       "  318: [1590, 1591, 1592, 1593, 1594],\n",
       "  319: [1595, 1596, 1597, 1598, 1599],\n",
       "  320: [1600, 1601, 1602, 1603, 1604],\n",
       "  321: [1605, 1606, 1607, 1608, 1609],\n",
       "  322: [1610, 1611, 1612, 1613, 1614],\n",
       "  323: [1615, 1616, 1617, 1618, 1619],\n",
       "  324: [1620, 1621, 1622, 1623, 1624],\n",
       "  325: [1625, 1626, 1627, 1628, 1629],\n",
       "  326: [1630, 1631, 1632, 1633, 1634],\n",
       "  327: [1635, 1636, 1637, 1638, 1639],\n",
       "  328: [1640, 1641, 1642, 1643, 1644],\n",
       "  329: [1645, 1646, 1647, 1648, 1649],\n",
       "  330: [1650, 1651, 1652, 1653, 1654],\n",
       "  331: [1655, 1656, 1657, 1658, 1659],\n",
       "  332: [1660, 1661, 1662, 1663, 1664],\n",
       "  333: [1665, 1666, 1667, 1668, 1669],\n",
       "  334: [1670, 1671, 1672, 1673, 1674],\n",
       "  335: [1675, 1676, 1677, 1678, 1679],\n",
       "  336: [1680, 1681, 1682, 1683, 1684],\n",
       "  337: [1685, 1686, 1687, 1688, 1689],\n",
       "  338: [1690, 1691, 1692, 1693, 1694],\n",
       "  339: [1695, 1696, 1697, 1698, 1699],\n",
       "  340: [1700, 1701, 1702, 1703, 1704],\n",
       "  341: [1705, 1706, 1707, 1708, 1709],\n",
       "  342: [1710, 1711, 1712, 1713, 1714],\n",
       "  343: [1715, 1716, 1717, 1718, 1719],\n",
       "  344: [1720, 1721, 1722, 1723, 1724],\n",
       "  345: [1725, 1726, 1727, 1728, 1729],\n",
       "  346: [1730, 1731, 1732, 1733, 1734],\n",
       "  347: [1735, 1736, 1737, 1738, 1739],\n",
       "  348: [1740, 1741, 1742, 1743, 1744],\n",
       "  349: [1745, 1746, 1747, 1748, 1749],\n",
       "  350: [1750, 1751, 1752, 1753, 1754],\n",
       "  351: [1755, 1756, 1757, 1758, 1759],\n",
       "  352: [1760, 1761, 1762, 1763, 1764],\n",
       "  353: [1765, 1766, 1767, 1768, 1769],\n",
       "  354: [1770, 1771, 1772, 1773, 1774],\n",
       "  355: [1775, 1776, 1777, 1778, 1779],\n",
       "  356: [1780, 1781, 1782, 1783, 1784],\n",
       "  357: [1785, 1786, 1787, 1788, 1789],\n",
       "  358: [1790, 1791, 1792, 1793, 1794],\n",
       "  359: [1795, 1796, 1797, 1798, 1799],\n",
       "  360: [1800, 1801, 1802, 1803, 1804],\n",
       "  361: [1805, 1806, 1807, 1808, 1809],\n",
       "  362: [1810, 1811, 1812, 1813, 1814],\n",
       "  363: [1815, 1816, 1817, 1818, 1819],\n",
       "  364: [1820, 1821, 1822, 1823, 1824],\n",
       "  365: [1825, 1826, 1827, 1828, 1829],\n",
       "  366: [1830, 1831, 1832, 1833, 1834],\n",
       "  367: [1835, 1836, 1837, 1838, 1839],\n",
       "  368: [1840, 1841, 1842, 1843, 1844],\n",
       "  369: [1845, 1846, 1847, 1848, 1849],\n",
       "  370: [1850, 1851, 1852, 1853, 1854],\n",
       "  371: [1855, 1856, 1857, 1858, 1859],\n",
       "  372: [1860, 1861, 1862, 1863, 1864],\n",
       "  373: [1865, 1866, 1867, 1868, 1869],\n",
       "  374: [1870, 1871, 1872, 1873, 1874],\n",
       "  375: [1875, 1876, 1877, 1878, 1879],\n",
       "  376: [1880, 1881, 1882, 1883, 1884],\n",
       "  377: [1885, 1886, 1887, 1888, 1889],\n",
       "  378: [1890, 1891, 1892, 1893, 1894],\n",
       "  379: [1895, 1896, 1897, 1898, 1899],\n",
       "  380: [1900, 1901, 1902, 1903, 1904],\n",
       "  381: [1905, 1906, 1907, 1908, 1909],\n",
       "  382: [1910, 1911, 1912, 1913, 1914],\n",
       "  383: [1915, 1916, 1917, 1918, 1919],\n",
       "  384: [1920, 1921, 1922, 1923, 1924],\n",
       "  385: [1925, 1926, 1927, 1928, 1929],\n",
       "  386: [1930, 1931, 1932, 1933, 1934],\n",
       "  387: [1935, 1936, 1937, 1938, 1939],\n",
       "  388: [1940, 1941, 1942, 1943, 1944],\n",
       "  389: [1945, 1946, 1947, 1948, 1949],\n",
       "  390: [1950, 1951, 1952, 1953, 1954],\n",
       "  391: [1955, 1956, 1957, 1958, 1959],\n",
       "  392: [1960, 1961, 1962, 1963, 1964],\n",
       "  393: [1965, 1966, 1967, 1968, 1969],\n",
       "  394: [1970, 1971, 1972, 1973, 1974],\n",
       "  395: [1975, 1976, 1977, 1978, 1979],\n",
       "  396: [1980, 1981, 1982, 1983, 1984],\n",
       "  397: [1985, 1986, 1987, 1988, 1989],\n",
       "  398: [1990, 1991, 1992, 1993, 1994],\n",
       "  399: [1995, 1996, 1997, 1998, 1999],\n",
       "  400: [2000, 2001, 2002, 2003, 2004],\n",
       "  401: [2005, 2006, 2007, 2008, 2009],\n",
       "  402: [2010, 2011, 2012, 2013, 2014],\n",
       "  403: [2015, 2016, 2017, 2018, 2019],\n",
       "  404: [2020, 2021, 2022, 2023, 2024],\n",
       "  405: [2025, 2026, 2027, 2028, 2029],\n",
       "  406: [2030, 2031, 2032, 2033, 2034],\n",
       "  407: [2035, 2036, 2037, 2038, 2039],\n",
       "  408: [2040, 2041, 2042, 2043, 2044],\n",
       "  409: [2045, 2046, 2047, 2048, 2049],\n",
       "  410: [2050, 2051, 2052, 2053, 2054],\n",
       "  411: [2055, 2056, 2057, 2058, 2059],\n",
       "  412: [2060, 2061, 2062, 2063, 2064],\n",
       "  413: [2065, 2066, 2067, 2068, 2069],\n",
       "  414: [2070, 2071, 2072, 2073, 2074],\n",
       "  415: [2075, 2076, 2077, 2078, 2079],\n",
       "  416: [2080, 2081, 2082, 2083, 2084],\n",
       "  417: [2085, 2086, 2087, 2088, 2089],\n",
       "  418: [2090, 2091, 2092, 2093, 2094],\n",
       "  419: [2095, 2096, 2097, 2098, 2099],\n",
       "  420: [2100, 2101, 2102, 2103, 2104],\n",
       "  421: [2105, 2106, 2107, 2108, 2109],\n",
       "  422: [2110, 2111, 2112, 2113, 2114],\n",
       "  423: [2115, 2116, 2117, 2118, 2119],\n",
       "  424: [2120, 2121, 2122, 2123, 2124],\n",
       "  425: [2125, 2126, 2127, 2128, 2129],\n",
       "  426: [2130, 2131, 2132, 2133, 2134],\n",
       "  427: [2135, 2136, 2137, 2138, 2139],\n",
       "  428: [2140, 2141, 2142, 2143, 2144],\n",
       "  429: [2145, 2146, 2147, 2148, 2149],\n",
       "  430: [2150, 2151, 2152, 2153, 2154],\n",
       "  431: [2155, 2156, 2157, 2158, 2159],\n",
       "  432: [2160, 2161, 2162, 2163, 2164],\n",
       "  433: [2165, 2166, 2167, 2168, 2169],\n",
       "  434: [2170, 2171, 2172, 2173, 2174],\n",
       "  435: [2175, 2176, 2177, 2178, 2179],\n",
       "  436: [2180, 2181, 2182, 2183, 2184],\n",
       "  437: [2185, 2186, 2187, 2188, 2189],\n",
       "  438: [2190, 2191, 2192, 2193, 2194],\n",
       "  439: [2195, 2196, 2197, 2198, 2199],\n",
       "  440: [2200, 2201, 2202, 2203, 2204],\n",
       "  441: [2205, 2206, 2207, 2208, 2209],\n",
       "  442: [2210, 2211, 2212, 2213, 2214],\n",
       "  443: [2215, 2216, 2217, 2218, 2219],\n",
       "  444: [2220, 2221, 2222, 2223, 2224],\n",
       "  445: [2225, 2226, 2227, 2228, 2229],\n",
       "  446: [2230, 2231, 2232, 2233, 2234],\n",
       "  447: [2235, 2236, 2237, 2238, 2239],\n",
       "  448: [2240, 2241, 2242, 2243, 2244],\n",
       "  449: [2245, 2246, 2247, 2248, 2249],\n",
       "  450: [2250, 2251, 2252, 2253, 2254],\n",
       "  451: [2255, 2256, 2257, 2258, 2259],\n",
       "  452: [2260, 2261, 2262, 2263, 2264],\n",
       "  453: [2265, 2266, 2267, 2268, 2269],\n",
       "  454: [2270, 2271, 2272, 2273, 2274],\n",
       "  455: [2275, 2276, 2277, 2278, 2279],\n",
       "  456: [2280, 2281, 2282, 2283, 2284],\n",
       "  457: [2285, 2286, 2287, 2288, 2289],\n",
       "  458: [2290, 2291, 2292, 2293, 2294],\n",
       "  459: [2295, 2296, 2297, 2298, 2299],\n",
       "  460: [2300, 2301, 2302, 2303, 2304],\n",
       "  461: [2305, 2306, 2307, 2308, 2309],\n",
       "  462: [2310, 2311, 2312, 2313, 2314],\n",
       "  463: [2315, 2316, 2317, 2318, 2319],\n",
       "  464: [2320, 2321, 2322, 2323, 2324],\n",
       "  465: [2325, 2326, 2327, 2328, 2329],\n",
       "  466: [2330, 2331, 2332, 2333, 2334],\n",
       "  467: [2335, 2336, 2337, 2338, 2339],\n",
       "  468: [2340, 2341, 2342, 2343, 2344],\n",
       "  469: [2345, 2346, 2347, 2348, 2349],\n",
       "  470: [2350, 2351, 2352, 2353, 2354],\n",
       "  471: [2355, 2356, 2357, 2358, 2359],\n",
       "  472: [2360, 2361, 2362, 2363, 2364],\n",
       "  473: [2365, 2366, 2367, 2368, 2369],\n",
       "  474: [2370, 2371, 2372, 2373, 2374],\n",
       "  475: [2375, 2376, 2377, 2378, 2379],\n",
       "  476: [2380, 2381, 2382, 2383, 2384],\n",
       "  477: [2385, 2386, 2387, 2388, 2389],\n",
       "  478: [2390, 2391, 2392, 2393, 2394],\n",
       "  479: [2395, 2396, 2397, 2398, 2399],\n",
       "  480: [2400, 2401, 2402, 2403, 2404],\n",
       "  481: [2405, 2406, 2407, 2408, 2409],\n",
       "  482: [2410, 2411, 2412, 2413, 2414],\n",
       "  483: [2415, 2416, 2417, 2418, 2419],\n",
       "  484: [2420, 2421, 2422, 2423, 2424],\n",
       "  485: [2425, 2426, 2427, 2428, 2429],\n",
       "  486: [2430, 2431, 2432, 2433, 2434],\n",
       "  487: [2435, 2436, 2437, 2438, 2439],\n",
       "  488: [2440, 2441, 2442, 2443, 2444],\n",
       "  489: [2445, 2446, 2447, 2448, 2449],\n",
       "  490: [2450, 2451, 2452, 2453, 2454],\n",
       "  491: [2455, 2456, 2457, 2458, 2459],\n",
       "  492: [2460, 2461, 2462, 2463, 2464],\n",
       "  493: [2465, 2466, 2467, 2468, 2469],\n",
       "  494: [2470, 2471, 2472, 2473, 2474],\n",
       "  495: [2475, 2476, 2477, 2478, 2479],\n",
       "  496: [2480, 2481, 2482, 2483, 2484],\n",
       "  497: [2485, 2486, 2487, 2488, 2489],\n",
       "  498: [2490, 2491, 2492, 2493, 2494],\n",
       "  499: [2495, 2496, 2497, 2498, 2499],\n",
       "  500: [2500, 2501, 2502, 2503, 2504],\n",
       "  501: [2505, 2506, 2507, 2508, 2509],\n",
       "  502: [2510, 2511, 2512, 2513, 2514],\n",
       "  503: [2515, 2516, 2517, 2518, 2519],\n",
       "  504: [2520, 2521, 2522, 2523, 2524],\n",
       "  505: [2525, 2526, 2527, 2528, 2529],\n",
       "  506: [2530, 2531, 2532, 2533, 2534],\n",
       "  507: [2535, 2536, 2537, 2538, 2539],\n",
       "  508: [2540, 2541, 2542, 2543, 2544],\n",
       "  509: [2545, 2546, 2547, 2548, 2549],\n",
       "  510: [2550, 2551, 2552, 2553, 2554],\n",
       "  511: [2555, 2556, 2557, 2558, 2559],\n",
       "  512: [2560, 2561, 2562, 2563, 2564],\n",
       "  513: [2565, 2566, 2567, 2568, 2569],\n",
       "  514: [2570, 2571, 2572, 2573, 2574],\n",
       "  515: [2575, 2576, 2577, 2578, 2579],\n",
       "  516: [2580, 2581, 2582, 2583, 2584],\n",
       "  517: [2585, 2586, 2587, 2588, 2589],\n",
       "  518: [2590, 2591, 2592, 2593, 2594],\n",
       "  519: [2595, 2596, 2597, 2598, 2599],\n",
       "  520: [2600, 2601, 2602, 2603, 2604],\n",
       "  521: [2605, 2606, 2607, 2608, 2609],\n",
       "  522: [2610, 2611, 2612, 2613, 2614],\n",
       "  523: [2615, 2616, 2617, 2618, 2619],\n",
       "  524: [2620, 2621, 2622, 2623, 2624],\n",
       "  525: [2625, 2626, 2627, 2628, 2629],\n",
       "  526: [2630, 2631, 2632, 2633, 2634],\n",
       "  527: [2635, 2636, 2637, 2638, 2639],\n",
       "  528: [2640, 2641, 2642, 2643, 2644],\n",
       "  529: [2645, 2646, 2647, 2648, 2649],\n",
       "  530: [2650, 2651, 2652, 2653, 2654],\n",
       "  531: [2655, 2656, 2657, 2658, 2659],\n",
       "  532: [2660, 2661, 2662, 2663, 2664],\n",
       "  533: [2665, 2666, 2667, 2668, 2669],\n",
       "  534: [2670, 2671, 2672, 2673, 2674],\n",
       "  535: [2675, 2676, 2677, 2678, 2679],\n",
       "  536: [2680, 2681, 2682, 2683, 2684],\n",
       "  537: [2685, 2686, 2687, 2688, 2689],\n",
       "  538: [2690, 2691, 2692, 2693, 2694],\n",
       "  539: [2695, 2696, 2697, 2698, 2699],\n",
       "  540: [2700, 2701, 2702, 2703, 2704],\n",
       "  541: [2705, 2706, 2707, 2708, 2709],\n",
       "  542: [2710, 2711, 2712, 2713, 2714],\n",
       "  543: [2715, 2716, 2717, 2718, 2719],\n",
       "  544: [2720, 2721, 2722, 2723, 2724],\n",
       "  545: [2725, 2726, 2727, 2728, 2729],\n",
       "  546: [2730, 2731, 2732, 2733, 2734],\n",
       "  547: [2735, 2736, 2737, 2738, 2739],\n",
       "  548: [2740, 2741, 2742, 2743, 2744],\n",
       "  549: [2745, 2746, 2747, 2748, 2749],\n",
       "  550: [2750, 2751, 2752, 2753, 2754],\n",
       "  551: [2755, 2756, 2757, 2758, 2759],\n",
       "  552: [2760, 2761, 2762, 2763, 2764],\n",
       "  553: [2765, 2766, 2767, 2768, 2769],\n",
       "  554: [2770, 2771, 2772, 2773, 2774],\n",
       "  555: [2775, 2776, 2777, 2778, 2779],\n",
       "  556: [2780, 2781, 2782, 2783, 2784],\n",
       "  557: [2785, 2786, 2787, 2788, 2789],\n",
       "  558: [2790, 2791, 2792, 2793, 2794],\n",
       "  559: [2795, 2796, 2797, 2798, 2799],\n",
       "  560: [2800, 2801, 2802, 2803, 2804],\n",
       "  561: [2805, 2806, 2807, 2808, 2809],\n",
       "  562: [2810, 2811, 2812, 2813, 2814],\n",
       "  563: [2815, 2816, 2817, 2818, 2819],\n",
       "  564: [2820, 2821, 2822, 2823, 2824],\n",
       "  565: [2825, 2826, 2827, 2828, 2829],\n",
       "  566: [2830, 2831, 2832, 2833, 2834],\n",
       "  567: [2835, 2836, 2837, 2838, 2839],\n",
       "  568: [2840, 2841, 2842, 2843, 2844],\n",
       "  569: [2845, 2846, 2847, 2848, 2849],\n",
       "  570: [2850, 2851, 2852, 2853, 2854],\n",
       "  571: [2855, 2856, 2857, 2858, 2859],\n",
       "  572: [2860, 2861, 2862, 2863, 2864],\n",
       "  573: [2865, 2866, 2867, 2868, 2869],\n",
       "  574: [2870, 2871, 2872, 2873, 2874],\n",
       "  575: [2875, 2876, 2877, 2878, 2879],\n",
       "  576: [2880, 2881, 2882, 2883, 2884],\n",
       "  577: [2885, 2886, 2887, 2888, 2889],\n",
       "  578: [2890, 2891, 2892, 2893, 2894],\n",
       "  579: [2895, 2896, 2897, 2898, 2899],\n",
       "  580: [2900, 2901, 2902, 2903, 2904],\n",
       "  581: [2905, 2906, 2907, 2908, 2909],\n",
       "  582: [2910, 2911, 2912, 2913, 2914],\n",
       "  583: [2915, 2916, 2917, 2918, 2919],\n",
       "  584: [2920, 2921, 2922, 2923, 2924],\n",
       "  585: [2925, 2926, 2927, 2928, 2929],\n",
       "  586: [2930, 2931, 2932, 2933, 2934],\n",
       "  587: [2935, 2936, 2937, 2938, 2939],\n",
       "  588: [2940, 2941, 2942, 2943, 2944],\n",
       "  589: [2945, 2946, 2947, 2948, 2949],\n",
       "  590: [2950, 2951, 2952, 2953, 2954],\n",
       "  591: [2955, 2956, 2957, 2958, 2959],\n",
       "  592: [2960, 2961, 2962, 2963, 2964],\n",
       "  593: [2965, 2966, 2967, 2968, 2969],\n",
       "  594: [2970, 2971, 2972, 2973, 2974],\n",
       "  595: [2975, 2976, 2977, 2978, 2979],\n",
       "  596: [2980, 2981, 2982, 2983, 2984],\n",
       "  597: [2985, 2986, 2987, 2988, 2989],\n",
       "  598: [2990, 2991, 2992, 2993, 2994],\n",
       "  599: [2995, 2996, 2997, 2998, 2999],\n",
       "  600: [3000, 3001, 3002, 3003, 3004],\n",
       "  601: [3005, 3006, 3007, 3008, 3009],\n",
       "  602: [3010, 3011, 3012, 3013, 3014],\n",
       "  603: [3015, 3016, 3017, 3018, 3019],\n",
       "  604: [3020, 3021, 3022, 3023, 3024],\n",
       "  605: [3025, 3026, 3027, 3028, 3029],\n",
       "  606: [3030, 3031, 3032, 3033, 3034],\n",
       "  607: [3035, 3036, 3037, 3038, 3039],\n",
       "  608: [3040, 3041, 3042, 3043, 3044],\n",
       "  609: [3045, 3046, 3047, 3048, 3049],\n",
       "  610: [3050, 3051, 3052, 3053, 3054],\n",
       "  611: [3055, 3056, 3057, 3058, 3059],\n",
       "  612: [3060, 3061, 3062, 3063, 3064],\n",
       "  613: [3065, 3066, 3067, 3068, 3069],\n",
       "  614: [3070, 3071, 3072, 3073, 3074],\n",
       "  615: [3075, 3076, 3077, 3078, 3079],\n",
       "  616: [3080, 3081, 3082, 3083, 3084],\n",
       "  617: [3085, 3086, 3087, 3088, 3089],\n",
       "  618: [3090, 3091, 3092, 3093, 3094],\n",
       "  619: [3095, 3096, 3097, 3098, 3099],\n",
       "  620: [3100, 3101, 3102, 3103, 3104],\n",
       "  621: [3105, 3106, 3107, 3108, 3109],\n",
       "  622: [3110, 3111, 3112, 3113, 3114],\n",
       "  623: [3115, 3116, 3117, 3118, 3119],\n",
       "  624: [3120, 3121, 3122, 3123, 3124],\n",
       "  625: [3125, 3126, 3127, 3128, 3129],\n",
       "  626: [3130, 3131, 3132, 3133, 3134],\n",
       "  627: [3135, 3136, 3137, 3138, 3139],\n",
       "  628: [3140, 3141, 3142, 3143, 3144],\n",
       "  629: [3145, 3146, 3147, 3148, 3149],\n",
       "  630: [3150, 3151, 3152, 3153, 3154],\n",
       "  631: [3155, 3156, 3157, 3158, 3159],\n",
       "  632: [3160, 3161, 3162, 3163, 3164],\n",
       "  633: [3165, 3166, 3167, 3168, 3169],\n",
       "  634: [3170, 3171, 3172, 3173, 3174],\n",
       "  635: [3175, 3176, 3177, 3178, 3179],\n",
       "  636: [3180, 3181, 3182, 3183, 3184],\n",
       "  637: [3185, 3186, 3187, 3188, 3189],\n",
       "  638: [3190, 3191, 3192, 3193, 3194],\n",
       "  639: [3195, 3196, 3197, 3198, 3199],\n",
       "  640: [3200, 3201, 3202, 3203, 3204],\n",
       "  641: [3205, 3206, 3207, 3208, 3209],\n",
       "  642: [3210, 3211, 3212, 3213, 3214],\n",
       "  643: [3215, 3216, 3217, 3218, 3219],\n",
       "  644: [3220, 3221, 3222, 3223, 3224],\n",
       "  645: [3225, 3226, 3227, 3228, 3229],\n",
       "  646: [3230, 3231, 3232, 3233, 3234],\n",
       "  647: [3235, 3236, 3237, 3238, 3239],\n",
       "  648: [3240, 3241, 3242, 3243, 3244],\n",
       "  649: [3245, 3246, 3247, 3248, 3249],\n",
       "  650: [3250, 3251, 3252, 3253, 3254],\n",
       "  651: [3255, 3256, 3257, 3258, 3259],\n",
       "  652: [3260, 3261, 3262, 3263, 3264],\n",
       "  653: [3265, 3266, 3267, 3268, 3269],\n",
       "  654: [3270, 3271, 3272, 3273, 3274],\n",
       "  655: [3275, 3276, 3277, 3278, 3279],\n",
       "  656: [3280, 3281, 3282, 3283, 3284],\n",
       "  657: [3285, 3286, 3287, 3288, 3289],\n",
       "  658: [3290, 3291, 3292, 3293, 3294],\n",
       "  659: [3295, 3296, 3297, 3298, 3299],\n",
       "  660: [3300, 3301, 3302, 3303, 3304],\n",
       "  661: [3305, 3306, 3307, 3308, 3309],\n",
       "  662: [3310, 3311, 3312, 3313, 3314],\n",
       "  663: [3315, 3316, 3317, 3318, 3319],\n",
       "  664: [3320, 3321, 3322, 3323, 3324],\n",
       "  665: [3325, 3326, 3327, 3328, 3329],\n",
       "  666: [3330, 3331, 3332, 3333, 3334],\n",
       "  667: [3335, 3336, 3337, 3338, 3339],\n",
       "  668: [3340, 3341, 3342, 3343, 3344],\n",
       "  669: [3345, 3346, 3347, 3348, 3349],\n",
       "  670: [3350, 3351, 3352, 3353, 3354],\n",
       "  671: [3355, 3356, 3357, 3358, 3359],\n",
       "  672: [3360, 3361, 3362, 3363, 3364],\n",
       "  673: [3365, 3366, 3367, 3368, 3369],\n",
       "  674: [3370, 3371, 3372, 3373, 3374],\n",
       "  675: [3375, 3376, 3377, 3378, 3379],\n",
       "  676: [3380, 3381, 3382, 3383, 3384],\n",
       "  677: [3385, 3386, 3387, 3388, 3389],\n",
       "  678: [3390, 3391, 3392, 3393, 3394],\n",
       "  679: [3395, 3396, 3397, 3398, 3399],\n",
       "  680: [3400, 3401, 3402, 3403, 3404],\n",
       "  681: [3405, 3406, 3407, 3408, 3409],\n",
       "  682: [3410, 3411, 3412, 3413, 3414],\n",
       "  683: [3415, 3416, 3417, 3418, 3419],\n",
       "  684: [3420, 3421, 3422, 3423, 3424],\n",
       "  685: [3425, 3426, 3427, 3428, 3429],\n",
       "  686: [3430, 3431, 3432, 3433, 3434],\n",
       "  687: [3435, 3436, 3437, 3438, 3439],\n",
       "  688: [3440, 3441, 3442, 3443, 3444],\n",
       "  689: [3445, 3446, 3447, 3448, 3449],\n",
       "  690: [3450, 3451, 3452, 3453, 3454],\n",
       "  691: [3455, 3456, 3457, 3458, 3459],\n",
       "  692: [3460, 3461, 3462, 3463, 3464],\n",
       "  693: [3465, 3466, 3467, 3468, 3469],\n",
       "  694: [3470, 3471, 3472, 3473, 3474],\n",
       "  695: [3475, 3476, 3477, 3478, 3479],\n",
       "  696: [3480, 3481, 3482, 3483, 3484],\n",
       "  697: [3485, 3486, 3487, 3488, 3489],\n",
       "  698: [3490, 3491, 3492, 3493, 3494],\n",
       "  699: [3495, 3496, 3497, 3498, 3499],\n",
       "  700: [3500, 3501, 3502, 3503, 3504],\n",
       "  701: [3505, 3506, 3507, 3508, 3509],\n",
       "  702: [3510, 3511, 3512, 3513, 3514],\n",
       "  703: [3515, 3516, 3517, 3518, 3519],\n",
       "  704: [3520, 3521, 3522, 3523, 3524],\n",
       "  705: [3525, 3526, 3527, 3528, 3529],\n",
       "  706: [3530, 3531, 3532, 3533, 3534],\n",
       "  707: [3535, 3536, 3537, 3538, 3539],\n",
       "  708: [3540, 3541, 3542, 3543, 3544],\n",
       "  709: [3545, 3546, 3547, 3548, 3549],\n",
       "  710: [3550, 3551, 3552, 3553, 3554],\n",
       "  711: [3555, 3556, 3557, 3558, 3559],\n",
       "  712: [3560, 3561, 3562, 3563, 3564],\n",
       "  713: [3565, 3566, 3567, 3568, 3569],\n",
       "  714: [3570, 3571, 3572, 3573, 3574],\n",
       "  715: [3575, 3576, 3577, 3578, 3579],\n",
       "  716: [3580, 3581, 3582, 3583, 3584],\n",
       "  717: [3585, 3586, 3587, 3588, 3589],\n",
       "  718: [3590, 3591, 3592, 3593, 3594],\n",
       "  719: [3595, 3596, 3597, 3598, 3599],\n",
       "  720: [3600, 3601, 3602, 3603, 3604],\n",
       "  721: [3605, 3606, 3607, 3608, 3609],\n",
       "  722: [3610, 3611, 3612, 3613, 3614],\n",
       "  723: [3615, 3616, 3617, 3618, 3619],\n",
       "  724: [3620, 3621, 3622, 3623, 3624],\n",
       "  725: [3625, 3626, 3627, 3628, 3629],\n",
       "  726: [3630, 3631, 3632, 3633, 3634],\n",
       "  727: [3635, 3636, 3637, 3638, 3639],\n",
       "  728: [3640, 3641, 3642, 3643, 3644],\n",
       "  729: [3645, 3646, 3647, 3648, 3649],\n",
       "  730: [3650, 3651, 3652, 3653, 3654],\n",
       "  731: [3655, 3656, 3657, 3658, 3659],\n",
       "  732: [3660, 3661, 3662, 3663, 3664],\n",
       "  733: [3665, 3666, 3667, 3668, 3669],\n",
       "  734: [3670, 3671, 3672, 3673, 3674],\n",
       "  735: [3675, 3676, 3677, 3678, 3679],\n",
       "  736: [3680, 3681, 3682, 3683, 3684],\n",
       "  737: [3685, 3686, 3687, 3688, 3689],\n",
       "  738: [3690, 3691, 3692, 3693, 3694],\n",
       "  739: [3695, 3696, 3697, 3698, 3699],\n",
       "  740: [3700, 3701, 3702, 3703, 3704],\n",
       "  741: [3705, 3706, 3707, 3708, 3709],\n",
       "  742: [3710, 3711, 3712, 3713, 3714],\n",
       "  743: [3715, 3716, 3717, 3718, 3719],\n",
       "  744: [3720, 3721, 3722, 3723, 3724],\n",
       "  745: [3725, 3726, 3727, 3728, 3729],\n",
       "  746: [3730, 3731, 3732, 3733, 3734],\n",
       "  747: [3735, 3736, 3737, 3738, 3739],\n",
       "  748: [3740, 3741, 3742, 3743, 3744],\n",
       "  749: [3745, 3746, 3747, 3748, 3749],\n",
       "  750: [3750, 3751, 3752, 3753, 3754],\n",
       "  751: [3755, 3756, 3757, 3758, 3759],\n",
       "  752: [3760, 3761, 3762, 3763, 3764],\n",
       "  753: [3765, 3766, 3767, 3768, 3769],\n",
       "  754: [3770, 3771, 3772, 3773, 3774],\n",
       "  755: [3775, 3776, 3777, 3778, 3779],\n",
       "  756: [3780, 3781, 3782, 3783, 3784],\n",
       "  757: [3785, 3786, 3787, 3788, 3789],\n",
       "  758: [3790, 3791, 3792, 3793, 3794],\n",
       "  759: [3795, 3796, 3797, 3798, 3799],\n",
       "  760: [3800, 3801, 3802, 3803, 3804],\n",
       "  761: [3805, 3806, 3807, 3808, 3809],\n",
       "  762: [3810, 3811, 3812, 3813, 3814],\n",
       "  763: [3815, 3816, 3817, 3818, 3819],\n",
       "  764: [3820, 3821, 3822, 3823, 3824],\n",
       "  765: [3825, 3826, 3827, 3828, 3829],\n",
       "  766: [3830, 3831, 3832, 3833, 3834],\n",
       "  767: [3835, 3836, 3837, 3838, 3839],\n",
       "  768: [3840, 3841, 3842, 3843, 3844],\n",
       "  769: [3845, 3846, 3847, 3848, 3849],\n",
       "  770: [3850, 3851, 3852, 3853, 3854],\n",
       "  771: [3855, 3856, 3857, 3858, 3859],\n",
       "  772: [3860, 3861, 3862, 3863, 3864],\n",
       "  773: [3865, 3866, 3867, 3868, 3869],\n",
       "  774: [3870, 3871, 3872, 3873, 3874],\n",
       "  775: [3875, 3876, 3877, 3878, 3879],\n",
       "  776: [3880, 3881, 3882, 3883, 3884],\n",
       "  777: [3885, 3886, 3887, 3888, 3889],\n",
       "  778: [3890, 3891, 3892, 3893, 3894],\n",
       "  779: [3895, 3896, 3897, 3898, 3899],\n",
       "  780: [3900, 3901, 3902, 3903, 3904],\n",
       "  781: [3905, 3906, 3907, 3908, 3909],\n",
       "  782: [3910, 3911, 3912, 3913, 3914],\n",
       "  783: [3915, 3916, 3917, 3918, 3919],\n",
       "  784: [3920, 3921, 3922, 3923, 3924],\n",
       "  785: [3925, 3926, 3927, 3928, 3929],\n",
       "  786: [3930, 3931, 3932, 3933, 3934],\n",
       "  787: [3935, 3936, 3937, 3938, 3939],\n",
       "  788: [3940, 3941, 3942, 3943, 3944],\n",
       "  789: [3945, 3946, 3947, 3948, 3949],\n",
       "  790: [3950, 3951, 3952, 3953, 3954],\n",
       "  791: [3955, 3956, 3957, 3958, 3959],\n",
       "  792: [3960, 3961, 3962, 3963, 3964],\n",
       "  793: [3965, 3966, 3967, 3968, 3969],\n",
       "  794: [3970, 3971, 3972, 3973, 3974],\n",
       "  795: [3975, 3976, 3977, 3978, 3979],\n",
       "  796: [3980, 3981, 3982, 3983, 3984],\n",
       "  797: [3985, 3986, 3987, 3988, 3989],\n",
       "  798: [3990, 3991, 3992, 3993, 3994],\n",
       "  799: [3995, 3996, 3997, 3998, 3999],\n",
       "  800: [4000, 4001, 4002, 4003, 4004],\n",
       "  801: [4005, 4006, 4007, 4008, 4009],\n",
       "  802: [4010, 4011, 4012, 4013, 4014],\n",
       "  803: [4015, 4016, 4017, 4018, 4019],\n",
       "  804: [4020, 4021, 4022, 4023, 4024],\n",
       "  805: [4025, 4026, 4027, 4028, 4029],\n",
       "  806: [4030, 4031, 4032, 4033, 4034],\n",
       "  807: [4035, 4036, 4037, 4038, 4039],\n",
       "  808: [4040, 4041, 4042, 4043, 4044],\n",
       "  809: [4045, 4046, 4047, 4048, 4049],\n",
       "  810: [4050, 4051, 4052, 4053, 4054],\n",
       "  811: [4055, 4056, 4057, 4058, 4059],\n",
       "  812: [4060, 4061, 4062, 4063, 4064],\n",
       "  813: [4065, 4066, 4067, 4068, 4069],\n",
       "  814: [4070, 4071, 4072, 4073, 4074],\n",
       "  815: [4075, 4076, 4077, 4078, 4079],\n",
       "  816: [4080, 4081, 4082, 4083, 4084],\n",
       "  817: [4085, 4086, 4087, 4088, 4089],\n",
       "  818: [4090, 4091, 4092, 4093, 4094],\n",
       "  819: [4095, 4096, 4097, 4098, 4099],\n",
       "  820: [4100, 4101, 4102, 4103, 4104],\n",
       "  821: [4105, 4106, 4107, 4108, 4109],\n",
       "  822: [4110, 4111, 4112, 4113, 4114],\n",
       "  823: [4115, 4116, 4117, 4118, 4119],\n",
       "  824: [4120, 4121, 4122, 4123, 4124],\n",
       "  825: [4125, 4126, 4127, 4128, 4129],\n",
       "  826: [4130, 4131, 4132, 4133, 4134],\n",
       "  827: [4135, 4136, 4137, 4138, 4139],\n",
       "  828: [4140, 4141, 4142, 4143, 4144],\n",
       "  829: [4145, 4146, 4147, 4148, 4149],\n",
       "  830: [4150, 4151, 4152, 4153, 4154],\n",
       "  831: [4155, 4156, 4157, 4158, 4159],\n",
       "  832: [4160, 4161, 4162, 4163, 4164],\n",
       "  833: [4165, 4166, 4167, 4168, 4169],\n",
       "  834: [4170, 4171, 4172, 4173, 4174],\n",
       "  835: [4175, 4176, 4177, 4178, 4179],\n",
       "  836: [4180, 4181, 4182, 4183, 4184],\n",
       "  837: [4185, 4186, 4187, 4188, 4189],\n",
       "  838: [4190, 4191, 4192, 4193, 4194],\n",
       "  839: [4195, 4196, 4197, 4198, 4199],\n",
       "  840: [4200, 4201, 4202, 4203, 4204],\n",
       "  841: [4205, 4206, 4207, 4208, 4209],\n",
       "  842: [4210, 4211, 4212, 4213, 4214],\n",
       "  843: [4215, 4216, 4217, 4218, 4219],\n",
       "  844: [4220, 4221, 4222, 4223, 4224],\n",
       "  845: [4225, 4226, 4227, 4228, 4229],\n",
       "  846: [4230, 4231, 4232, 4233, 4234],\n",
       "  847: [4235, 4236, 4237, 4238, 4239],\n",
       "  848: [4240, 4241, 4242, 4243, 4244],\n",
       "  849: [4245, 4246, 4247, 4248, 4249],\n",
       "  850: [4250, 4251, 4252, 4253, 4254],\n",
       "  851: [4255, 4256, 4257, 4258, 4259],\n",
       "  852: [4260, 4261, 4262, 4263, 4264],\n",
       "  853: [4265, 4266, 4267, 4268, 4269],\n",
       "  854: [4270, 4271, 4272, 4273, 4274],\n",
       "  855: [4275, 4276, 4277, 4278, 4279],\n",
       "  856: [4280, 4281, 4282, 4283, 4284],\n",
       "  857: [4285, 4286, 4287, 4288, 4289],\n",
       "  858: [4290, 4291, 4292, 4293, 4294],\n",
       "  859: [4295, 4296, 4297, 4298, 4299],\n",
       "  860: [4300, 4301, 4302, 4303, 4304],\n",
       "  861: [4305, 4306, 4307, 4308, 4309],\n",
       "  862: [4310, 4311, 4312, 4313, 4314],\n",
       "  863: [4315, 4316, 4317, 4318, 4319],\n",
       "  864: [4320, 4321, 4322, 4323, 4324],\n",
       "  865: [4325, 4326, 4327, 4328, 4329],\n",
       "  866: [4330, 4331, 4332, 4333, 4334],\n",
       "  867: [4335, 4336, 4337, 4338, 4339],\n",
       "  868: [4340, 4341, 4342, 4343, 4344],\n",
       "  869: [4345, 4346, 4347, 4348, 4349],\n",
       "  870: [4350, 4351, 4352, 4353, 4354],\n",
       "  871: [4355, 4356, 4357, 4358, 4359],\n",
       "  872: [4360, 4361, 4362, 4363, 4364],\n",
       "  873: [4365, 4366, 4367, 4368, 4369],\n",
       "  874: [4370, 4371, 4372, 4373, 4374],\n",
       "  875: [4375, 4376, 4377, 4378, 4379],\n",
       "  876: [4380, 4381, 4382, 4383, 4384],\n",
       "  877: [4385, 4386, 4387, 4388, 4389],\n",
       "  878: [4390, 4391, 4392, 4393, 4394],\n",
       "  879: [4395, 4396, 4397, 4398, 4399],\n",
       "  880: [4400, 4401, 4402, 4403, 4404],\n",
       "  881: [4405, 4406, 4407, 4408, 4409],\n",
       "  882: [4410, 4411, 4412, 4413, 4414],\n",
       "  883: [4415, 4416, 4417, 4418, 4419],\n",
       "  884: [4420, 4421, 4422, 4423, 4424],\n",
       "  885: [4425, 4426, 4427, 4428, 4429],\n",
       "  886: [4430, 4431, 4432, 4433, 4434],\n",
       "  887: [4435, 4436, 4437, 4438, 4439],\n",
       "  888: [4440, 4441, 4442, 4443, 4444],\n",
       "  889: [4445, 4446, 4447, 4448, 4449],\n",
       "  890: [4450, 4451, 4452, 4453, 4454],\n",
       "  891: [4455, 4456, 4457, 4458, 4459],\n",
       "  892: [4460, 4461, 4462, 4463, 4464],\n",
       "  893: [4465, 4466, 4467, 4468, 4469],\n",
       "  894: [4470, 4471, 4472, 4473, 4474],\n",
       "  895: [4475, 4476, 4477, 4478, 4479],\n",
       "  896: [4480, 4481, 4482, 4483, 4484],\n",
       "  897: [4485, 4486, 4487, 4488, 4489],\n",
       "  898: [4490, 4491, 4492, 4493, 4494],\n",
       "  899: [4495, 4496, 4497, 4498, 4499],\n",
       "  900: [4500, 4501, 4502, 4503, 4504],\n",
       "  901: [4505, 4506, 4507, 4508, 4509],\n",
       "  902: [4510, 4511, 4512, 4513, 4514],\n",
       "  903: [4515, 4516, 4517, 4518, 4519],\n",
       "  904: [4520, 4521, 4522, 4523, 4524],\n",
       "  905: [4525, 4526, 4527, 4528, 4529],\n",
       "  906: [4530, 4531, 4532, 4533, 4534],\n",
       "  907: [4535, 4536, 4537, 4538, 4539],\n",
       "  908: [4540, 4541, 4542, 4543, 4544],\n",
       "  909: [4545, 4546, 4547, 4548, 4549],\n",
       "  910: [4550, 4551, 4552, 4553, 4554],\n",
       "  911: [4555, 4556, 4557, 4558, 4559],\n",
       "  912: [4560, 4561, 4562, 4563, 4564],\n",
       "  913: [4565, 4566, 4567, 4568, 4569],\n",
       "  914: [4570, 4571, 4572, 4573, 4574],\n",
       "  915: [4575, 4576, 4577, 4578, 4579],\n",
       "  916: [4580, 4581, 4582, 4583, 4584],\n",
       "  917: [4585, 4586, 4587, 4588, 4589],\n",
       "  918: [4590, 4591, 4592, 4593, 4594],\n",
       "  919: [4595, 4596, 4597, 4598, 4599],\n",
       "  920: [4600, 4601, 4602, 4603, 4604],\n",
       "  921: [4605, 4606, 4607, 4608, 4609],\n",
       "  922: [4610, 4611, 4612, 4613, 4614],\n",
       "  923: [4615, 4616, 4617, 4618, 4619],\n",
       "  924: [4620, 4621, 4622, 4623, 4624],\n",
       "  925: [4625, 4626, 4627, 4628, 4629],\n",
       "  926: [4630, 4631, 4632, 4633, 4634],\n",
       "  927: [4635, 4636, 4637, 4638, 4639],\n",
       "  928: [4640, 4641, 4642, 4643, 4644],\n",
       "  929: [4645, 4646, 4647, 4648, 4649],\n",
       "  930: [4650, 4651, 4652, 4653, 4654],\n",
       "  931: [4655, 4656, 4657, 4658, 4659],\n",
       "  932: [4660, 4661, 4662, 4663, 4664],\n",
       "  933: [4665, 4666, 4667, 4668, 4669],\n",
       "  934: [4670, 4671, 4672, 4673, 4674],\n",
       "  935: [4675, 4676, 4677, 4678, 4679],\n",
       "  936: [4680, 4681, 4682, 4683, 4684],\n",
       "  937: [4685, 4686, 4687, 4688, 4689],\n",
       "  938: [4690, 4691, 4692, 4693, 4694],\n",
       "  939: [4695, 4696, 4697, 4698, 4699],\n",
       "  940: [4700, 4701, 4702, 4703, 4704],\n",
       "  941: [4705, 4706, 4707, 4708, 4709],\n",
       "  942: [4710, 4711, 4712, 4713, 4714],\n",
       "  943: [4715, 4716, 4717, 4718, 4719],\n",
       "  944: [4720, 4721, 4722, 4723, 4724],\n",
       "  945: [4725, 4726, 4727, 4728, 4729],\n",
       "  946: [4730, 4731, 4732, 4733, 4734],\n",
       "  947: [4735, 4736, 4737, 4738, 4739],\n",
       "  948: [4740, 4741, 4742, 4743, 4744],\n",
       "  949: [4745, 4746, 4747, 4748, 4749],\n",
       "  950: [4750, 4751, 4752, 4753, 4754],\n",
       "  951: [4755, 4756, 4757, 4758, 4759],\n",
       "  952: [4760, 4761, 4762, 4763, 4764],\n",
       "  953: [4765, 4766, 4767, 4768, 4769],\n",
       "  954: [4770, 4771, 4772, 4773, 4774],\n",
       "  955: [4775, 4776, 4777, 4778, 4779],\n",
       "  956: [4780, 4781, 4782, 4783, 4784],\n",
       "  957: [4785, 4786, 4787, 4788, 4789],\n",
       "  958: [4790, 4791, 4792, 4793, 4794],\n",
       "  959: [4795, 4796, 4797, 4798, 4799],\n",
       "  960: [4800, 4801, 4802, 4803, 4804],\n",
       "  961: [4805, 4806, 4807, 4808, 4809],\n",
       "  962: [4810, 4811, 4812, 4813, 4814],\n",
       "  963: [4815, 4816, 4817, 4818, 4819],\n",
       "  964: [4820, 4821, 4822, 4823, 4824],\n",
       "  965: [4825, 4826, 4827, 4828, 4829],\n",
       "  966: [4830, 4831, 4832, 4833, 4834],\n",
       "  967: [4835, 4836, 4837, 4838, 4839],\n",
       "  968: [4840, 4841, 4842, 4843, 4844],\n",
       "  969: [4845, 4846, 4847, 4848, 4849],\n",
       "  970: [4850, 4851, 4852, 4853, 4854],\n",
       "  971: [4855, 4856, 4857, 4858, 4859],\n",
       "  972: [4860, 4861, 4862, 4863, 4864],\n",
       "  973: [4865, 4866, 4867, 4868, 4869],\n",
       "  974: [4870, 4871, 4872, 4873, 4874],\n",
       "  975: [4875, 4876, 4877, 4878, 4879],\n",
       "  976: [4880, 4881, 4882, 4883, 4884],\n",
       "  977: [4885, 4886, 4887, 4888, 4889],\n",
       "  978: [4890, 4891, 4892, 4893, 4894],\n",
       "  979: [4895, 4896, 4897, 4898, 4899],\n",
       "  980: [4900, 4901, 4902, 4903, 4904],\n",
       "  981: [4905, 4906, 4907, 4908, 4909],\n",
       "  982: [4910, 4911, 4912, 4913, 4914],\n",
       "  983: [4915, 4916, 4917, 4918, 4919],\n",
       "  984: [4920, 4921, 4922, 4923, 4924],\n",
       "  985: [4925, 4926, 4927, 4928, 4929],\n",
       "  986: [4930, 4931, 4932, 4933, 4934],\n",
       "  987: [4935, 4936, 4937, 4938, 4939],\n",
       "  988: [4940, 4941, 4942, 4943, 4944],\n",
       "  989: [4945, 4946, 4947, 4948, 4949],\n",
       "  990: [4950, 4951, 4952, 4953, 4954],\n",
       "  991: [4955, 4956, 4957, 4958, 4959],\n",
       "  992: [4960, 4961, 4962, 4963, 4964],\n",
       "  993: [4965, 4966, 4967, 4968, 4969],\n",
       "  994: [4970, 4971, 4972, 4973, 4974],\n",
       "  995: [4975, 4976, 4977, 4978, 4979],\n",
       "  996: [4980, 4981, 4982, 4983, 4984],\n",
       "  997: [4985, 4986, 4987, 4988, 4989],\n",
       "  998: [4990, 4991, 4992, 4993, 4994],\n",
       "  999: [4995, 4996, 4997, 4998, 4999]}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "flickr_dataset.img_transform = img_transform\n",
    "\n",
    "pipeline = InferencePipeline(model, device, processor)\n",
    "results = pipeline.run_inference(flickr_dataset, task = 'image_text_retrieval')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding current path to python system paths\n"
     ]
    }
   ],
   "source": [
    "from scoring_pipeline import ScoringPipeline\n",
    "\n",
    "scoring_pipeline = ScoringPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'txt_r1': 0.1,\n",
       " 'txt_r5': 0.5,\n",
       " 'txt_r10': 0.8,\n",
       " 'txt_r_mean': 0.4666666666666666,\n",
       " 'img_r1': 0.02,\n",
       " 'img_r5': 0.12,\n",
       " 'img_r10': 0.36,\n",
       " 'img_r_mean': 0.16666666666666666,\n",
       " 'r_mean': 0.31666666666666665,\n",
       " 'agg_metrics': 0.4666666666666666}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_pipeline._compute_retrieval_scores(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
