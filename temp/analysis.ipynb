{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d028a27-d0ab-4a8b-8942-22424e576e15",
   "metadata": {},
   "source": [
    "# Analysis of Config Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e7b6c-77c1-4f26-a989-4347f264466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from scoring_pipeline import ScoringPipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_config(config_file):\n",
    "    with open(config_file, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def get_bit_size(config):\n",
    "    if config and \"num_bits\" in config[0]:\n",
    "        return config[0][\"num_bits\"]\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_layer_type(config):\n",
    "    if config and \"layer_type\" in config[0]:\n",
    "        return config[0][\"layer_type\"]\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_quantized_parts(config):\n",
    "    parts = {\n",
    "        \"VIT\": {\"FIRST\": 0, \"MIDDLE\": 0, \"LAST\": 0},\n",
    "        \"QFORMER\": {\"FIRST\": 0, \"MIDDLE\": 0, \"LAST\": 0},\n",
    "        \"LLM\": {\"FIRST\": 0, \"MIDDLE\": 0, \"LAST\": 0},\n",
    "    }\n",
    "    for item in config:\n",
    "        if \"model_part\" in item and \"layer_group\" in item:\n",
    "            if item[\"layer_group\"] == \"ALL\":\n",
    "                parts[item[\"model_part\"]] = {\"FIRST\": 1, \"MIDDLE\": 1, \"LAST\": 1}\n",
    "            else:\n",
    "                parts[item[\"model_part\"]][item[\"layer_group\"]] = 1\n",
    "    return parts\n",
    "\n",
    "\n",
    "results = []\n",
    "scorer = ScoringPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dfa06f-2b05-4059-8805-7eb7a2c82f8d",
   "metadata": {},
   "source": [
    "## Run Scoring Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a67e5-4147-49ed-9e43-4179fb3aff75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get list of files and use tqdm for progress bar\n",
    "result_files = [f for f in os.listdir(\"./results\") if f.endswith(\".json\")]\n",
    "for filename in tqdm(result_files, desc=\"Processing files\"):\n",
    "    config_number = filename.split(\".\")[0]\n",
    "\n",
    "    # Load and process config\n",
    "    config_file = os.path.join(\"./configs\", filename)\n",
    "    config = load_config(config_file)\n",
    "    bit_size = get_bit_size(config)\n",
    "    layer_type = get_layer_type(config)\n",
    "    quantized_parts = get_quantized_parts(config)\n",
    "\n",
    "    # Load and process results\n",
    "    result_file = os.path.join(\"./results\", filename)\n",
    "    loaded_results = scorer.load_results(result_file)\n",
    "    scores = scorer.compute_scores(loaded_results, task=\"image_captioning\")\n",
    "\n",
    "    # Compile row data\n",
    "    row = {\n",
    "        \"config\": config_number,\n",
    "        \"bit_size\": bit_size,\n",
    "        \"type\": layer_type,\n",
    "        \"VIT_FIRST\": quantized_parts[\"VIT\"][\"FIRST\"],\n",
    "        \"VIT_MIDDLE\": quantized_parts[\"VIT\"][\"MIDDLE\"],\n",
    "        \"VIT_LAST\": quantized_parts[\"VIT\"][\"LAST\"],\n",
    "        \"QFORMER_FIRST\": quantized_parts[\"QFORMER\"][\"FIRST\"],\n",
    "        \"QFORMER_MIDDLE\": quantized_parts[\"QFORMER\"][\"MIDDLE\"],\n",
    "        \"QFORMER_LAST\": quantized_parts[\"QFORMER\"][\"LAST\"],\n",
    "        \"LLM_FIRST\": quantized_parts[\"LLM\"][\"FIRST\"],\n",
    "        \"LLM_MIDDLE\": quantized_parts[\"LLM\"][\"MIDDLE\"],\n",
    "        \"LLM_LAST\": quantized_parts[\"LLM\"][\"LAST\"],\n",
    "    }\n",
    "\n",
    "    # Add metrics\n",
    "    for metric, score in scores.items():\n",
    "        if not metric.endswith(\"_per_caption\"):\n",
    "            row[metric] = score\n",
    "\n",
    "    results.append(row)\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"quantization_results.csv\", index=False)\n",
    "print(\"Results saved to quantization_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd6603-71d6-4e36-a7f1-13dba5f97a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44431e1-c1ae-48cf-95f8-992f08213fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaedda9-0251-438e-81f0-22d37080fe23",
   "metadata": {},
   "source": [
    "## Plot Scores and Normalized Scores (Sorted by CIDEr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba62b88-fb82-415b-9595-09f9370cc308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your data in a DataFrame called 'df'\n",
    "df_sorted = df.sort_values(\"CIDEr\").reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.scatter(df_sorted.index, df_sorted[\"METEOR\"], color=\"blue\", alpha=0.5, s=10, label=\"METEOR\")\n",
    "plt.scatter(df_sorted.index, df_sorted[\"CIDEr\"], color=\"red\", alpha=0.5, s=10, label=\"CIDEr\")\n",
    "\n",
    "plt.xlabel(\"Sorted Index\", fontsize=12)\n",
    "plt.ylabel(\"Score\", fontsize=12)\n",
    "plt.title(\"METEOR and CIDEr Scores (Sorted by CIDEr)\", fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f411d8-4732-4dad-8e68-a340a56e40b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple min-max normalization function\n",
    "def normalize(series):\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "\n",
    "\n",
    "# Normalize the data\n",
    "df_normalized = pd.DataFrame({\"METEOR\": normalize(df_sorted[\"METEOR\"]), \"CIDEr\": normalize(df_sorted[\"CIDEr\"])})\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.scatter(\n",
    "    df_normalized.index,\n",
    "    df_normalized[\"METEOR\"],\n",
    "    color=\"blue\",\n",
    "    alpha=0.5,\n",
    "    s=10,\n",
    "    label=\"METEOR\",\n",
    ")\n",
    "plt.scatter(\n",
    "    df_normalized.index,\n",
    "    df_normalized[\"CIDEr\"],\n",
    "    color=\"red\",\n",
    "    alpha=0.5,\n",
    "    s=10,\n",
    "    label=\"CIDEr\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Sorted Index\", fontsize=12)\n",
    "plt.ylabel(\"Normalized Score\", fontsize=12)\n",
    "plt.title(\"Normalized METEOR and CIDEr Scores (Sorted by CIDEr)\", fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2f33cf-d872-4566-8191-59ddbab23bc7",
   "metadata": {},
   "source": [
    "## Add Column for Measured Model Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d6a41f-e1bb-4ffe-acc3-61d356c76f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"quantization_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d7ce0-a920-44a6-abd6-54de85949cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Blip2ForConditionalGeneration\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "# Usage:\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Total trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f3394-fa00-4163-b18c-a115d553214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quantized_size(\n",
    "    model,\n",
    "    bit_size,\n",
    "    layer_type,\n",
    "    vit_first,\n",
    "    vit_middle,\n",
    "    vit_last,\n",
    "    qformer_first,\n",
    "    qformer_middle,\n",
    "    qformer_last,\n",
    "    llm_first,\n",
    "    llm_middle,\n",
    "    llm_last,\n",
    "):\n",
    "    def count_layer_params(layer, count_attention, count_mlp):\n",
    "        param_count = 0\n",
    "        if count_attention:\n",
    "            if hasattr(layer, \"self_attn\"):\n",
    "                param_count += sum(p.numel() for p in layer.self_attn.parameters() if p.requires_grad)\n",
    "            elif hasattr(layer, \"attention\"):\n",
    "                param_count += sum(p.numel() for p in layer.attention.parameters() if p.requires_grad)\n",
    "        if count_mlp:\n",
    "            if hasattr(layer, \"mlp\"):\n",
    "                param_count += sum(p.numel() for p in layer.mlp.parameters() if p.requires_grad)\n",
    "            elif hasattr(layer, \"fc1\") and hasattr(layer, \"fc2\"):\n",
    "                param_count += sum(p.numel() for p in layer.fc1.parameters() if p.requires_grad)\n",
    "                param_count += sum(p.numel() for p in layer.fc2.parameters() if p.requires_grad)\n",
    "        return param_count\n",
    "\n",
    "    def quantize_part(layers, first, middle, last):\n",
    "        total_layers = len(layers)\n",
    "        first_end = total_layers // 3\n",
    "        middle_start = first_end\n",
    "        middle_end = 2 * total_layers // 3\n",
    "        last_start = middle_end\n",
    "\n",
    "        quantized_params = 0\n",
    "        for i, layer in enumerate(layers):\n",
    "            if (i < first_end and first) or (middle_start <= i < middle_end and middle) or (i >= last_start and last):\n",
    "                quantized_params += count_layer_params(\n",
    "                    layer,\n",
    "                    layer_type in [\"BOTH\", \"ATTENTION\"],\n",
    "                    layer_type in [\"BOTH\", \"MLP\"],\n",
    "                )\n",
    "        return quantized_params\n",
    "\n",
    "    vit_params = quantize_part(model.vision_model.encoder.layers, vit_first, vit_middle, vit_last)\n",
    "    qformer_params = quantize_part(model.qformer.encoder.layer, qformer_first, qformer_middle, qformer_last)\n",
    "    llm_params = quantize_part(model.language_model.model.decoder.layers, llm_first, llm_middle, llm_last)\n",
    "\n",
    "    total_quantized_params = vit_params + qformer_params + llm_params\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    # Calculate the new model size\n",
    "    original_size = total_params * 32  # Assuming original is 32-bit\n",
    "    quantized_size = (total_params - total_quantized_params) * 32 + total_quantized_params * bit_size\n",
    "\n",
    "    return quantized_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13944dfd-9977-4594-acff-afc3d900e878",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48006fc-4f6f-4edf-a500-714afa9be121",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_size = count_parameters(model) * 32\n",
    "print(f\"Full size: {full_size}\")\n",
    "\n",
    "for layer_type in [\"BOTH\", \"ATTENTION\", \"MLP\"]:\n",
    "    print(f\"\\nTesting with layer_type: {layer_type}\")\n",
    "\n",
    "    half_size = calculate_quantized_size(model, 16, layer_type, 1, 1, 1, 1, 1, 1, 1, 1, 1)\n",
    "    print(f\"Calculated half size: {half_size}\")\n",
    "    print(f\"Ratio of size between full: {half_size / full_size}\")\n",
    "\n",
    "    quarter = calculate_quantized_size(model, 8, layer_type, 1, 1, 1, 1, 1, 1, 1, 1, 1)\n",
    "    print(f\"Calculated quarter size: {quarter}\")\n",
    "    print(f\"Ratio of size between full: {quarter / full_size}\")\n",
    "\n",
    "    eight = calculate_quantized_size(model, 4, layer_type, 1, 1, 1, 1, 1, 1, 1, 1, 1)\n",
    "    print(f\"Calculated eight size: {eight}\")\n",
    "    print(f\"Ratio of size between full: {eight / full_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740314d-0540-448e-b2fd-186feabd0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_quantization(row, model):\n",
    "    return calculate_quantized_size(\n",
    "        model,\n",
    "        row[\"bit_size\"],\n",
    "        row[\"type\"],\n",
    "        row[\"VIT_FIRST\"],\n",
    "        row[\"VIT_MIDDLE\"],\n",
    "        row[\"VIT_LAST\"],\n",
    "        row[\"QFORMER_FIRST\"],\n",
    "        row[\"QFORMER_MIDDLE\"],\n",
    "        row[\"QFORMER_LAST\"],\n",
    "        row[\"LLM_FIRST\"],\n",
    "        row[\"LLM_MIDDLE\"],\n",
    "        row[\"LLM_LAST\"],\n",
    "    )\n",
    "\n",
    "\n",
    "# Assuming your DataFrame is called 'df' and your model is called 'model'\n",
    "df[\"quantized_size\"] = df.apply(lambda row: apply_quantization(row, model), axis=1)\n",
    "\n",
    "# Calculate the compression ratio\n",
    "total_params = count_parameters(model)\n",
    "original_size = total_params * 32\n",
    "df[\"compression_ratio\"] = df[\"quantized_size\"] / original_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43da7fe-ad6b-48b3-b458-e26b230982e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff42080-9d8c-40e9-8065-ca2cca95d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"quantization_results_w_size.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b316cb-4edf-4661-b47d-4c2f66356d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df[\"bit_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8137bdd7-db83-4232-ab12-d0d1eca9a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "# Define the discrete color map using a sequential colormap\n",
    "bit_sizes = set(df[\"bit_size\"])\n",
    "n_colors = len(bit_sizes)\n",
    "colors = px.colors.sequential.Plasma\n",
    "color_indices = np.linspace(0, len(colors) - 1, n_colors).astype(int)\n",
    "discrete_colors = [colors[i] for i in color_indices]\n",
    "color_map = dict(zip(bit_sizes, discrete_colors))\n",
    "\n",
    "# Rest of your plotting code remains the same\n",
    "hover_text = df.apply(lambda row: \"<br>\".join([f\"{col}: {row[col]}\" for col in df.columns]), axis=1)\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=df[\"METEOR\"],\n",
    "            y=df[\"CIDEr\"],\n",
    "            z=df[\"quantized_size\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=5, color=[color_map[size] for size in df[\"bit_size\"]], opacity=0.8),\n",
    "            text=hover_text,\n",
    "            hoverinfo=\"text\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Add discrete color legend\n",
    "for bit_size, color in color_map.items():\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            z=[None],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=10, color=color),\n",
    "            showlegend=True,\n",
    "            name=f\"{bit_size}-bit\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"3D Scatter Plot of METEOR, CIDEr, and Quantized Size\",\n",
    "    scene=dict(xaxis_title=\"METEOR\", yaxis_title=\"CIDEr\", zaxis_title=\"Quantized Size\"),\n",
    "    width=800,\n",
    "    height=800,\n",
    "    margin=dict(r=20, b=10, l=10, t=40),\n",
    "    legend_title=\"Bit Size\",\n",
    ")\n",
    "\n",
    "fig.write_html(\"3d_plot.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7937357d-a40a-413b-9371-72a4b99f9995",
   "metadata": {},
   "source": [
    "## QFormer Bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d536b95f-3500-4457-9e4b-820b94b5734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"compression_ratio\"] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193fdef7-dceb-40a1-95fb-3c561420442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quantized_size(\n",
    "    model,\n",
    "    bit_size,\n",
    "    layer_type,\n",
    "    vit_first,\n",
    "    vit_middle,\n",
    "    vit_last,\n",
    "    qformer_first,\n",
    "    qformer_middle,\n",
    "    qformer_last,\n",
    "    llm_first,\n",
    "    llm_middle,\n",
    "    llm_last,\n",
    "):\n",
    "    def count_layer_params(layer, count_attention, count_mlp):\n",
    "        param_count = 0\n",
    "        if count_attention:\n",
    "            if hasattr(layer, \"self_attn\"):\n",
    "                param_count += sum(p.numel() for p in layer.self_attn.parameters() if p.requires_grad)\n",
    "            elif hasattr(layer, \"attention\"):\n",
    "                param_count += sum(p.numel() for p in layer.attention.parameters() if p.requires_grad)\n",
    "        if count_mlp:\n",
    "            if hasattr(layer, \"mlp\"):\n",
    "                param_count += sum(p.numel() for p in layer.mlp.parameters() if p.requires_grad)\n",
    "            elif hasattr(layer, \"fc1\") and hasattr(layer, \"fc2\"):\n",
    "                param_count += sum(p.numel() for p in layer.fc1.parameters() if p.requires_grad)\n",
    "                param_count += sum(p.numel() for p in layer.fc2.parameters() if p.requires_grad)\n",
    "        return param_count\n",
    "\n",
    "    def quantize_part(layers, first, middle, last):\n",
    "        total_layers = len(layers)\n",
    "        first_end = total_layers // 3\n",
    "        middle_start = first_end\n",
    "        middle_end = 2 * total_layers // 3\n",
    "        last_start = middle_end\n",
    "\n",
    "        quantized_params = 0\n",
    "        for i, layer in enumerate(layers):\n",
    "            if (i < first_end and first) or (middle_start <= i < middle_end and middle) or (i >= last_start and last):\n",
    "                quantized_params += count_layer_params(\n",
    "                    layer,\n",
    "                    layer_type in [\"BOTH\", \"ATTENTION\"],\n",
    "                    layer_type in [\"BOTH\", \"MLP\"],\n",
    "                )\n",
    "        return quantized_params\n",
    "\n",
    "    vit_params = quantize_part(model.vision_model.encoder.layers, vit_first, vit_middle, vit_last)\n",
    "    qformer_params = quantize_part(model.qformer.encoder.layer, qformer_first, qformer_middle, qformer_last)\n",
    "    llm_params = quantize_part(model.language_model.model.decoder.layers, llm_first, llm_middle, llm_last)\n",
    "\n",
    "    print(f\"VIT params quantized: {vit_params}\")\n",
    "    print(f\"QFormer params quantized: {qformer_params}\")\n",
    "    print(f\"LLM params quantized: {llm_params}\")\n",
    "\n",
    "    total_quantized_params = vit_params + qformer_params + llm_params\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(f\"Total params: {total_params}\")\n",
    "    print(f\"Total quantized params: {total_quantized_params}\")\n",
    "\n",
    "    # Calculate the new model size\n",
    "    original_size = total_params * 32  # Assuming original is 32-bit\n",
    "    quantized_size = (total_params - total_quantized_params) * 32 + total_quantized_params * bit_size\n",
    "\n",
    "    return quantized_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0dee9-3ecf-4816-9943-432fb84cc87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Assuming you have your BLIP-2 model loaded as 'model'\n",
    "\n",
    "\n",
    "def test_qformer_structure():\n",
    "    print(\"QFormer Structure:\")\n",
    "    print(model.qformer)\n",
    "    print(\"\\nNumber of QFormer layers:\", len(model.qformer.encoder.layer))\n",
    "\n",
    "\n",
    "def count_qformer_params():\n",
    "    return sum(p.numel() for p in model.qformer.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def test_qformer_param_count():\n",
    "    qformer_params = count_qformer_params()\n",
    "    print(f\"Total QFormer parameters: {qformer_params}\")\n",
    "\n",
    "\n",
    "def test_qformer_layer_param_count():\n",
    "    for i, layer in enumerate(model.qformer.encoder.layer):\n",
    "        layer_params = sum(p.numel() for p in layer.parameters() if p.requires_grad)\n",
    "        print(f\"QFormer Layer {i} parameters: {layer_params}\")\n",
    "\n",
    "\n",
    "def test_qformer_quantization(bit_size, layer_type, first, middle, last):\n",
    "    def count_layer_params(layer, count_attention, count_mlp):\n",
    "        param_count = 0\n",
    "        if count_attention:\n",
    "            if hasattr(layer, \"self_attn\"):\n",
    "                param_count += sum(p.numel() for p in layer.self_attn.parameters() if p.requires_grad)\n",
    "            elif hasattr(layer, \"attention\"):\n",
    "                param_count += sum(p.numel() for p in layer.attention.parameters() if p.requires_grad)\n",
    "        if count_mlp:\n",
    "            if hasattr(layer, \"mlp\"):\n",
    "                param_count += sum(p.numel() for p in layer.mlp.parameters() if p.requires_grad)\n",
    "            elif hasattr(layer, \"fc1\") and hasattr(layer, \"fc2\"):\n",
    "                param_count += sum(p.numel() for p in layer.fc1.parameters() if p.requires_grad)\n",
    "                param_count += sum(p.numel() for p in layer.fc2.parameters() if p.requires_grad)\n",
    "        return param_count\n",
    "\n",
    "    layers = model.qformer.encoder.layer\n",
    "    total_layers = len(layers)\n",
    "    first_end = total_layers // 3\n",
    "    middle_start = first_end\n",
    "    middle_end = 2 * total_layers // 3\n",
    "    last_start = middle_end\n",
    "\n",
    "    quantized_params = 0\n",
    "    for i, layer in enumerate(layers):\n",
    "        if (i < first_end and first) or (middle_start <= i < middle_end and middle) or (i >= last_start and last):\n",
    "            layer_params = count_layer_params(\n",
    "                layer,\n",
    "                layer_type in [\"BOTH\", \"ATTENTION\"],\n",
    "                layer_type in [\"BOTH\", \"MLP\"],\n",
    "            )\n",
    "            quantized_params += layer_params\n",
    "            print(f\"Layer {i} quantized parameters: {layer_params}\")\n",
    "\n",
    "    print(f\"Total QFormer quantized parameters: {quantized_params}\")\n",
    "    total_params = count_qformer_params()\n",
    "    print(f\"QFormer compression ratio: {quantized_params * bit_size / (total_params * 32):.4f}\")\n",
    "\n",
    "\n",
    "# Run the tests\n",
    "print(\"Test 1: QFormer Structure\")\n",
    "test_qformer_structure()\n",
    "\n",
    "print(\"\\nTest 2: QFormer Parameter Count\")\n",
    "test_qformer_param_count()\n",
    "\n",
    "print(\"\\nTest 3: QFormer Layer-wise Parameter Count\")\n",
    "test_qformer_layer_param_count()\n",
    "\n",
    "print(\"\\nTest 4: QFormer Quantization (8-bit, MLP, all layers)\")\n",
    "test_qformer_quantization(8, \"MLP\", True, True, True)\n",
    "\n",
    "print(\"\\nTest 5: QFormer Quantization (4-bit, ATTENTION, first third)\")\n",
    "test_qformer_quantization(4, \"ATTENTION\", True, False, False)\n",
    "\n",
    "print(\"\\nTest 6: QFormer Quantization (16-bit, BOTH, middle third)\")\n",
    "test_qformer_quantization(16, \"BOTH\", False, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ccf01-3e64-4950-b91e-dbf39e611def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mlp_layers(model, model_name):\n",
    "    mlp_count = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if (\n",
    "            \"mlp\" in name.lower()\n",
    "            or \"mlp\" in name.lower()\n",
    "            or (\"intermediate\" in name.lower() and \"dense\" in name.lower())\n",
    "        ):\n",
    "            mlp_count += 1\n",
    "    print(f\"Number of MLP layers in {model_name}: {mlp_count}\")\n",
    "\n",
    "\n",
    "# Count MLP layers in the vision model\n",
    "count_mlp_layers(model.vision_model, \"Vision Model\")\n",
    "\n",
    "# Count MLP layers in the language model\n",
    "count_mlp_layers(model.language_model, \"Language Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be317e-4fd5-48c4-bd4f-f6669d2bdbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mlp_layers(model, model_name):\n",
    "    mlp_count = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if (\n",
    "            \"fc1\" in name.lower()\n",
    "            or \"fc1\" in name.lower()\n",
    "            or (\"intermediate\" in name.lower() and \"dense\" in name.lower())\n",
    "        ):\n",
    "            mlp_count += 1\n",
    "        elif (\n",
    "            \"fc2\" in name.lower()\n",
    "            or \"fc2\" in name.lower()\n",
    "            or (\"intermediate\" in name.lower() and \"dense\" in name.lower())\n",
    "        ):\n",
    "            mlp_count += 1\n",
    "    print(f\"Number of FC1 layers in {model_name}: {mlp_count}\")\n",
    "\n",
    "\n",
    "# Count MLP layers in the vision model\n",
    "count_mlp_layers(model.vision_model, \"Vision Model\")\n",
    "\n",
    "# Count MLP layers in the language model\n",
    "count_mlp_layers(model.language_model, \"Language Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7794127e-5e38-4e5d-a44f-5808661a1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac4694-2ac4-478b-84b2-1a19e93120b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vision_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c933c3b-1111-43fe-9c96-19ead76220e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
