{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs/nexus-scratch/vla/micromamba/envs/MMQ/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration, AutoProcessor, Blip2ForImageTextRetrieval\n",
    "from datasets import COCODataset\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "# from utils import print_model_structure\n",
    "\n",
    "from collections import defaultdict\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.18it/s]\n",
      "/fs/nexus-scratch/vla/micromamba/envs/MMQ/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1602: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Salesforce/blip2-opt-2.7b\"\n",
    "\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(model_name)\n",
    "model = model.to(device)\n",
    "\n",
    "processor = Blip2Processor.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# TODO: determine appropriate size for this calibration set\n",
    "# AutoAWQ defaults to a size of 512\n",
    "\n",
    "coco_dataset = COCODataset(ann_file='/nfshomes/vla/project_dirs/low-bit-vision/datasets/cocow/annotations/captions_val2017.json',\n",
    "                           img_dir='/nfshomes/vla/project_dirs/low-bit-vision/datasets/cocow/images/val2017')\n",
    "\n",
    "# calibration_set = [coco_dataset[0], coco_dataset[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base class for AWQ quantizer\n",
    "class BaseAWQQuantizer():\n",
    "    \n",
    "    def __init__(self, model, device, inputs_processor, dataset, **kwargs):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.inputs_processor = inputs_processor\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.group_size = 128\n",
    "        \n",
    "        self.run_model = None\n",
    "\n",
    "\n",
    "    def quantize(self):\n",
    "        layers = self._get_model_layers()\n",
    "        calibration_set = self._get_calibration_set()\n",
    "        inputs = self._gather_inputs(layers, calibration_set)\n",
    "\n",
    "        # for i,layer in enumerate(layers):\n",
    "        #     inp = inputs[i]\n",
    "\n",
    "        #     # # TODO: some inputs have different shape? cannot just concat them all channelwise\n",
    "        #     # inp = {k: torch.cat(v, dim=0) for k, v in inp.items()}\n",
    "\n",
    "        #     self._compute_scales(layer, inp)\n",
    "        \n",
    "        return layers, inputs\n",
    "    \n",
    "    def _compute_scales(self, layer, inp):\n",
    "\n",
    "        for mod_name, xs in inp.items():\n",
    "            x_flat = torch.cat([x.cpu().abs().view(-1, x.shape[-1]) for x in xs], dim = 0)\n",
    "\n",
    "            # average of absolute value of all channels in linear module\n",
    "            x_mean = x_flat.mean(0)\n",
    "            print(x_mean)\n",
    "\n",
    "            \n",
    "\n",
    "    def _gather_inputs(self, layers, calibration_set):\n",
    "\n",
    "        def input_hook(module, input, output, layer_index, module_name, inputs):\n",
    "            x = input[0]\n",
    "            x = x.detach().cpu()\n",
    "\n",
    "            out = output[0]\n",
    "            out = out.detach().cpu()\n",
    "\n",
    "            inputs[layer_index][module_name].append(x)\n",
    "        \n",
    "\n",
    "        # list of dicts holding inputs for each layer\n",
    "        inputs = [defaultdict(list)] * len(layers)\n",
    "        # list of hooks so we can remove them after\n",
    "        hooks = []\n",
    "        \n",
    "        for i,layer in enumerate(layers):\n",
    "            named_linears = self._get_named_linears(layer)\n",
    "            for name, mod in named_linears.items():\n",
    "                hooks.append(\n",
    "                    mod.register_forward_hook(partial(input_hook,\n",
    "                                                      layer_index = i, \n",
    "                                                      module_name=name, \n",
    "                                                      inputs = inputs))\n",
    "                )\n",
    "\n",
    "        \n",
    "        # TODO: setup proper dataloader for this\n",
    "        for batch in calibration_set:\n",
    "            X = self._prepare_input(batch)\n",
    "            self.run_model(**X)\n",
    "\n",
    "        # remove hooks from model\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "\n",
    "        return inputs\n",
    "        \n",
    "\n",
    "    # returns all nn.linear within module (a layer)\n",
    "    def _get_named_linears(self, module):\n",
    "        return {name: mod for name, mod in module.named_modules() if isinstance(mod, nn.Linear)}\n",
    "\n",
    "    # return layers of model to consider for quantization (modify with config file)\n",
    "    def _get_model_layers(self):\n",
    "        raise NotImplementedError('_get_model_layers')\n",
    "    \n",
    "    def _get_calibration_set(self):\n",
    "        raise NotImplementedError('_get_calibration_set')\n",
    "\n",
    "    def _prepare_input(self):\n",
    "        raise NotImplementedError('_prepare_input')\n",
    "    \n",
    "\n",
    "class Blip2ForConditionalGenerationAWQQuantizer(BaseAWQQuantizer):\n",
    "\n",
    "    def __init__(self, model, inputs_processor, dataset):\n",
    "        assert isinstance(model, Blip2ForConditionalGeneration)\n",
    "\n",
    "        super().__init__(model, device, inputs_processor, dataset)\n",
    "        self.run_model = model.generate\n",
    "        \n",
    "    def _get_model_layers(self):\n",
    "        # NOTE: returning all layers for now\n",
    "        return [*[layer for layer in self.model.vision_model.encoder.layers],\n",
    "                *[layer for layer in self.model.qformer.encoder.layer],\n",
    "                *[layer for layer in self.model.language_model.model.decoder.layers]]\n",
    "\n",
    "    def _get_calibration_set(self):\n",
    "        # NOTE: small set for testing\n",
    "        return [self.dataset[0], self.dataset[1]]\n",
    "\n",
    "    def _prepare_input(self, batch):\n",
    "        X = self.inputs_processor(images=batch[0], return_tensors=\"pt\").to(device)\n",
    "        return X\n",
    "\n",
    "\n",
    "class Blip2ForImageTextRetrievalAWQQuantizer(BaseAWQQuantizer):\n",
    "\n",
    "    def __init__(self, model, device, inputs_processor, dataset):\n",
    "        assert isinstance(model, Blip2ForImageTextRetrieval)\n",
    "        super().__init__(model, device, inputs_processor, dataset)\n",
    "        self.run_model = model.forward\n",
    "        \n",
    "    def _get_model_layers(self):\n",
    "        # NOTE: returning all layers for now\n",
    "        return [*[layer for layer in self.model.vision_model.encoder.layers],\n",
    "                *[layer for layer in self.model.qformer.encoder.layer]]\n",
    "\n",
    "    def _get_calibration_set(self):\n",
    "        return [self.dataset[0], self.dataset[1]]\n",
    "\n",
    "    def _prepare_input(self, batch):\n",
    "        X = self.processor(images=batch[0], text=batch[1][0], return_tensors=\"pt\").to(device, torch.float16)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Blip2ForImageTextRetrieval.from_pretrained(\"Salesforce/blip2-itm-vit-g\", torch_dtype=torch.float16)\n",
    "# processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-itm-vit-g\")\n",
    "# model.to(device)\n",
    "\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Blip2ForConditionalGenerationAWQQuantizer(model, processor, coco_dataset)\n",
    "layers, inputs = b.quantize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blip2EncoderLayer(\n",
       "  (self_attn): Blip2Attention(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "    (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "  )\n",
       "  (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "  (mlp): Blip2MLP(\n",
       "    (activation_fn): GELUActivation()\n",
       "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "  )\n",
       "  (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = layers[0]\n",
    "layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self_attn.qkv': Linear(in_features=1408, out_features=4224, bias=True),\n",
       " 'self_attn.projection': Linear(in_features=1408, out_features=1408, bias=True),\n",
       " 'mlp.fc1': Linear(in_features=1408, out_features=6144, bias=True),\n",
       " 'mlp.fc2': Linear(in_features=6144, out_features=1408, bias=True)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b._get_named_linears(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.cat([_m.weight for _m in layers], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blip2EncoderLayer(\n",
       "  (self_attn): Blip2Attention(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n",
       "    (projection): Linear(in_features=1408, out_features=1408, bias=True)\n",
       "  )\n",
       "  (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       "  (mlp): Blip2MLP(\n",
       "    (activation_fn): GELUActivation()\n",
       "    (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n",
       "    (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n",
       "  )\n",
       "  (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 33, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n",
      "torch.Size([1, 1, 2560])\n"
     ]
    }
   ],
   "source": [
    "for x in inputs[0]['self_attn.q_proj']:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2816, 2560])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = [x.cpu().abs().view(-1, x.shape[-1]) for x in inputs[0]['self_attn.q_proj']]\n",
    "torch.cat(xs, dim = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6801, 0.4476, 0.5009,  ..., 0.7988, 0.7426, 0.6116])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(xs, dim = 0).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = Blip2ForImageTextRetrievalAWQQuantizer(model, processor, coco_dataset)\n",
    "# inputs = b.quantize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: exlude certain linear layers, reading from quant config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: solve for optimal (per input channel) scaling factor\n",
    "# TODO: grid search for \\alpha which balances protection of salient / non-salient weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
